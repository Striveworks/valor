{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d0a509-7500-44ba-b951-3566d4a4fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import json\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "from velour.client import Client, ClientException\n",
    "from velour.data_types import GroundTruthInstanceSegmentation, GroundTruthSemanticSegmentation, Image, Label\n",
    "from velour.viz import combined_segmentation_mask\n",
    "from velour.integrations.coco import upload_coco_panoptic\n",
    "from velour.integrations.yolo import parse_yolo_object_detection, parse_yolo_image_segmentation\n",
    "from velour.metrics import Task\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acb1bd2-238e-4f7e-b246-dd881f020813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chariot.datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32c5d65-a49b-4440-9cd3-241501b89cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(\"http://localhost:8000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fdc5dc-94e4-42c4-8c3c-4f75b6ce50db",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dataset ingestion\n",
    "\n",
    "We assume the COCO panoptic evaluations from\n",
    "http://images.cocodataset.org/annotations/panoptic_annotations_trainval2017.zip have been downloaded and unzipped (including unzipping the file `panoptic_val2017.zip`) to `./coco`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03075a85-d075-4eff-928d-69369d042287",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./coco/annotations/panoptic_val2017.json\") as f:\n",
    "    annotations = json.load(f)\n",
    "    \n",
    "annotations[\"annotations\"] = annotations[\"annotations\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9af91c2-f88d-4722-b988-a2da13eb042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper method to download underlying images from COCO\n",
    "image_id_to_coco_url = {str(img_dict[\"id\"]): img_dict[\"coco_url\"] for img_dict in annotations[\"images\"]}\n",
    "def download_image(img: Image) -> PIL.Image:\n",
    "    url = image_id_to_coco_url[img.uid]\n",
    "    img_data = BytesIO(requests.get(url).content)\n",
    "    return PIL.Image.open(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb100fb9-5cde-47a3-acb5-961b7c9bfb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a dataset object in velour\n",
    "try:\n",
    "    dataset = client.create_image_dataset(\"coco2017-panoptic\")\n",
    "    upload_coco_panoptic(\n",
    "        dataset,\n",
    "        annotations=annotations,\n",
    "        masks_path=\"./coco/annotations/panoptic_val2017/\"\n",
    "    )\n",
    "except ClientException:\n",
    "    dataset = client.get_dataset(\"coco2017-panoptic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6e03d2-72fe-49b5-907d-cd67ba4e1dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.get_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f26aef-b5bb-4c6c-9c28-707ad5e40c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_image(dataset.get_images()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3d5384-14fc-4093-8fea-040d4782e496",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_segs = dataset.get_groundtruth_instance_segmentations(\"139\")\n",
    "semantic_segs = dataset.get_groundtruth_semantic_segmentations(\"139\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737e3e25-aa4a-4934-ad5f-da770bffa44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_mask, instance_legend = combined_segmentation_mask(instance_segs, label_key=\"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9febaa28-6cfd-426b-b637-437bc5594687",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd651c08-c554-4fb2-9dab-4b44679c500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in instance_legend.items():\n",
    "    print(k)\n",
    "    display(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1592a5-375a-4472-98d6-01f519ce2538",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_mask, semantic_legend = combined_segmentation_mask(semantic_segs, label_key=\"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68e5396-03b8-45ad-bed6-9c9c06315da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300e6751-68bb-482f-99b6-e0ee8b28c1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in semantic_legend.items():\n",
    "    print(k)\n",
    "    display(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4ea8d6-9916-4c9d-b913-b7e47d971f2d",
   "metadata": {},
   "source": [
    "# Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a65438-5e69-4577-9a7d-6d796fb164e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chariot.client import connect\n",
    "from chariot.models import Model\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from velour.integrations.chariot import create_model_from_chariot, parse_chariot_object_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b928fc11-f025-4785-8439-a3c2fb1c69bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "connect(\"https://production.chariot.striveworks.us/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ac2e65-1277-4098-b196-0adb71ac3eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = client.get_dataset(\"coco2017-panoptic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43969bb6-102c-45fa-b6a0-0f01d840da2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"fasterrcnnresnet-50fpn\"\n",
    "chariot_model = Model(name=model_name, project_name=\"Global\")\n",
    "\n",
    "try:\n",
    "    velour_chariot_model = create_model_from_chariot(client, chariot_model)\n",
    "except ClientException:\n",
    "    velour_chariot_model = client.get_model('chariot-'+model_name+'-v'+str(chariot_model.version))\n",
    "\n",
    "\n",
    "try:\n",
    "    for image_metadata in tqdm(dataset.get_images()):\n",
    "        image = download_image(image_metadata)    \n",
    "        \n",
    "        # Chariot Inference\n",
    "        detections = chariot_model.detect(image)\n",
    "        velour_dets = parse_chariot_object_detections(detections, image_metadata, label_key=\"name\") \n",
    "\n",
    "        velour_chariot_model.add_predictions(dataset=dataset, predictions=velour_dets, show_progress_bar=False)\n",
    "except ClientException:\n",
    "    print(\"Velour Chariot model already finalized.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae341dc-44b8-47e3-b99c-486c475b4c1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"yolov8n-seg\"\n",
    "yolo_model = YOLO(f\"{model_name}.pt\")\n",
    "\n",
    "try:\n",
    "    velour_yolo_model = client.create_image_model(model_name + \"\")\n",
    "except ClientException:\n",
    "    velour_yolo_model = client.get_model(model_name + '')\n",
    "\n",
    "try:\n",
    "    for image_metadata in tqdm(dataset.get_images()):\n",
    "        image = download_image(image_metadata)     \n",
    "        \n",
    "        # YOLO Inference\n",
    "        results = yolo_model(image, verbose=False)\n",
    "        \n",
    "        if model_name == 'yolov8n-seg':\n",
    "            velour_dets = parse_yolo_object_detection(results[0], uid=image_metadata.uid, label_key='name')\n",
    "        # elif model_name == 'yolov8n-seg':\n",
    "        #     velour_dets = parse_yolo_image_segmentation(results[0], uid=image_metadata.uid, label_key='name')\n",
    "        else:\n",
    "            raise NameError\n",
    "\n",
    "        velour_yolo_model.add_predictions(dataset=dataset, predictions=velour_dets, show_progress_bar=False)\n",
    "\n",
    "except ClientException:\n",
    "    print(\"Velour YOLO model already finalized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92993647",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(velour_dets[0].scored_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583f9282-70b7-4d5e-911a-810d7c3502e6",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffb60f0-516b-4a89-b159-0359285b35a6",
   "metadata": {},
   "source": [
    "for provenance, the dataset and inferences on the dataset must be finalized before evaluation can be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f4179d-0314-4d79-81f1-b9b309452250",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.finalize()\n",
    "velour_chariot_model.finalize_inferences(dataset)\n",
    "velour_yolo_model.finalize_inferences(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85404d81-b422-41c3-b7fc-4c6ba727eaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def evaluate_ap(dataset, model, max_area=None):\n",
    "    eval_job = model.evaluate_ap(\n",
    "        dataset=dataset,\n",
    "        model_pred_task_type=Task.BBOX_OBJECT_DETECTION,\n",
    "        dataset_gt_task_type=Task.INSTANCE_SEGMENTATION,\n",
    "        label_key=\"name\",\n",
    "        max_area=max_area,\n",
    "    )\n",
    "\n",
    "    while eval_job.status() == 'Processing':\n",
    "        time.sleep(1)\n",
    "    \n",
    "    return eval_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b78220-a479-4f2f-8134-a24fc2e8b782",
   "metadata": {},
   "outputs": [],
   "source": [
    "job1 = evaluate_ap(dataset, velour_chariot_model)\n",
    "job2 = evaluate_ap(dataset, velour_chariot_model, max_area=30*300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adefc71-c2c8-42f0-b0a9-2381263ae3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "job3 = evaluate_ap(dataset, velour_yolo_model)\n",
    "job4 = evaluate_ap(dataset, velour_yolo_model, max_area=30*300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0b0cc1-93b6-4807-a63c-9cd9e0435a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(job1.metrics()[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1054a222",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(job2.metrics()[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6e3abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(job3.metrics()[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b50dbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(job4.metrics()[:2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ade3e294",
   "metadata": {},
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9dd0c0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully connected to http://localhost:8000/.\n"
     ]
    }
   ],
   "source": [
    "from velour.client import Client\n",
    "from velour.data_types import Label\n",
    "client = Client(\"http://localhost:8000\")\n",
    "\n",
    "velour_coco = client.get_dataset(\"coco2017-panoptic\")\n",
    "\n",
    "model_name = \"yolov8n-seg\"\n",
    "velour_yolo = client.get_model(model_name + '')\n",
    "\n",
    "model_name = \"fasterrcnnresnet-50fpn\"\n",
    "velour_chariot = client.get_model('chariot-'+model_name+'-v'+str('1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99183b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coco2017-panoptic\n",
      "None\n",
      "None\n",
      "0\n",
      "0\n",
      "351\n",
      "SEGMENTATION\n",
      "['chariot-fasterrcnnresnet-50fpn-v1', 'yolov8n-seg']\n"
     ]
    }
   ],
   "source": [
    "print(velour_coco.name)\n",
    "print(velour_coco.description)\n",
    "print(velour_coco.href)\n",
    "print(velour_coco.number_of_classifications)\n",
    "print(velour_coco.number_of_detections)\n",
    "print(velour_coco.number_of_segmentations)\n",
    "print(velour_coco.type)\n",
    "print(velour_coco.associated_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98ff7e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolov8n-seg\n",
      "None\n",
      "None\n",
      "0\n",
      "49\n",
      "0\n",
      "DETECTION\n",
      "['coco2017-panoptic']\n"
     ]
    }
   ],
   "source": [
    "print(velour_yolo.name)\n",
    "print(velour_yolo.description)\n",
    "print(velour_yolo.href)\n",
    "print(velour_yolo.number_of_classifications)\n",
    "print(velour_yolo.number_of_detections)\n",
    "print(velour_yolo.number_of_segmentations)\n",
    "print(velour_yolo.type)\n",
    "print(velour_yolo.associated_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb36cb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chariot-fasterrcnnresnet-50fpn-v1\n",
      "FasterRCNNResnet50FPN detector pretrained on COCO. Transferred from torchvision.models. This model was uploaded via CICD\n",
      "https://production.chariot.striveworks.us/projects/2LVnCYT9WAMXfIZjW2o4E1X3Mvz/models/2LhPalERvF0qb42znK7D35fOwjI\n",
      "0\n",
      "96\n",
      "0\n",
      "DETECTION\n",
      "['coco2017-panoptic']\n"
     ]
    }
   ],
   "source": [
    "print(velour_chariot.name)\n",
    "print(velour_chariot.description)\n",
    "print(velour_chariot.href)\n",
    "print(velour_chariot.number_of_classifications)\n",
    "print(velour_chariot.number_of_detections)\n",
    "print(velour_chariot.number_of_segmentations)\n",
    "print(velour_chariot.type)\n",
    "print(velour_chariot.associated_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79b58bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = velour_coco.get_label_distribution()\n",
    "\n",
    "label_person = Label(key='name', value='person')\n",
    "label = Label(key='supercategory', value='furniture')\n",
    "\n",
    "count = distribution[label_person]\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ed238",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = velour_yolo.get_label_distribution()\n",
    "\n",
    "label = Label(key='name', value='tv')\n",
    "\n",
    "info = distribution[label]\n",
    "\n",
    "print(info['count'])\n",
    "print(info['scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcc5cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = velour_yolo.get_labels()\n",
    "\n",
    "for label in labels:\n",
    "    print(label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env-velour",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
