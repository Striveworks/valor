{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "An introduction to the Velour evaluation service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from velour.client import Dataset, Model, Client, ClientException\n",
    "from velour.coretypes import Datum, Annotation, Label, GroundTruth, Prediction\n",
    "from velour.enums import TaskType"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Getting Started\n",
    "    a. Basic usage & workflow of classification task\n",
    "    b. Labels\n",
    "2. Annotations\n",
    "    a. Annotations\n",
    "    b. Image\n",
    "        i. geometry\n",
    "    c. Tabular\n",
    "    d. Future support\n",
    "3. Metadata\n",
    "    a. Adding metadata to Dataset, Model, Datum and Annotation objects.\n",
    "    b. How this enables MetaTypes for representing customer data.\n",
    "4. Filtering\n",
    "    a. Basic filters from intrinsics\n",
    "    b. Leverage metadata to create application-specific filters\n",
    "    c. Geospatial filters\n",
    "5. Classification\n",
    "6. Object Detection\n",
    "7. Semantic Segmentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(\"http://localhost:8000\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset and Model are client-types in Velour. Their internal values are determined by the backend. Note that they use a `classmethod` for creation and that they take the client object as input.\n",
    "\n",
    "If the normal initializer is used to create a client-type then creation on the backend is not guaranteed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.create(client, name=\"myDataset\")\n",
    "model = Model.create(client, name=\"myModel\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`velour.coretypes` contain other velour types that are used to construct representations of your annotations and metadata. The two most important types are `Datum` and `Annotation`. These are the building blocks for constructing a representation of your data that can be operated over by Velour.\n",
    "\n",
    "Let's create a datum and then an annotation for a classification job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datum = Datum(uid=\"myDatum1\")\n",
    "\n",
    "annotation = Annotation(\n",
    "    task_type=TaskType.CLASSIFICATION,\n",
    "    labels=[\n",
    "        Label(key=\"k1\", value=\"v1\"),\n",
    "        Label(key=\"k2\", value=\"v2\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "annotation_with_scores = Annotation(\n",
    "    task_type=TaskType.CLASSIFICATION,\n",
    "    labels=[\n",
    "        Label(key=\"k1\", value=\"v1\", score=0.7),\n",
    "        Label(key=\"k1\", value=\"v2\", score=0.3),\n",
    "        Label(key=\"k2\", value=\"v1\", score=0.1),\n",
    "        Label(key=\"k2\", value=\"v2\", score=0.9),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`velour.coretypes` also defines `GroundTruth` and `Prediction`. These are closely related objects with the only difference being the backend target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth = GroundTruth(datum, annotations=[annotation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = Prediction(datum, annotations=[annotation_with_scores])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have everything required to upload to velour! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.add_groundtruth(groundtruth)\n",
    "model.add_prediction(prediction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can run an evaluation we need to finalize our dataset and then our predictions over the dataset. This is a requirement of Velour so that repeat evaluations over a Dataset-Model pairing are guaranteed to return the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.finalize()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Model` finalization is a little different than `Dataset` as it is locking predictions with respect to the dataset they operated over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.finalize_inferences(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a dataset and model representation on the backend that we can evaluate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate_classification(dataset)\n",
    "evaluation.wait_for_completion()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We currently support `classification`, `object-detection`, and `semantic-segmentation` evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluation.results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env-velour",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
