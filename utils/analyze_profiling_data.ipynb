{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import linecache\n",
    "\n",
    "from run_profile import load_pkl\n",
    "from viz import plot_grouped_barchart, convert_shortened_bytes_to_int, bytes_to_readable_fmt\n",
    "import tracemalloc\n",
    "import warnings\n",
    "import yappi\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Overall Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files_to_load = ['profiling_4', 'profiling_5', 'profiling_6']\n",
    "\n",
    "files_to_load = ['profiling_3']\n",
    "\n",
    "results = []\n",
    "for file in files_to_load:\n",
    "    results += load_pkl(f\"{os.getcwd()}/profiles/{file}.pkl\")\n",
    "\n",
    "\n",
    "df = pd.DataFrame.from_records(results)\n",
    "\n",
    "for col in ['total_runtime_seconds', 'setup_runtime_seconds', 'evaluation_runtime_seconds']:\n",
    "    df[col.replace('_seconds', '_minutes')] = df[col] / 60\n",
    "\n",
    "# parse docker output into bytes\n",
    "for col in ['pgvalor_disk_space']:\n",
    "    split_df = df.loc[:, col].str.split('(', expand=True)\n",
    "    split_df[1] = split_df[1].replace(to_replace='\\)', value=\"\", regex=True).replace(to_replace='virtual ', value=\"\", regex=True)\n",
    "    split_df = split_df.applymap(convert_shortened_bytes_to_int)\n",
    "    split_df.columns = [f'{col}_used', f'{col}_virtual']\n",
    "    split_df[f'{col}_total'] = split_df.sum(axis=1)\n",
    "    df = pd.concat([df, split_df], axis=1)\n",
    "\n",
    "for col in ['pgvalor_cpu_util', 'pgvalor_mem_util']:\n",
    "    df[col] = df[col].str.rstrip('%').astype('float') / 100.0\n",
    "\n",
    "\n",
    "# combine tracemalloc columns\n",
    "df['client_tracemalloc_top10'] = df[[i for i in range(10)]].apply(dict, axis=1)\n",
    "df.drop([i for i in range(10)], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grouped_barchart(df=df, x=\"n_images\", y=\"total_runtime_minutes\", hue=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grouped_barchart(df=df, x=\"n_images\", y=\"setup_runtime_minutes\", hue=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grouped_barchart(df=df, x=\"n_images\", y=\"evaluation_runtime_minutes\", hue=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grouped_barchart(df=df, x=\"n_images\", y=\"total_runtime_minutes\", hue='n_annotations')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### postgis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grouped_barchart(df=df, x=\"n_images\", y=\"pgvalor_disk_space_total\", hue=None, y_axis_label='total disk space used by postgresql', convert_bytes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: mem_util is the memory usage at the time the snapshot was taken, not the overall peak memory usage\n",
    "plot_grouped_barchart(df=df, x=\"n_images\", y=\"pgvalor_mem_util\", hue=None, y_axis_label='memory used by pgvalor after profiling function call', convert_perc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Backend Profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cprofile\n",
    "\n",
    "Use this command to analyze CProfile reports in snakeviz:\n",
    "\n",
    "```\n",
    "snakeviz utils/profiles/create_groundtruths.cprofile\n",
    "snakeviz utils/profiles/create_predictions.cprofile\n",
    "snakeviz utils/profiles/create_detection_metrics.cprofile\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tracemalloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create_groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_to_analyze = 'create_groundtruths'\n",
    "\n",
    "def _print_tracemalloc_peaks(dct:dict):\n",
    "    size_pct = (dct[\"second_size\"]-dct[\"first_size\"])/dct[\"first_size\"]\n",
    "    print(f'Original size: {bytes_to_readable_fmt(dct[\"first_size\"], 0)}')\n",
    "    print(f'Final size: {bytes_to_readable_fmt(dct[\"second_size\"], 0)}')\n",
    "    print(f'Percent Change: {size_pct:2%}')\n",
    "    print('')\n",
    "\n",
    "tracemalloc_path = f'profiles/{function_to_analyze}.tracemalloc'\n",
    "snapshot = tracemalloc.Snapshot.load(tracemalloc_path)\n",
    "tracemalloc_dct = load_pkl(tracemalloc_path + '.pkl')\n",
    "\n",
    "\n",
    "_print_tracemalloc_peaks(tracemalloc_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _display_top_tracemalloc(snapshot:tracemalloc.Snapshot, key_type:str='lineno', limit:int=10):\n",
    "    snapshot = snapshot.filter_traces((\n",
    "        tracemalloc.Filter(False, \"<frozen importlib._bootstrap>\"),\n",
    "        tracemalloc.Filter(False, \"<unknown>\"),\n",
    "        tracemalloc.Filter(True, '*/valor/*')\n",
    "    ))\n",
    "    top_stats = snapshot.statistics(key_type)\n",
    "\n",
    "    print(\"Top %s lines\" % limit)\n",
    "    for index, stat in enumerate(top_stats[:limit], 1):\n",
    "        frame = stat.traceback[0]\n",
    "        print(\"#%s: %s:%s: %.1f KiB\"\n",
    "              % (index, frame.filename, frame.lineno, stat.size / 1024))\n",
    "        line = linecache.getline(frame.filename, frame.lineno).strip()\n",
    "        if line:\n",
    "            print('    loc: %s:%s' % (frame.filename, frame.lineno))\n",
    "            print('    func: %s' % line)\n",
    "\n",
    "    other = top_stats[limit:]\n",
    "    if other:\n",
    "        size = sum(stat.size for stat in other)\n",
    "        print(\"%s other: %.1f KiB\" % (len(other), size / 1024))\n",
    "    total = sum(stat.size for stat in top_stats)\n",
    "    print(\"Total allocated size: %.1f KiB\" % (total / 1024))\n",
    "\n",
    "_display_top_tracemalloc(snapshot=snapshot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_to_analyze = 'create_predictions'\n",
    "\n",
    "tracemalloc_path = f'profiles/{function_to_analyze}.tracemalloc'\n",
    "snapshot = tracemalloc.Snapshot.load(tracemalloc_path)\n",
    "tracemalloc_dct = load_pkl(tracemalloc_path + '.pkl')\n",
    "\n",
    "\n",
    "_print_tracemalloc_peaks(tracemalloc_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_top_tracemalloc(snapshot=snapshot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create_detection_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_to_analyze = 'create_detection_metrics'\n",
    "\n",
    "tracemalloc_path = f'profiles/{function_to_analyze}.tracemalloc'\n",
    "snapshot = tracemalloc.Snapshot.load(tracemalloc_path)\n",
    "tracemalloc_dct = load_pkl(tracemalloc_path + '.pkl')\n",
    "\n",
    "\n",
    "_print_tracemalloc_peaks(tracemalloc_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_top_tracemalloc(snapshot=snapshot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## yappi\n",
    "\n",
    "NOTE: This profiler is difficult to visualize without kCacheGrind. Prefer cprofile for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = yappi.get_func_stats()\n",
    "stats.add(\"profiles/create_groundtruths.yappi\")\n",
    "\n",
    "stats.sort(\"tsub\", \"desc\").print_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = yappi.get_func_stats()\n",
    "stats.add(\"profiles/create_predictions.yappi\")\n",
    "\n",
    "stats.sort(\"tsub\", \"desc\").print_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = yappi.get_func_stats()\n",
    "stats.add(\"profiles/create_detection_metrics.yappi\")\n",
    "\n",
    "stats.sort(\"tsub\", \"desc\").print_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
