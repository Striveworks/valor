
<!DOCTYPE html>

<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<link href="../metadata_and_filtering/" rel="prev"/>
<link href="../endpoints/" rel="next"/>
<link href="../assets/images/favicon.png" rel="icon"/>
<meta content="mkdocs-1.5.3, mkdocs-material-9.5.11" name="generator"/>
<title>Metrics - Valor</title>
<link href="../assets/stylesheets/main.7e359304.min.css" rel="stylesheet"/>
<link href="../assets/stylesheets/palette.06af60db.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
<link href="../assets/_mkdocstrings.css" rel="stylesheet"/>
<script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
</head>
<body data-md-color-accent="indigo" data-md-color-primary="deep-purple" data-md-color-scheme="slate" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#metrics">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header md-header--shadow" data-md-component="header">
<nav aria-label="Header" class="md-header__inner md-grid">
<a aria-label="Valor" class="md-header__button md-logo" data-md-component="logo" href=".." title="Valor">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"></path></svg>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            Valor
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              Metrics
            
          </span>
</div>
</div>
</div>
<label class="md-header__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="Search" required="" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg>
</label>
<nav aria-label="Search" class="md-search__options">
<button aria-label="Clear" class="md-search__icon md-icon" tabindex="-1" title="Clear" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"></path></svg>
</button>
</nav>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            Initializing search
          </div>
<ol class="md-search-result__list" role="presentation"></ol>
</div>
</div>
</div>
</div>
</div>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/striveworks/valor" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="Valor" class="md-nav__button md-logo" data-md-component="logo" href=".." title="Valor">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"></path></svg>
</a>
    Valor
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/striveworks/valor" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="..">
<span class="md-ellipsis">
    Overview
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../installation/">
<span class="md-ellipsis">
    Installation
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../basic_usage/">
<span class="md-ellipsis">
    Basic Usage
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="https://github.com/Striveworks/valor/blob/main/examples/">
<span class="md-ellipsis">
    Sample Notebooks
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../metadata_and_filtering/">
<span class="md-ellipsis">
    Metadata &amp; Filtering
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
<span class="md-ellipsis">
    Metrics
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="./">
<span class="md-ellipsis">
    Metrics
  </span>
</a>
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#classification-metrics">
<span class="md-ellipsis">
      Classification Metrics
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#object-detection-and-instance-segmentation-metrics1">
<span class="md-ellipsis">
      Object Detection and Instance Segmentation Metrics[^1]
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#semantic-segmentation-metrics">
<span class="md-ellipsis">
      Semantic Segmentation Metrics
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../endpoints/">
<span class="md-ellipsis">
    Endpoints
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../technical_concepts/">
<span class="md-ellipsis">
    Technical Concepts
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../contributing/">
<span class="md-ellipsis">
    Contributing &amp; Development
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_10" type="checkbox"/>
<label class="md-nav__link" for="__nav_10" id="__nav_10_label" tabindex="0">
<span class="md-ellipsis">
    Python Client API
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_10_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_10">
<span class="md-nav__icon md-icon"></span>
            Python Client API
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../client_api/Annotation/">
<span class="md-ellipsis">
    Annotation
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../client_api/Client/">
<span class="md-ellipsis">
    Client
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../client_api/Data%20Generation/">
<span class="md-ellipsis">
    Data Generation
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../client_api/Dataset/">
<span class="md-ellipsis">
    Dataset
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../client_api/Datum/">
<span class="md-ellipsis">
    Datum
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../client_api/Evaluation/">
<span class="md-ellipsis">
    Evaluation
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../client_api/Groundtruth/">
<span class="md-ellipsis">
    Groundtruth
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../client_api/ImageMetadata/">
<span class="md-ellipsis">
    ImageMetadata
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../client_api/Label/">
<span class="md-ellipsis">
    Label
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../client_api/Model/">
<span class="md-ellipsis">
    Model
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../client_api/Prediction/">
<span class="md-ellipsis">
    Prediction
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../client_api/VideoFrameMetadata/">
<span class="md-ellipsis">
    VideoFrameMetadata
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../client_api/Viz/">
<span class="md-ellipsis">
    Viz
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle md-toggle--indeterminate" id="__nav_10_14" type="checkbox"/>
<label class="md-nav__link" for="__nav_10_14" id="__nav_10_14_label" tabindex="0">
<span class="md-ellipsis">
    Schemas
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_10_14_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_10_14">
<span class="md-nav__icon md-icon"></span>
            Schemas
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../client_api/Schemas/Evaluation/">
<span class="md-ellipsis">
    Evaluation
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../client_api/Schemas/Filters/">
<span class="md-ellipsis">
    Filters
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../client_api/Schemas/Geometries/">
<span class="md-ellipsis">
    Geometries
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#classification-metrics">
<span class="md-ellipsis">
      Classification Metrics
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#object-detection-and-instance-segmentation-metrics1">
<span class="md-ellipsis">
      Object Detection and Instance Segmentation Metrics[^1]
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#semantic-segmentation-metrics">
<span class="md-ellipsis">
      Semantic Segmentation Metrics
    </span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<h1 id="metrics">Metrics</h1>
<p>Let's look at the various metrics you can calculate using Valor.</p>
<p>If we're missing an important metric for your particular use case, please <a href="https://github.com/Striveworks/valor/issues">write us a GitHub Issue ticket</a>. We love hearing your suggestions.</p>
<h2 id="classification-metrics">Classification Metrics</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Name</th>
<th style="text-align: left;">Description</th>
<th style="text-align: left;">Equation</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Precision</td>
<td style="text-align: left;">The number of true positives divided by the total number of positive predictions (i.e., the number of true positives plus the number of false positives).</td>
<td style="text-align: left;">$$\dfrac{|TP|}{|TP|+|FP|}$$</td>
</tr>
<tr>
<td style="text-align: left;">Recall</td>
<td style="text-align: left;">The number of true positives divided by the total count of the class of interest (i.e., the number of true positives plus the number of true negatives).</td>
<td style="text-align: left;">$$\dfrac{|TP|}{|TP|+|FN|}$$</td>
</tr>
<tr>
<td style="text-align: left;">F1</td>
<td style="text-align: left;">A weighted average of precision and recall.</td>
<td style="text-align: left;">$$\frac{2 * Precision * Recall}{Precision + Recall}$$</td>
</tr>
<tr>
<td style="text-align: left;">Accuracy</td>
<td style="text-align: left;">The number of true predictions divided by the total number of predictions.</td>
<td style="text-align: left;">$$\dfrac{|TP|+|TN|}{|TP|+|TN|+|FP|+|FN|}$$</td>
</tr>
<tr>
<td style="text-align: left;">ROC AUC</td>
<td style="text-align: left;">The area under the Receiver Operating Characteristic (ROC) curve for the predictions generated by a given model.</td>
<td style="text-align: left;">See <a href="#binary-roc-auc">ROCAUC methods</a>.</td>
</tr>
</tbody>
</table>
<h2 id="object-detection-and-instance-segmentation-metrics1">Object Detection and Instance Segmentation Metrics[^1]</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Name</th>
<th style="text-align: left;">Description</th>
<th style="text-align: left;">Equation</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Average Precision (AP)</td>
<td style="text-align: left;">The weighted mean of precisions achieved at several different recall thresholds for a single Intersection over Union (IOU), grouped by class.</td>
<td style="text-align: left;">See <a href="#average-precision-ap">AP methods</a>.</td>
</tr>
<tr>
<td style="text-align: left;">AP Averaged Over IOUs</td>
<td style="text-align: left;">The average of several AP metrics, calculated at various IOUs, grouped by class.</td>
<td style="text-align: left;">$$\dfrac{1}{\text{number of thresholds}} \sum\limits_{iou \in thresholds} AP_{iou}$$</td>
</tr>
<tr>
<td style="text-align: left;">Mean Average Precision (mAP)</td>
<td style="text-align: left;">The mean of several AP scores, calculated over various classes.</td>
<td style="text-align: left;">$$\dfrac{1}{\text{number of classes}} \sum\limits_{c \in classes} AP_{c}$$</td>
</tr>
<tr>
<td style="text-align: left;">mAP Averaged Over IOUs</td>
<td style="text-align: left;">The mean of several averaged AP scores, calculated over various classes.</td>
<td style="text-align: left;">$$\dfrac{1}{\text{number of thresholds}} \sum\limits_{iou \in thresholds} mAP_{iou}$$</td>
</tr>
</tbody>
</table>
<p>[^1]: When calculating IOUs for object detection metrics, Valor handles the necessary conversion between different types of geometric annotations. For example, if your model prediction is a polygon and your groundtruth is a raster, then the raster will be converted to a polygon prior to calculating the IOU.</p>
<h2 id="semantic-segmentation-metrics">Semantic Segmentation Metrics</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Name</th>
<th style="text-align: left;">Description</th>
<th style="text-align: left;">Equation</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Intersection Over Union (IOU)</td>
<td style="text-align: left;">A ratio between the groundtruth and predicted regions of an image, measured as a percentage, grouped by class.</td>
<td style="text-align: left;">$$\dfrac{area( prediction \cap groundtruth )}{area( prediction \cup groundtruth )}$$</td>
</tr>
<tr>
<td style="text-align: left;">Mean IOU</td>
<td style="text-align: left;">The average of IOUs, calculated over several different classes.</td>
<td style="text-align: left;">$$\dfrac{1}{\text{number of classes}} \sum\limits_{c \in classes} IOU_{c}$$</td>
</tr>
</tbody>
</table>
<h1 id="appendix-metric-calculations">Appendix: Metric Calculations</h1>
<h2 id="binary-roc-auc">Binary ROC AUC</h2>
<h3 id="receiver-operating-characteristic-roc">Receiver Operating Characteristic (ROC)</h3>
<p>An ROC curve plots the True Positive Rate (TPR) vs. the False Positive Rate (FPR) at different confidence thresholds.</p>
<p>In Valor, we use the confidence scores sorted in decreasing order as our thresholds. Using these thresholds, we can calculate our TPR and FPR as follows:</p>
<h4 id="determining-the-rate-of-correct-predictions">Determining the Rate of Correct Predictions</h4>
<table>
<thead>
<tr>
<th>Element</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>True Positive (TP)</td>
<td>Prediction confidence score &gt;= threshold and is correct.</td>
</tr>
<tr>
<td>False Positive (FP)</td>
<td>Prediction confidence score &gt;= threshold and is incorrect.</td>
</tr>
<tr>
<td>True Negative (TN)</td>
<td>Prediction confidence score &lt; threshold and is correct.</td>
</tr>
<tr>
<td>False Negative (FN)</td>
<td>Prediction confidence score &lt; threshold and is incorrect.</td>
</tr>
</tbody>
</table>
<ul>
<li>
<p>$\text{True Positive Rate (TPR)} = \dfrac{|TP|}{|TP| + |FN|} = \dfrac{|TP(threshold)|}{|TP(threshold)| + |FN(threshold)|}$</p>
</li>
<li>
<p>$\text{False Positive Rate (FPR)} = \dfrac{|FP|}{|FP| + |TN|} = \dfrac{|FP(threshold)|}{|FP(threshold)| + |TN(threshold)|}$</p>
</li>
</ul>
<p>We now use the confidence scores, sorted in decreasing order, as our thresholds in order to generate points on a curve.</p>
<p>$$
Point(score) = (FPR(score), \ TPR(score))
$$</p>
<h3 id="area-under-the-roc-curve-roc-auc">Area Under the ROC Curve (ROC AUC)</h3>
<p>After calculating the ROC curve, we find the ROC AUC metric by approximating the integral using the trapezoidal rule formula.</p>
<p>$$
ROC AUC =  \sum_{i=1}^{|scores|} \frac{  \lVert Point(score_{i-1}) - Point(score_i) \rVert }{2}
$$</p>
<p>See <a href="https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc">Classification: ROC Curve and AUC</a> for more information.</p>
<h2 id="average-precision-ap">Average Precision (AP)</h2>
<p>For object detection and instance segmentation tasks, average precision is calculated from the intersection-over-union (IOU) of geometric predictions and ground truths.</p>
<h3 id="multiclass-precision-and-recall">Multiclass Precision and Recall</h3>
<p>Tasks that predict geometries (such as object detection or instance segmentation) use the ratio intersection-over-union (IOU) to calculate precision and recall. IOU is the ratio of the intersecting area over the joint area spanned by the two geometries, and is defined in the following equation.</p>
<p>$$Intersection \ over \ Union \ (IOU) = \dfrac{Area( prediction \cap groundtruth )}{Area( prediction \cup groundtruth )}$$</p>
<p>Using different IOU thresholds, we can determine whether we count a pairing between a prediction and a ground truth pairing based on their overlap.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Case</th>
<th style="text-align: left;">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">True Positive (TP)</td>
<td style="text-align: left;">Prediction-GroundTruth pair exists with IOU &gt;= threshold.</td>
</tr>
<tr>
<td style="text-align: left;">False Positive (FP)</td>
<td style="text-align: left;">Prediction-GroundTruth pair exists with IOU &lt; threshold.</td>
</tr>
<tr>
<td style="text-align: left;">True Negative (TN)</td>
<td style="text-align: left;">Unused in multi-class evaluation.</td>
</tr>
<tr>
<td style="text-align: left;">False Negative (FN)</td>
<td style="text-align: left;">No Prediction with a matching label exists for the GroundTruth.</td>
</tr>
</tbody>
</table>
<ul>
<li>
<p>$Precision = \dfrac{|TP|}{|TP| + |FP|} = \dfrac{\text{Number of True Predictions}}{|\text{Predictions}|}$</p>
</li>
<li>
<p>$Recall = \dfrac{|TP|}{|TP| + |FN|} = \dfrac{\text{Number of True Predictions}}{|\text{Groundtruths}|}$</p>
</li>
</ul>
<h3 id="matching-ground-truths-with-predictions">Matching Ground Truths with Predictions</h3>
<p>To properly evaluate a detection, we must first find the best pairings of predictions to ground truths. We start by iterating over our predictions, ordering them by highest scores first. We pair each prediction with the ground truth that has the highest calculated IOU. Both the prediction and ground truth are now considered paired and removed from the pool of choices.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="k">def</span> <span class="nf">rank_ious</span><span class="p">(</span>
</span><span id="__span-0-2"><a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="n">groundtruths</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span>
</span><span id="__span-0-3"><a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="n">predictions</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span>
</span><span id="__span-0-4"><a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]:</span>
</span><span id="__span-0-5"><a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="w">    </span><span class="sd">"""Ranks ious by unique pairings."""</span>
</span><span id="__span-0-6"><a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a>
</span><span id="__span-0-7"><a href="#__codelineno-0-7" id="__codelineno-0-7" name="__codelineno-0-7"></a>    <span class="n">retval</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="__span-0-8"><a href="#__codelineno-0-8" id="__codelineno-0-8" name="__codelineno-0-8"></a>    <span class="n">groundtruths</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">groundtruths</span><span class="p">)</span>
</span><span id="__span-0-9"><a href="#__codelineno-0-9" id="__codelineno-0-9" name="__codelineno-0-9"></a>    <span class="k">for</span> <span class="n">prediction</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="o">-</span><span class="n">x</span><span class="o">.</span><span class="n">score</span><span class="p">):</span>
</span><span id="__span-0-10"><a href="#__codelineno-0-10" id="__codelineno-0-10" name="__codelineno-0-10"></a>        <span class="n">groundtruth</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">groundtruths</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="n">calculate_iou</span><span class="p">(</span><span class="n">groundtruth</span><span class="p">,</span> <span class="n">prediction</span><span class="p">))</span>
</span><span id="__span-0-11"><a href="#__codelineno-0-11" id="__codelineno-0-11" name="__codelineno-0-11"></a>        <span class="n">groundtruths</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">groundtruth</span><span class="p">)</span>
</span><span id="__span-0-12"><a href="#__codelineno-0-12" id="__codelineno-0-12" name="__codelineno-0-12"></a>        <span class="n">retval</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">calculate_iou</span><span class="p">(</span><span class="n">groundtruth</span><span class="p">,</span> <span class="n">prediction</span><span class="p">))</span>
</span></code></pre></div>
<h3 id="precision-recall-curve">Precision-Recall Curve</h3>
<p>We can now compute the precision-recall curve using our previously ranked IOU's. We do this by iterating through the ranked IOU's and creating points cumulatively using recall and precision.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a href="#__codelineno-1-1" id="__codelineno-1-1" name="__codelineno-1-1"></a><span class="k">def</span> <span class="nf">create_precision_recall_curve</span><span class="p">(</span>
</span><span id="__span-1-2"><a href="#__codelineno-1-2" id="__codelineno-1-2" name="__codelineno-1-2"></a>    <span class="n">number_of_groundtruths</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span><span id="__span-1-3"><a href="#__codelineno-1-3" id="__codelineno-1-3" name="__codelineno-1-3"></a>    <span class="n">ranked_ious</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
</span><span id="__span-1-4"><a href="#__codelineno-1-4" id="__codelineno-1-4" name="__codelineno-1-4"></a>    <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span>
</span><span id="__span-1-5"><a href="#__codelineno-1-5" id="__codelineno-1-5" name="__codelineno-1-5"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]:</span>
</span><span id="__span-1-6"><a href="#__codelineno-1-6" id="__codelineno-1-6" name="__codelineno-1-6"></a><span class="w">    </span><span class="sd">"""Creates the precision-recall curve from a list of IOU's and a threshold."""</span>
</span><span id="__span-1-7"><a href="#__codelineno-1-7" id="__codelineno-1-7" name="__codelineno-1-7"></a>
</span><span id="__span-1-8"><a href="#__codelineno-1-8" id="__codelineno-1-8" name="__codelineno-1-8"></a>    <span class="n">retval</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="__span-1-9"><a href="#__codelineno-1-9" id="__codelineno-1-9" name="__codelineno-1-9"></a>    <span class="n">count_tp</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="__span-1-10"><a href="#__codelineno-1-10" id="__codelineno-1-10" name="__codelineno-1-10"></a>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ranked_ious</span><span class="p">):</span>
</span><span id="__span-1-11"><a href="#__codelineno-1-11" id="__codelineno-1-11" name="__codelineno-1-11"></a>        <span class="k">if</span> <span class="n">ranked_ious</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">threshold</span><span class="p">:</span>
</span><span id="__span-1-12"><a href="#__codelineno-1-12" id="__codelineno-1-12" name="__codelineno-1-12"></a>            <span class="n">count_tp</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span id="__span-1-13"><a href="#__codelineno-1-13" id="__codelineno-1-13" name="__codelineno-1-13"></a>        <span class="n">precision</span> <span class="o">=</span> <span class="n">count_tp</span> <span class="o">/</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-1-14"><a href="#__codelineno-1-14" id="__codelineno-1-14" name="__codelineno-1-14"></a>        <span class="n">recall</span> <span class="o">=</span> <span class="n">count_tp</span> <span class="o">/</span> <span class="n">number_of_groundtruths</span>
</span><span id="__span-1-15"><a href="#__codelineno-1-15" id="__codelineno-1-15" name="__codelineno-1-15"></a>        <span class="n">retval</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">recall</span><span class="p">,</span> <span class="n">precision</span><span class="p">))</span>
</span></code></pre></div>
<h3 id="calculating-average-precision">Calculating Average Precision</h3>
<p>Average precision is defined as the area under the precision-recall curve.</p>
<p>We will use a 101-point interpolation of the curve to be consistent with the COCO evaluator. The intent behind interpolation is to reduce the fuzziness that results from ranking pairs.</p>
<p>$$
AP = \frac{1}{101} \sum\limits_{r\in{ 0, 0.01, \ldots , 1 }}\rho_{interp}(r)
$$</p>
<p>$$
\rho_{interp} = \underset{\tilde{r}:\tilde{r} \ge r}{max \ \rho (\tilde{r})}
$$</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://cocodataset.org/#detection-eval">MS COCO Detection Evaluation</a></li>
<li><a href="https://link.springer.com/article/10.1007/s11263-009-0275-4">The PASCAL Visual Object Classes (VOC) Challenge</a></li>
<li><a href="https://pyimagesearch.com/2022/05/02/mean-average-precision-map-using-the-coco-evaluator/">Mean Average Precision (mAP) Using the COCO Evaluator</a></li>
</ul>
</article>
</div>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div>
</main>
<footer class="md-footer">
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs
    </a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": "..", "features": ["navigation.expand"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
<script src="../assets/javascripts/bundle.8fd75fb4.min.js"></script>
<script>document$.subscribe(() => {
            window.update_swagger_ui_iframe_height = function (id) {
                var iFrameID = document.getElementById(id);
                if (iFrameID) {
                    full_height = (iFrameID.contentWindow.document.body.scrollHeight + 80) + "px";
                    iFrameID.height = full_height;
                    iFrameID.style.height = full_height;
                }
            }
        
            let iframe_id_list = []
            var iframes = document.getElementsByClassName("swagger-ui-iframe");
            for (var i = 0; i < iframes.length; i++) { 
                iframe_id_list.push(iframes[i].getAttribute("id"))
            }
        
            let ticking = true;
            
            document.addEventListener('scroll', function(e) {
                if (!ticking) {
                    window.requestAnimationFrame(()=> {
                        let half_vh = window.innerHeight/2;
                        for(var i = 0; i < iframe_id_list.length; i++) {
                            let element = document.getElementById(iframe_id_list[i])
                            if(element==null){
                                return
                            }
                            let diff = element.getBoundingClientRect().top
                            if(element.contentWindow.update_top_val){
                                element.contentWindow.update_top_val(half_vh - diff)
                            }
                        }
                        ticking = false;
                    });
                    ticking = true;
                }
            });
        
            const dark_scheme_name = "slate"
            
            window.scheme = document.body.getAttribute("data-md-color-scheme")
            const options = {
                attributeFilter: ['data-md-color-scheme'],
            };
            function color_scheme_callback(mutations) {
                for (let mutation of mutations) {
                    if (mutation.attributeName === "data-md-color-scheme") {
                        scheme = document.body.getAttribute("data-md-color-scheme")
                        var iframe_list = document.getElementsByClassName("swagger-ui-iframe")
                        for(var i = 0; i < iframe_list.length; i++) {
                            var ele = iframe_list.item(i);
                            if (ele) {
                                if (scheme === dark_scheme_name) {
                                    ele.contentWindow.enable_dark_mode();
                                } else {
                                    ele.contentWindow.disable_dark_mode();
                                }
                            }
                        }
                    }
                }
            }
            observer = new MutationObserver(color_scheme_callback);
            observer.observe(document.body, options);
            })</script></body>
</html>