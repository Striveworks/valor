{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Valor is a centralized evaluation store that makes it easy to measure, explore, and rank model performance. Valor empowers data scientists and engineers to evaluate the performance of their machine learning pipelines and use those evaluations to make better modeling decisions in the future. To skip this textual introduction and dive right in, first go here for instructions to setup the Valor service, and then checkout the sample notebooks.</p> <p>Valor is maintained by Striveworks, a cutting-edge machine learning operations (MLOps) company based out of Austin, Texas. We'd love to learn more about your interest in Valor and answer any questions you may have; please don't hesitate to reach out to us on Slack or GitHub.</p> <p>These docs are organized as follows:</p> <ul> <li>Overview (this page): Provides an overview of what Valor is, why it's important, and how it works.</li> <li>Installation: Explains how to install Valor.</li> <li>Basic Usage: Details everything you need to get up and running with using Valor.</li> <li>Sample Notebooks: Collection of descriptive Jupyter notebooks giving examples of how to evaluate model performance using Valor.</li> <li>Metadata and Filtering: Describes Valor's robust support for adding metadata to data, along with how to filter evaluations and Valor objects based on metadata and other attributes.</li> <li>Metrics: Describes all of the metrics that you can calculate using Valor.</li> <li>Endpoints: Documents Valor's various API endpoints.</li> <li>Technical Concepts: Describes the technical concepts that underpin Valor.</li> <li>Contributing and Development: Explains how you can build on and contribute to Valor.</li> <li>Python Client API: Shares reference documentation for our Python client.</li> </ul>"},{"location":"#overview","title":"Overview","text":"<p>In this section, we'll explore what Valor is, why it's important, and provide a high-level description of how it works. This overview is also available in the following five-minute video:</p>"},{"location":"#use-cases-for-a-containerized-evaluation-store","title":"Use Cases for a Containerized Evaluation Store","text":"<p>As we've worked with dozens of data scientists and engineers on their MLOps pipelines, we have identified three important questions that an effective evaluation store could help them answer. First, they wanted to understand: \"Of the various models I tested for a given dataset, which one performs best?\". This is a very common and important use case\u2014and one that is often solved on a model-to-model basis in a local Jupyter notebook. This focus on bespoke implementations limits traceability and makes it difficult to create apples-to-apples comparisons between new model runs and prior model runs.</p> <p>Second, our users wanted to understand: \"How does the performance of a particular model vary across datasets?\". We found that many practitioners use the same computer vision model (e.g., YOLOv8) for a variety of supervised learning tasks, and they needed a way to identify patterns where that particular model didn't meet expectations.</p> <p>Finally, our users wanted to understand: \"How can I use my prior evaluations to pick the best model for a future ML pipeline?\". This last question requires the ability to filter previous evaluations on granular metadata (e.g., time of day, geospatial coordinates, etc.) in order to provide tailored recommendations regarding which model to pick in the future.</p> <p>With these three use cases in mind, we set out to build a centralized evaluation store that we later named Valor.</p>"},{"location":"#introducing-valor","title":"Introducing Valor","text":"<p>Valor is a centralized evaluation store that makes it easy to measure, explore, and rank model performance. Our ultimate goal with Valor is to help data scientists and engineers pick the right ML model for their specific needs. To that end, we built Valor with three design principles in mind:</p> <ul> <li>Valor works with any dataset or model: We believe Valor should be able to handle any supervised learning task that you want to throw at it. Just pass in your ground truth annotations and predictions, describe your learning task (i.e., object detection), and Valor will do the rest. (Note: At launch, Valor will only support classification and computer vision (i.e., image segmentation and object detection) tasks. We're confident this framework will abstract well to other supervised learning tasks and plan to support them in later releases).</li> <li>Valor can handle any type of image, model, or dataset metadata you throw at it: Metadata is a critical component of any evaluation store as it enables the system to offer tailored model recommendations based on a user's specific needs. To that end, we built Valor to handle any metadata under the sun. Dates, geospatial coordinates, and even JSONs filled with configuration details are all on the table. This means you can slice and dice your evaluations any way you want: just pass in the right labels for your use case and define your filter (say a geographic bounding box), and you\u2019ll get back results for your specific needs.</li> <li>Valor standardizes the evaluation process: The trickiest part of comparing two different model runs is avoiding apples-to-oranges comparisons. Valor helps you audit your metrics and avoid false comparisons by versioning your uploads, storing them in a centralized location, and ensuring that you only compare runs that used the exact same filters and metrics.</li> </ul>"},{"location":"#how-it-works-an-illustrative-example","title":"How It Works: An Illustrative Example","text":"<p>Let\u2019s walk through a quick example to bring Valor to life.</p> <p>Say that you're interested in using computer vision models to detect forest fires around the world using satellite imagery. You've just been tasked with building a new ML pipeline to detect fires in an unfamiliar region of interest. How might you leverage your evaluation metrics from prior ML pipelines to understand which model will perform best for this particular use case?</p> <p></p> <p>To answer this question, we'll start by passing in three pieces of information from each of our prior modeling runs:</p> <ul> <li>GroundTruths: First, we'll pass in human-annotated bounding boxes to tell Valor exactly where forest fires can be found across all of the satellite images used in prior runs.</li> <li>Predictions: Next, we'll pass machine-generated predictions for each image (also in the form of bounding boxes) so that Valor can evaluate how well each model did at predicting forest fires.</li> <li>Labels: Finally, we'll pass metadata to Valor describing each of our various images (e.g., the time of day the photo was taken, the geospatial coordinates of the forest in the photo, etc.). We'll use this metadata later on in order to identify the right model for our new use case.</li> </ul> <p>Once we pass in these three ingredients, Valor will compare all of our <code>GroundTruths</code> and <code>Predictions</code> in order to calculate various evaluation metrics (i.e., mean average precision or mAP). These metrics, <code>Labels</code>, <code>GroundTruths</code>, and <code>Predictions</code>, will all be stored in Postgres, with PostGIS support for fast geospatial lookups and geometric comparisons at a later date.</p> <p>Finally, once all of our previous pipeline runs and evaluations are stored in Valor, we can use Valor\u2019s API to specify our exact filter criteria and get back its model rankings. In this case, we can ask Valor to find us the best model for detecting forest fires at night in a 50 mile radius around (42.36, -71.03), sorted by mAP. Valor will then filter all of our stored evaluation metrics, rank each model with evaluations that meet our criteria, and send back all relevant evaluation metrics to help us determine which model to use for our new modeling pipeline.</p> <p></p>"},{"location":"#next-steps","title":"Next Steps","text":"<p>To get started with Valor, we'd recommend reviewing our sample notebooks or reading our Getting Started docs. For more detailed explanations of Valor's technical underpinnings, see our technical concepts guide.</p>"},{"location":"#faq","title":"FAQ","text":"<p>Q. What is Valor?</p> <p>A. Valor is a centralized evaluation store that makes it easy to measure, explore, and rank model performance. For an overview of what Valor is and why it's important, please refer to our high-level overview.</p> <p>Q. What evaluation methods are supported?</p> <p>A. Valor currently supports generic classification as well as object-detection and semantic-segmentation for images. The long-term goal for Valor is to support the most popular supervised learning methods.</p> <p>Q. Does Valor store data?</p> <p>A. Valor only stores ground truth annotations, model predictions, and user-defined metadata.</p> <p>Q. What is a Datum?</p> <p>A. A <code>valor.Datum</code> object is a generic type that represents a datum in the context of a machine learning workflow. The object stores a UID and related metadata in a dictionary. This metadata allows for the user to construct their own abstraction layer by mapping a real-world type (e.g., an image) into a <code>valor.Datum</code> type.</p> <pre><code>from valor.metatypes import ImageMetadata\nimage = ImageMetadata(\n  uid = \"1234\",\n  height = 100,\n  width = 100,\n)\n\n# convert metatype to datum\ndatum = image.to_datum()\n</code></pre> <p>Q. What is a GroundTruth?</p> <p>A. <code>valor.GroundTruth</code> objects in Valor each represent a singular datum and its associated annotations that provide a reference standard or the 'truth' against which predictions are compared. There cannot be multiple ground truths per datum.</p> <p>Q. What is a Prediction?</p> <p>A. <code>valor.Prediction</code> objects are similar to <code>valor.GroundTruth</code> objects in that they also contain a list of annotations over a datum. However, these annotations are generated by a model as inferences, and the object also includes the name of the model that was used for creating these inferences. There cannot be multiple predictions by the same model over a single datum.</p> <p>Q. Can Valor handle multiple data types?</p> <p>A. Valor abstracts data types through metadata. An example of this can be seen in <code>valor.metatypes.ImageMetadata</code> which describes the mapping of an image to a <code>valor.Datum</code>.</p>"},{"location":"#troubleshooting","title":"Troubleshooting","text":"<p>Q. Why am I getting <code>NotFinalizedError</code> when trying to run an evaluation?</p> <p>A. Valor requires both dataset and model representations to be finalized before evaluation can take place. Finalization is crucial for auditability as it ensures that data finalized at a certain date is immutable.</p> <p>Dataset finalization is accomplished through the <code>valor.Dataset.finalize</code> member function.</p> <pre><code>from valor import Client, Dataset\nclient = Client(...)\ndataset = Dataset(name=\"test_dataset\")\n...\ndataset.finalize()\n</code></pre> <p>Models are finalized automatically given two conditions.</p> <ol> <li>The working dataset is finalized.</li> <li>There is a 1:1 mapping of predictions to ground truths.</li> </ol> <p>Models and their predictions can also be finalized prematurely using the <code>valor.Model.finalize_inferences</code> member function. This will generate empty predictions with task type <code>enums.TaskType.SKIP</code> to achieve the 1:1 ground truth mapping.</p> <pre><code>from valor import Client, Dataset, Model\nclient = Client(...)\ndataset = Dataset(name=\"test_dataset\")\nmodel = Model(name=\"test_model\")\n...\ndataset.finalize()\nmodel.finalize_inferences(dataset)\n</code></pre> <p>Q. Why am I getting GDAL driver errors?</p> <p>A. For some computations (mostly involving rasters), Valor requires the PostGIS database to have all GDAL drivers enabled. The Valor back end attempts to enable these drivers, but it might not have permission depending on your specific setup. If you encounter this error, see here for ways to enable the drivers directly in the PostGIS instance.</p>"},{"location":"basic_usage/","title":"Basic Usage","text":"<p>Valor is a centralized evaluation store that makes it easy to measure, explore, and rank model performance. For an overview of what Valor is and why it's important, please refer to our high-level overview.</p> <p>On this page, we'll describe the basic usage of Valor. For how to install Valor, please see our installation guide.</p> <p>There are two ways to access Valor: by leveraging our Python client (the typical way users of Valor will interact with the service), or by calling our REST endpoints directly (e.g. for integrating Valor into other services). This guide covers the former way of interacting with Valor. For the latter, please see our API endpoints documentation.</p>"},{"location":"basic_usage/#using-the-python-client","title":"Using the Python client","text":"<p>Let's walk through a hypothetical example where we're trying to classify dogs and cats in a series of images. Note that all of the code below is pseudo-code for clarity; please see our Getting Started notebook for a working example.</p>"},{"location":"basic_usage/#import-dependencies","title":"Import dependencies","text":"<p>Import basic objects directly from the client module using:</p> <pre><code>from valor import (\n    connect\n    Client,\n    Dataset,\n    Model,\n    Datum,\n    Annotation,\n    GroundTruth,\n    Prediction,\n    Label,\n)\nfrom valor.schemas import (\n    BoundingBox,\n    Polygon,\n    BasicPolygon,\n    Point,\n)\nfrom valor.enums import TaskType\n</code></pre>"},{"location":"basic_usage/#connect-to-the-client","title":"Connect to the Client","text":"<p>The <code>valor.Client</code> class gives an object that is used to communicate with the <code>valor</code> back end.</p> <pre><code>connect(\"http://0.0.0.0:8000\")\nclient = Client()\n</code></pre> <p>In the event that the host uses authentication, the argument <code>access_token</code> should also be passed to <code>Client</code>.</p>"},{"location":"basic_usage/#pass-your-ground-truths-into-valor","title":"Pass your ground truths into Valor","text":"<p>First, we define our <code>Dataset</code> object using <code>Dataset.create()</code>.</p> <pre><code>dataset = Dataset(\n    client=client,\n    name=\"myDataset\",\n    metadata={        # optional, metadata can take `str`, `int`, `float` value types.\n        \"some_string\": \"hello_world\",\n        \"some_number\": 1234,\n        \"a_different_number\": 1.234,\n    },\n    geospatial=None,  # optional, define a GeoJSON\n)\n</code></pre> <p>Next, we add one or more <code>GroundTruths</code> to our <code>Dataset</code>. These objects help Valor understand: \"What is the correct classification for this particular image?\".</p> <pre><code># We start with an example of what third-party annotations could look like.\n# img3.png contains a bounding box annotation with label \"dog\".\n# img4.png contains a bounding box annotation with label \"cat\"\n# img5.png contains no annotations\ngroundtruth_annotations = [\n    {\"path\": \"a/b/c/img3.png\", \"annotations\": [{\"class_label\": \"dog\", \"bbox\": {\"xmin\": 16, \"ymin\": 130, \"xmax\": 70, \"ymax\": 150}}, {\"class_label\": \"person\", \"bbox\": {\"xmin\": 89, \"ymin\": 10, \"xmax\": 97, \"ymax\": 110}}]},\n    {\"path\": \"a/b/c/img4.png\", \"annotations\": [{\"class_label\": \"cat\", \"bbox\": {\"xmin\": 500, \"ymin\": 220, \"xmax\": 530, \"ymax\": 260}}]},\n    {\"path\": \"a/b/c/img5.png\", \"annotations\": []}\n]\n\nfor image in groundtruth_annotations:\n\n    # each image is represented by a Valor Datum.\n    # this is used to connect ground truths and predictions when it's time for evaluation.\n    datum = Datum(\n        uid=Path(image[\"path\"]).stem, # strip the filename for use as Datum UID.\n        metadata={\n            \"path\": image[\"path\"],  # store the path in metadata\n        }\n    )\n\n    # a Valor Annotation consists of a task_type, labels, and, optionally, a geometry.\n    annotations = [\n        Annotation(\n            task_type=TaskType.OBJECT_DETECTION,\n            labels=[Label(key=\"class_label\", value=annotation[\"class_label\"])],\n            bounding_box=BoundingBox.from_extrema(\n                xmin=annotation[\"bbox\"][\"xmin\"],\n                xmax=annotation[\"bbox\"][\"xmax\"],\n                ymin=annotation[\"bbox\"][\"ymin\"],\n                ymax=annotation[\"bbox\"][\"ymax\"],\n            )\n        )\n        for annotation in image[\"annotations\"]\n        if len(annotation) &gt; 0\n    ]\n\n    # the datum and annotations we created are then used to form a GroundTruth.\n    groundtruth = GroundTruth(\n        datum=datum,\n        annotations=annotations,\n    )\n\n    # add it to your dataset\n    dataset.add_groundtruth(groundtruth)\n\n# now that we've added all our ground truths, we can finalize our dataset for evaluation\ndataset.finalize()\n</code></pre>"},{"location":"basic_usage/#pass-your-predictions-into-valor","title":"Pass your predictions into Valor","text":"<p>Now that we've passed several images of dogs into Valor, we need to pass in model predictions before we can evaluate whether those predictions were correct or not. To accomplish this task, we start by defining our <code>Model</code>:</p> <pre><code># create model\nmodel = Model(\n    client=client,\n    name=\"myModel\",\n    metadata={\n        \"foo\": \"bar\",\n        \"some_number\": 4321,\n    },\n    geospatial=None,\n)\n</code></pre> <p>Next, we tell Valor what our model predicted for each image by attaching <code>Predictions</code> to our <code>Model</code>:</p> <pre><code>def create_prediction_from_object_detection_dict(element: dict, datums_by_uid:dict) -&gt; Prediction:\n\n    # get datum from dataset using filename\n    uid=Path(element[\"path\"]).stem\n    groundtruth = dataset.get_groundtruth(uid)\n\n    # create Annotations\n    annotations = [\n        Annotation(\n            task_type=TaskType.OBJECT_DETECTION,\n            labels=[\n                Label(key=\"class_label\", value=label[\"class_label\"], score=label[\"score\"])\n                for label in annotation[\"labels\"]\n            ],\n            bounding_box=BoundingBox.from_extrema(\n                xmin=annotation[\"bbox\"][\"xmin\"],\n                xmax=annotation[\"bbox\"][\"xmax\"],\n                ymin=annotation[\"bbox\"][\"ymin\"],\n                ymax=annotation[\"bbox\"][\"ymax\"],\n            )\n        )\n        for annotation in element[\"annotations\"]\n        if len(annotation) &gt; 0\n    ]\n\n    # create and return Prediction\n    return Prediction(\n        datum=groundtruth.datum,\n        annotations=annotations,\n    )\n\n# let's represent the simulated model output in a similar format to the ground truths:\nobject_detections = [\n    {\"path\": \"a/b/c/img3.png\", \"annotations\": [\n        {\"labels\": [{\"class_label\": \"dog\", \"score\": 0.8}, {\"class_label\": \"cat\", \"score\": 0.1}, {\"class_label\": \"person\", \"score\": 0.1}], \"bbox\": {\"xmin\": 16, \"ymin\": 130, \"xmax\": 70, \"ymax\": 150}},\n        {\"labels\": [{\"class_label\": \"dog\", \"score\": 0.05}, {\"class_label\": \"cat\", \"score\": 0.05}, {\"class_label\": \"person\", \"score\": 0.9}], \"bbox\": {\"xmin\": 89, \"ymin\": 10, \"xmax\": 97, \"ymax\": 110}}\n    ]},\n    {\"path\": \"a/b/c/img4.png\", \"annotations\": [\n        {\"labels\": [{\"class_label\": \"dog\", \"score\": 0.8}, {\"class_label\": \"cat\", \"score\": 0.1}, {\"class_label\": \"person\", \"score\": 0.1}], \"bbox\": {\"xmin\": 500, \"ymin\": 220, \"xmax\": 530, \"ymax\": 260}}\n    ]},\n    {\"path\": \"a/b/c/img5.png\", \"annotations\": []}\n]\n\nfor element in object_detections:\n    # create prediction\n    prediction = create_prediction_from_object_detection_dict(element, datums_by_uid=datums_by_uid)\n\n    # add prediction to model\n    model.add_prediction(prediction)\n</code></pre>"},{"location":"basic_usage/#run-your-evaluation-and-print-metrics","title":"Run your evaluation and print metrics","text":"<p>Now that both our <code>Dataset</code> and <code>Model</code> are finalized, we can evaluate how well our hypothetical model performed.</p> <pre><code># run evaluation\nevaluation = model.evaluate_classification(\n    dataset=dataset,\n    filters=[\n        Annotation.labels.in_(\n            [\n                Label(key=\"class_label\", value=\"dog\"),\n                Label(key=\"class_label\", value=\"cat\"),\n            ]\n         # with this filter, we're asking Valor to only evaluate how well our model predicted cats and dogs in our images.\n    ]\n)\nevaluation.wait_for_completion() # wait for the job to finish\n\n# get the result of our evaluation\nresult = evaluation.get_result()\n\n# print our classification metrics\nprint(result.metrics)\n</code></pre>"},{"location":"basic_usage/#run-a-filtered-evaluation-and-print-metrics","title":"Run a filtered evaluation and print metrics","text":"<p>Valor offers more than just 1:1 evaluations; it allows the creation of metadata filters to stratify the dataset ground truths and model predictions. This enables the user to ask complex questions about their data.</p> <p>With this in mind, let's pose the question: \"How well did the model perform on animal prediction?\"</p> <p>We can ask this question with the following evaluation statement:</p> <pre><code># run evaluation\nanimal_evaluation = model.evaluate_classification(\n    dataset=dataset,\n    filters=[\n        # with this filter, we're asking Valor to only evaluate how well our model performed on predicting cats and dogs.\n        Annotation.labels.in_(\n            [\n                Label(key=\"class_label\", value=\"dog\"),\n                Label(key=\"class_label\", value=\"cat\"),\n            ]\n        ),\n    ]\n)\n\nanimal_evaluation.wait_for_completion() # wait for the job to finish\n\n# get the result of our evaluation\nresult = animal_evaluation.get_result()\n\n# print our classification metrics\nprint(result.metrics)\n</code></pre> <p>For more examples, please see our sample notebooks.</p>"},{"location":"basic_usage/#next-steps","title":"Next Steps","text":"<p>For more examples, we'd recommend reviewing our sample notebooks on GitHub. For more detailed explanations of Valor's technical underpinnings, see our technical concepts guide.</p>"},{"location":"contributing/","title":"Contributing to Valor","text":"<p>We welcome all contributions, bug reports, bug fixes, documentation improvements, enhancements, and ideas aimed at improving Valor. This doc describes the high-level process for how to contribute to this repository. If you have any questions or comments about this process, please feel free to reach out to us on Slack.</p>"},{"location":"contributing/#on-github","title":"On GitHub","text":"<p>We use Git on GitHub to manage this repo, which means you will need to sign up for a free GitHub account to submit issues, ideas, and pull requests. We use Git for version control to allow contributors from all over the world to work together on this project.</p> <p>If you are new to Git, these official resources can help bring you up to speed:</p> <ul> <li>GitHub documentation for forking a repo</li> <li>GitHub documentation for collaborating with pull requests</li> <li>GitHub documentation for working with forks</li> </ul>"},{"location":"contributing/#contribution-workflow","title":"Contribution Workflow","text":"<p>Generally, the high-level workflow for contributing to this repo includes:</p> <ol> <li>Submitting an issue or enhancement request using the appropriate template on GitHub Issues.</li> <li>Gathering feedback from devs and the broader community in your issue before starting to code.</li> <li>Forking the Valor repo, making your proposed changes, and submitting a pull request (PR). When submitting a PR, please be sure to:<ol> <li>Update the README.md and/or any relevant docstrings with details of your change.</li> <li>Add tests where necessary.</li> <li>Run <code>pre-commit install</code> on your local repo before your last commit to ensure your changes follow our formatting guidelines.</li> <li>Double-check that your code passes all of the tests that are automated via GitHub Actions.</li> <li>Ping us on Slack to ensure timely review.</li> </ol> </li> <li>Working with repo maintainers to review and improve your PR before it is merged into the official repo.</li> </ol> <p>For questions or comments on this process, please reach out to us at any time on Slack.</p>"},{"location":"contributing/#development-tips-and-tricks","title":"Development Tips and Tricks","text":""},{"location":"contributing/#deploying-the-back-end-for-development","title":"Deploying the Back End for Development","text":""},{"location":"contributing/#docker-compose","title":"Docker Compose","text":"<p>The fastest way to test the API and Python client is via Docker Compose. Start by setting the environment variable <code>POSTGRES_PASSWORD</code> to your liking, and then start Docker and build the container:</p> <pre><code>export POSTGRES_PASSWORD=\"my_password\"\ndocker compose up\n</code></pre>"},{"location":"contributing/#makefile-requires-docker","title":"Makefile (requires Docker)","text":"<p>Alternatively, you may want to run the API service from a terminal to enable faster debugging. To start the service, you can run:</p> <pre><code>pip install api # Install the API in your python environment\n\nexport POSTGRES_PASSWORD=password\nexport POSTGRES_HOST=localhost\nmake start-postgres-docker # Start the custom postgres service in Docker\nmake run-migrations # Instantiate the table schemas in Postgres\nmake start-server # Start the API service locally\n</code></pre>"},{"location":"contributing/#setting-up-your-environment","title":"Setting Up Your Environment","text":"<p>Creating a Valor-specific Python environment at the start of development can help you avoid dependency and versioning issues later on. To start, we'd recommend activating a new Python environment:</p> <pre><code># venv\npython3 -m venv .env-valor\nsource .env-valor/bin/activate\n\n# conda\nconda create --name valor python=3.11\nconda activate valor\n</code></pre> <p>Next, install pre-commit to ensure formatting consistency throughout your repo:</p> <pre><code>pip install pre-commit\npre-commit install\n</code></pre> <p>Finally, you're ready to install your client and API modules:</p> <pre><code># Install the Client module\npython -m pip install -e client/.\n\n# Install the API module\npython -m pip install -e api/.\n</code></pre>"},{"location":"contributing/#use-pgadmin-to-debug-postgis","title":"Use pgAdmin to Debug PostGIS","text":"<p>You can use the pgAdmin utility to debug your PostGIS tables as you code. Start by installing pgAdmin, and then select <code>Object &gt; Register &gt; Server</code> to connect to your PostGIS container. The default connection details are listed below for convenience:</p> <pre><code>- *Host name/address*: 0.0.0.0\n- *Port*: 5432\n- *Maintenance database*: postgres\n- *Username*: postgres\n</code></pre>"},{"location":"contributing/#running-tests","title":"Running Tests","text":"<p>All of our tests are run automatically via GitHub Actions on every push, so it's important to double-check that your code passes all local tests before committing your code. All of the tests below require <code>pytest</code>:</p> <pre><code>pip install pytest\n</code></pre>"},{"location":"contributing/#running-integration-tests","title":"Running integration tests","text":"<pre><code>pytest integration_tests\n</code></pre>"},{"location":"contributing/#running-back-end-unit-tests","title":"Running back end unit tests","text":"<pre><code>pytest api/tests/unit-tests\n</code></pre>"},{"location":"contributing/#running-back-end-functional-tests","title":"Running back end functional tests","text":"<p>Note: Functional tests require a running instance of PostgreSQL, which you can start using <code>make start-postgres-docker</code>.</p> <pre><code>POSTGRES_PASSWORD=password \\\nPOSTGRES_HOST=localhost \\\npytest api/tests/functional-tests/\n</code></pre>"},{"location":"endpoints/","title":"Endpoints","text":""},{"location":"installation/","title":"Installation","text":"<p>Valor comprises two services: a back-end service (which consists of a REST API and a Postgres database with the PostGIS extension), and a Python client for interacting with the back-end service.</p>"},{"location":"installation/#setting-up-the-back-end-service","title":"Setting up the back-end service","text":""},{"location":"installation/#using-docker-compose","title":"Using Docker Compose","text":"<p>The easiest way to get up and running with Valor is to use Docker Compose with the <code>docker-compose.yml</code> file in the repository root:</p> <pre><code>git clone https://github.com/striveworks/valor\ncd valor\ndocker compose --env-file ./api/.env.testing up\n</code></pre> <p>This will set up the necessary environment variables, start both the API and database services, and run the database migration job. The endpoint <code>localhost:8000/health</code> should return <code>{\"status\":\"ok\"}</code> if all of Valor's services were started correctly.</p> <p>Note: running Valor this way is not intended for production and scalable use and is only recommended for development and testing purposes.</p>"},{"location":"installation/#deploying-via-docker-and-a-hosted-database","title":"Deploying via Docker and a hosted database","text":"<p>For a more production-grade deployment, we publish the images <code>ghcr.io/striveworks/valor/valor-service</code> (used for the REST API) and <code>ghcr.io/striveworks/valor/migrations</code> (used for setting up the database and migrations). These can be paired with any Postgres database with the PostGIS extension.</p> <p>The following environment variables are required for running these images:</p> Variable Description Images that need it <code>POSTGRES_HOST</code> The host of the Postgres database <code>valor-service</code>, <code>migrations</code> <code>POSTGRES_PORT</code> The port of the Postgres database <code>valor-service</code>, <code>migrations</code> <code>POSTGRES_DB</code> The name of the Postgres database <code>valor-service</code>, <code>migrations</code> <code>POSTGRES_USERNAME</code> The user of the Postgres database <code>valor-service</code>, <code>migrations</code> <code>POSTGRES_PASSWORD</code> The password of the Postgres database <code>valor-service</code>, <code>migrations</code> <code>POSTGRES_SSLMODE</code> Sets the Postgres instance SSL mode (typically needs to be \"require\") <code>migrations</code> <code>API_ROOT_PATH</code> The root path of the API (if serving behind a proxy) <code>valor-service</code> <p>Additionally, the Valor REST API has an optional single username/password/bearer token authentication. To enable this feature, the <code>valor-service</code> image requires the following environment variables:</p> Variable Description <code>VALOR_USERNAME</code> The username to use <code>VALOR_PASSWORD</code> The password to use <code>VALOR_SECRET_KEY</code> A random, secret string used for signing JWT tokens"},{"location":"installation/#helm-chart","title":"Helm chart","text":"<p>Alternatively, we provide pre-built charts for deploying Valor on Kubernetes via Helm using the following commands:</p> <pre><code>helm repo add valor https://striveworks.github.io/valor-charts/\nhelm install valor valor/valor\n# Valor should now be available at valor.namespace.svc.local\n</code></pre>"},{"location":"installation/#manual-deployment","title":"Manual deployment","text":"<p>If you would prefer to build your own image or if you want a debug console for the back-end, please see the deployment instructions in Contributing to Valor.</p>"},{"location":"installation/#setting-up-the-python-client","title":"Setting up the Python client","text":"<p>The Python client can be installed via pip:</p> <pre><code>pip install valor-client\n</code></pre>"},{"location":"metadata_and_filtering/","title":"Metadata and Filtering","text":""},{"location":"metadata_and_filtering/#metadata","title":"Metadata","text":"<p>Valor offers rich support for attaching metadata to almost any object, which can then be used to filter, group, and organize objects in Valor.</p> <p>The metadata types supported are:</p> <ul> <li>simple data types (strings, numerics, boolean)</li> <li>datetimes (via <code>datetime.datetime</code>, <code>datetime.date</code>, <code>datetime.time</code>, and <code>datetime.timedelta</code> in the Valor client)</li> <li>geometries and geographies (via GeoJSON)</li> </ul> <p>Metadata is added on object creation. For example, if you want to use metadata to organize models that come from training run checkpoints, this may look like:</p> <pre><code>run_name: str\nckpt: int\n\nModel.create(name=f\"{run_name}-ckpt{ckpt}\", metadata={\"run_name\": run_name, \"ckpt\": ckpt})\n</code></pre> <p>or if a datum has an associated datetime of capture, that can be added in the creation stage:</p> <pre><code>from datetime import datetime\n\nDatum(uid=fname, metadata={\"capture_day\": datetime.datetime(day=1, month=1, year=2021)})\n</code></pre>"},{"location":"metadata_and_filtering/#filtering","title":"Filtering","text":"<p>Valor supports filtering objects based on metadata or other attributes (such as labels or bounding boxes). One of the most important use cases of filtering is to define a subset of a dataset to evaluate a model on.</p>"},{"location":"metadata_and_filtering/#filtering-by-metadata","title":"Filtering by metadata","text":"<p>For example, using the above example where <code>capture_day</code> was added as metadata, one way to test model drift could be to evaluate the model over different time periods. Such a workflow may look like:</p> <pre><code>import datetime\n\nimport valor\n\nmodel: valor.Model # classification model\ndset: valor.Dataset # dataset to evaluate on\n\n# compare performance on data captured before and after 2020\nd = datetime.datetime(day=5, month=10, year=2020)\neval1 = model.evaluate_classification(dset, filter_by=[Datum.metadata[\"capture_day\"] &lt; d])\neval2 = model.evaluate_classification(dset, filter_by=[Datum.metadata[\"capture_day\"] &gt; d])\n</code></pre>"},{"location":"metadata_and_filtering/#filtering-by-geometric-attributes","title":"Filtering by geometric attributes","text":"<p>As an example for filtering by geometric attributes, consider evaluating an object detection model's performance on small objects, where we define small as being less than 500 square pixels in area. This can be achieved via:</p> <pre><code>import valor\n\nmodel: valor.Model # object detection model\ndset: valor.Dataset # dataset to evaluate on\n\ndset.evaluate_detection(dset, filter_by=[valor.Annotation.bounding_box.area &lt; 500])\n</code></pre>"},{"location":"metadata_and_filtering/#filtering-in-queries","title":"Filtering in queries","text":"<p>Filtering can also be used when querying for different objects. For example, taking the model section checkpoint example from above, we could query model checkpoints from a training run based on the checkpoint number greater than 100 by:</p> <pre><code>from valor import client\n\nrun_name: str # run name to query for\n\nclient.get_models([Model.metadata[\"run_name\"] == run_name, Model.metadata[\"ckpt\"] &gt; 100])\n</code></pre>"},{"location":"metrics/","title":"Metrics","text":"<p>Let's look at the various metrics you can calculate using Valor.</p> <p>If we're missing an important metric for your particular use case, please write us a GitHub Issue ticket. We love hearing your suggestions.</p>"},{"location":"metrics/#classification-metrics","title":"Classification Metrics","text":"Name Description Equation Precision The number of true positives divided by the total number of positive predictions (i.e., the number of true positives plus the number of false positives). \\(\\dfrac{\\|TP\\|}{\\|TP\\|+\\|FP\\|}\\) Recall The number of true positives divided by the total count of the class of interest (i.e., the number of true positives plus the number of true negatives). \\(\\dfrac{\\|TP\\|}{\\|TP\\|+\\|FN\\|}\\) F1 A weighted average of precision and recall. \\(\\frac{2 * Precision * Recall}{Precision + Recall}\\) Accuracy The number of true predictions divided by the total number of predictions. \\(\\dfrac{\\|TP\\|+\\|TN\\|}{\\|TP\\|+\\|TN\\|+\\|FP\\|+\\|FN\\|}\\) ROC AUC The area under the Receiver Operating Characteristic (ROC) curve for the predictions generated by a given model. See ROCAUC methods."},{"location":"metrics/#object-detection-and-instance-segmentation-metrics","title":"Object Detection and Instance Segmentation Metrics**","text":"Name Description Equation Average Precision (AP) The weighted mean of precisions achieved at several different recall thresholds for a single Intersection over Union (IOU), grouped by class. See AP methods. AP Averaged Over IOUs The average of several AP metrics across IOU thresholds, grouped by class labels. \\(\\dfrac{1}{\\text{number of thresholds}} \\sum\\limits_{iou \\in thresholds} AP_{iou}\\) Mean Average Precision (mAP) The average of several AP metrics across class labels, grouped by IOU thresholds. \\(\\dfrac{1}{\\text{number of classes}} \\sum\\limits_{c \\in classes} AP_{c}\\) mAP Averaged Over IOUs The average of several  mAP metrics across class labels. \\(\\dfrac{1}{\\text{number of thresholds}} \\sum\\limits_{iou \\in thresholds} mAP_{iou}\\) Average Recall (AR) The average of several recall metrics across IOU thresholds, grouped by class labels. See AR methods. Mean Average Recall (mAR) The average of several AR metrics across class labels. \\(\\dfrac{1}{\\text{number of classes}} \\sum\\limits_{class \\in classes} AR_{class}\\) <p>**When calculating IOUs for object detection metrics, Valor handles the necessary conversion between different types of geometric annotations. For example, if your model prediction is a polygon and your groundtruth is a raster, then the raster will be converted to a polygon prior to calculating the IOU.</p>"},{"location":"metrics/#semantic-segmentation-metrics","title":"Semantic Segmentation Metrics","text":"Name Description Equation Intersection Over Union (IOU) A ratio between the groundtruth and predicted regions of an image, measured as a percentage, grouped by class. \\(\\dfrac{area( prediction \\cap groundtruth )}{area( prediction \\cup groundtruth )}\\) Mean IOU The average of IOUs, calculated over several different classes. \\(\\dfrac{1}{\\text{number of classes}} \\sum\\limits_{c \\in classes} IOU_{c}\\)"},{"location":"metrics/#appendix-metric-calculations","title":"Appendix: Metric Calculations","text":""},{"location":"metrics/#binary-roc-auc","title":"Binary ROC AUC","text":""},{"location":"metrics/#receiver-operating-characteristic-roc","title":"Receiver Operating Characteristic (ROC)","text":"<p>An ROC curve plots the True Positive Rate (TPR) vs. the False Positive Rate (FPR) at different confidence thresholds.</p> <p>In Valor, we use the confidence scores sorted in decreasing order as our thresholds. Using these thresholds, we can calculate our TPR and FPR as follows:</p>"},{"location":"metrics/#determining-the-rate-of-correct-predictions","title":"Determining the Rate of Correct Predictions","text":"Element Description True Positive (TP) Prediction confidence score &gt;= threshold and is correct. False Positive (FP) Prediction confidence score &gt;= threshold and is incorrect. True Negative (TN) Prediction confidence score &lt; threshold and is correct. False Negative (FN) Prediction confidence score &lt; threshold and is incorrect. <ul> <li> <p>\\(\\text{True Positive Rate (TPR)} = \\dfrac{|TP|}{|TP| + |FN|} = \\dfrac{|TP(threshold)|}{|TP(threshold)| + |FN(threshold)|}\\)</p> </li> <li> <p>\\(\\text{False Positive Rate (FPR)} = \\dfrac{|FP|}{|FP| + |TN|} = \\dfrac{|FP(threshold)|}{|FP(threshold)| + |TN(threshold)|}\\)</p> </li> </ul> <p>We now use the confidence scores, sorted in decreasing order, as our thresholds in order to generate points on a curve.</p> <p>\\(Point(score) = (FPR(score), \\ TPR(score))\\)</p>"},{"location":"metrics/#area-under-the-roc-curve-roc-auc","title":"Area Under the ROC Curve (ROC AUC)","text":"<p>After calculating the ROC curve, we find the ROC AUC metric by approximating the integral using the trapezoidal rule formula.</p> <p>\\(ROC AUC =  \\sum_{i=1}^{|scores|} \\frac{  \\lVert Point(score_{i-1}) - Point(score_i) \\rVert }{2}\\)</p> <p>See Classification: ROC Curve and AUC for more information.</p>"},{"location":"metrics/#average-precision-ap","title":"Average Precision (AP)","text":"<p>For object detection and instance segmentation tasks, average precision is calculated from the intersection-over-union (IOU) of geometric predictions and ground truths.</p>"},{"location":"metrics/#multiclass-precision-and-recall","title":"Multiclass Precision and Recall","text":"<p>Tasks that predict geometries (such as object detection or instance segmentation) use the ratio intersection-over-union (IOU) to calculate precision and recall. IOU is the ratio of the intersecting area over the joint area spanned by the two geometries, and is defined in the following equation.</p> <p>\\(Intersection \\ over \\ Union \\ (IOU) = \\dfrac{Area( prediction \\cap groundtruth )}{Area( prediction \\cup groundtruth )}\\)</p> <p>Using different IOU thresholds, we can determine whether we count a pairing between a prediction and a ground truth pairing based on their overlap.</p> Case Description True Positive (TP) Prediction-GroundTruth pair exists with IOU &gt;= threshold. False Positive (FP) Prediction-GroundTruth pair exists with IOU &lt; threshold. True Negative (TN) Unused in multi-class evaluation. False Negative (FN) No Prediction with a matching label exists for the GroundTruth. <ul> <li> <p>\\(Precision = \\dfrac{|TP|}{|TP| + |FP|} = \\dfrac{\\text{Number of True Predictions}}{|\\text{Predictions}|}\\)</p> </li> <li> <p>\\(Recall = \\dfrac{|TP|}{|TP| + |FN|} = \\dfrac{\\text{Number of True Predictions}}{|\\text{Groundtruths}|}\\)</p> </li> </ul>"},{"location":"metrics/#matching-ground-truths-with-predictions","title":"Matching Ground Truths with Predictions","text":"<p>To properly evaluate a detection, we must first find the best pairings of predictions to ground truths. We start by iterating over our predictions, ordering them by highest scores first. We pair each prediction with the ground truth that has the highest calculated IOU. Both the prediction and ground truth are now considered paired and removed from the pool of choices.</p> <pre><code>def rank_ious(\n    groundtruths: list,\n    predictions: list,\n) -&gt; list[float]:\n    \"\"\"Ranks ious by unique pairings.\"\"\"\n\n    retval = []\n    groundtruths = set(groundtruths)\n    for prediction in sorted(predictions, key=lambda x : -x.score):\n        groundtruth = max(groundtruths, key=lambda x : calculate_iou(groundtruth, prediction))\n        groundtruths.remove(groundtruth)\n        retval.append(calculate_iou(groundtruth, prediction))\n</code></pre>"},{"location":"metrics/#precision-recall-curve","title":"Precision-Recall Curve","text":"<p>We can now compute the precision-recall curve using our previously ranked IOU's. We do this by iterating through the ranked IOU's and creating points cumulatively using recall and precision.</p> <pre><code>def create_precision_recall_curve(\n    number_of_groundtruths: int,\n    ranked_ious: list[float],\n    threshold: float\n) -&gt; list[tuple[float, float]]:\n    \"\"\"Creates the precision-recall curve from a list of IOU's and a threshold.\"\"\"\n\n    retval = []\n    count_tp = 0\n    for i in range(ranked_ious):\n        if ranked_ious[i] &gt;= threshold:\n            count_tp += 1\n        precision = count_tp / (i + 1)\n        recall = count_tp / number_of_groundtruths\n        retval.append((recall, precision))\n</code></pre>"},{"location":"metrics/#calculating-average-precision","title":"Calculating Average Precision","text":"<p>Average precision is defined as the area under the precision-recall curve.</p> <p>We will use a 101-point interpolation of the curve to be consistent with the COCO evaluator. The intent behind interpolation is to reduce the fuzziness that results from ranking pairs.</p> <p>\\(AP = \\frac{1}{101} \\sum\\limits_{r\\in\\{ 0, 0.01, \\ldots , 1 \\}}\\rho_{interp}(r)\\)</p> <p>\\(\\rho_{interp} = \\underset{\\tilde{r}:\\tilde{r} \\ge r}{max \\ \\rho (\\tilde{r})}\\)</p>"},{"location":"metrics/#references","title":"References","text":"<ul> <li>MS COCO Detection Evaluation</li> <li>The PASCAL Visual Object Classes (VOC) Challenge</li> <li>Mean Average Precision (mAP) Using the COCO Evaluator</li> </ul>"},{"location":"metrics/#average-recall-ar","title":"Average Recall (AR)","text":"<p>To calculate Average Recall (AR), we:</p> <ol> <li>Find the count of true positives above specified IOU and confidence thresholds for all images containing a ground truth of a particular class.</li> <li>Divide that count of true positives by the total number of ground truths to get the recall value per class and IOU threshold. Append that recall value to a list.</li> <li>Repeat steps 1 &amp; 2 for multiple IOU thresholds (e.g., [.5, .75])</li> <li>Take the average of our list of recalls to arrive at the AR value per class.</li> </ol> <p>Note that this metric differs from COCO's calculation in two ways:</p> <ul> <li>COCO averages across classes while calculating AR, while we calculate AR separately for each class. Our AR calculations matches the original FAIR definition of AR, while our mAR calculations match what COCO calls AR.</li> <li>COCO calculates three different AR metrics (AR@1, AR@5, AR@100)) by considering only the top 1/5/100 most confident predictions during the matching process. Valor, on the other hand, allows users to input a <code>recall_score_threshold</code> value that will prevent low-confidence predictions from being counted as true positives when calculating AR.</li> </ul>"},{"location":"technical_concepts/","title":"Technical Concepts","text":"<p>On this page, we'll describe many of the technical concepts underpinning Valor.</p>"},{"location":"technical_concepts/#high-level-workflow","title":"High-Level Workflow","text":"<p>The typical Valor workflow involves POSTing ground truth annotations (e.g., class labels, bounding boxes, segmentation masks, etc.) and model predictions to our API service. The service leverages these ground truths and predictions to compute evaluation metrics, and then stores the ground truths, predictions, and evaluation metrics centrally in Postgres. Users can also attach metadata to their <code>Datasets</code>, <code>Models</code>, <code>GroundTruths</code>, and <code>Annotations</code>; this metadata makes it easy to query for specific subsets of evaluations at a later date. Once an evaluation is stored in Valor, users can query those evaluations from Postgres via <code>GET</code> requests to the Valor API.</p> <p>Note that Valor does not store raw data (such as underlying images) or facilitate model inference. Only the following items are stored in Postgres:</p> <ul> <li>Ground truth annotations</li> <li>Predictions outputted from a model</li> <li>Metadata from any of Valor's various classes</li> <li>Evaluation metrics computed by Valor</li> <li>State related to any of the above</li> </ul>"},{"location":"technical_concepts/#supported-task-types","title":"Supported Task Types","text":"<p>As of January 2024, Valor supports the following types of supervised learning tasks and associated metrics:</p> <ul> <li>Classification (including multi-label classification)</li> <li>F1</li> <li>ROC AUC</li> <li>Accuracy</li> <li>Precision</li> <li>Recall</li> <li>Object detection</li> <li>AP</li> <li>mAP</li> <li>AP Averaged Over IOUs</li> <li>mAP Averaged Over IOUs</li> <li>Segmentation (including both instance and semantic segmentation)</li> <li>IOU</li> <li>mIOU</li> </ul> <p>For descriptions of each of these metrics, see our Metrics page.</p> <p>We expect the Valor framework to extend well to other types of supervised learning tasks and plan to expand our supported task types in future releases.</p>"},{"location":"technical_concepts/#components","title":"Components","text":"<p>We can think of Valor in terms of four orthogonal components:</p>"},{"location":"technical_concepts/#api","title":"API","text":"<p>The core of Valor is a back end REST API service. Users can call the API's endpoints directly (e.g., <code>POST /datasets</code>), or they can use our Python client to handle the API calls in their Python environment. All of Valor's state is stored in Postgres; the API itself is completely stateless.</p> <p>Note that, after you start the API service in Dockers, you'll be able to view FastAPI's automatically generated API documentation at <code>https://&lt;your host&gt;/docs</code>.</p>"},{"location":"technical_concepts/#postgresql","title":"PostgreSQL","text":"<p>PostgreSQL (a.k.a. Postgres or psql) is an open-source relational database management system. We use Postgres to store all of Valor's various objects and states.</p> <p>One of the most important reasons we chose Postgres was its PostGIS extension, which adds support for storing, indexing, and querying geographic data. PostGIS enables Valor to quickly filter prior evaluations using geographic coordinates, which is a critically important feature for any computer vision task involving satellite data.</p>"},{"location":"technical_concepts/#python-client","title":"Python Client","text":"<p>Finally, we created a client to make it easier for our users to play with Valor from their Python environment. All of Valor's validations and computations are handled by our API; the Python client simply provides convenient methods to call the API's endpoints.</p>"},{"location":"technical_concepts/#classes","title":"Classes","text":"<p>The Valor API and Python client both make use of six core classes:</p>"},{"location":"technical_concepts/#dataset","title":"<code>Dataset</code>","text":"<p>The highest-level class is a <code>Dataset</code>, which stores metadata and annotations associated with a particular set of data. Note that <code>Dataset</code> is an abstraction: You can have multiple <code>Datasets</code> that reference the exact same input data, which is useful if you need to update or version your data over time.</p> <p><code>Datasets</code> require a name at instantiation and can optionally take in various types of metadata that you want to associate with your data.</p>"},{"location":"technical_concepts/#model","title":"<code>Model</code>","text":"<p><code>Models</code> describe a particular instantiation of a machine learning model. We use the <code>Model</code> object to delineate between different model runs or between the same model run over time. Note that <code>Models</code> aren't children of <code>Datasets</code>; you can have one <code>Model</code> contain predictions for multiple <code>Datasets</code>.</p> <p><code>Models</code> require a name at instantiation and can optionally take in various types of metadata that you want to associate with your model.</p>"},{"location":"technical_concepts/#groundtruth","title":"<code>GroundTruth</code>","text":"<p>A <code>GroundTruth</code> object clarifies what the correct prediction should be for a given piece of data (e.g., an image). For an object detection task, for example, the <code>GroundTruth</code> would store a human-drawn bounding box that, when overlayed on an object, would correctly enclose the object that we're trying to predict.</p> <p><code>GroundTruths</code> take one <code>Datum</code> and a list of <code>Annotations</code> as arguments.</p>"},{"location":"technical_concepts/#prediction","title":"<code>Prediction</code>","text":"<p>A <code>Prediction</code> object describes the output of a machine learning model. For an object detection task, for example, the <code>Prediction</code> would describe a machine-generated bounding box enclosing the area where a computer vision model believes a certain class of object can be found.</p> <p><code>Predictions</code> take one <code>Datum</code> and a list of <code>Annotations</code> as arguments.</p>"},{"location":"technical_concepts/#datum","title":"<code>Datum</code>","text":"<p><code>Datums</code> are used to store metadata about <code>GroundTruths</code> or <code>Predictions</code>. This metadata can include user-supplied metadata (e.g., JSONs filled with configuration details) or geospatial coordinates (via the <code>geospatial</code> argument). <code>Datums</code> provide the vital link between <code>GroundTruths</code> / <code>Predictions</code> and <code>Datasets</code>, and they are useful when filtering your evaluations on specific conditions.</p> <p>A <code>Datum</code> requires a universal ID (UID) and dataset name at instantiation, along with any <code>metadata</code> or <code>geospatial</code> dictionaries that you want to associate with your <code>GroundTruth</code> or <code>Prediction</code>.</p>"},{"location":"technical_concepts/#annotation","title":"<code>Annotation</code>","text":"<p><code>Annotations</code> attach to both <code>GroundTruths</code> and <code>Predictions</code>, enabling users to add textual labels to these objects. If a <code>GroundTruth</code> depicts a bounding box around a cat, for example, the <code>Annotation</code> would be passed into the <code>GroundTruth</code> to clarify the correct label for the <code>GroundTruth</code> (e.g., <code>class=cat</code>) and any other labels the user wants to specify for that bounding box (e.g., <code>breed=tabby</code>).</p> <p><code>Annotations</code> require the user to specify their task type, labels, and metadata at instantiation. Users can also pass in various visual representations tailored to their specific task, such as bounding boxes, segmentations, or image rasters.</p>"},{"location":"technical_concepts/#authentication","title":"Authentication","text":"<p>The API can be run without authentication (by default), or with authentication with a single global username and password. To set this up, set the following environment variables when running the back end:</p> <ul> <li>Set the environment variables <code>VALOR_SECRET_KEY</code>, <code>VALOR_USERNAME</code>, and <code>VALOR_PASSWORD</code> manually (e.g., <code>export SECRET_KEY=&lt;secret key&gt;</code>)</li> <li>Set these environment variables in a file named <code>.env.auth</code>, and place that file in the <code>api</code> directory. An example of such a file would look like:</li> </ul> <pre><code>VALOR_SECRET_KEY=\"secret key\"\nVALOR_USERNAME=\"username\"\nVALOR_PASSWORD=\"password\"\n</code></pre> <p><code>VALOR_SECRET_KEY</code> is the key used for encoding and decoding tokens, and should be a random string. <code>VALOR_USERNAME</code> and <code>VALOR_PASSWORD</code> are the username and password that will be used to authenticate requests.</p> <p>You can use the tests in <code>integration_tests/test_client_auth.py</code> to check whether your authenticator is running correctly.</p>"},{"location":"technical_concepts/#deployment-settings","title":"Deployment Settings","text":"<p>When deploying behind a proxy or with external routing, the <code>API_ROOT_PATH</code> environment variable should be used to set the <code>root_path</code> argument to <code>fastapi.FastAPI</code> (see https://fastapi.tiangolo.com/advanced/behind-a-proxy/#setting-the-root_path-in-the-fastapi-app).</p>"},{"location":"technical_concepts/#release-process","title":"Release Process","text":"<p>A release is made by publishing a tag of the form <code>vX.Y.Z</code> (e.g., <code>v0.1.0</code>). This will trigger a GitHub action that will build and publish the Python client to PyPI. These releases should be created using the GitHub UI.</p>"},{"location":"client_api/Annotation/","title":"Annotation","text":"<p>A class used to annotate <code>GroundTruths</code> and <code>Predictions</code>.</p> <p>Parameters:</p> Name Type Description Default <code>task_type</code> <code>TaskType</code> <p>The task type associated with the <code>Annotation</code>.</p> required <code>labels</code> <code>Optional[List[Label]]</code> <p>A list of labels to use for the <code>Annotation</code>.</p> <code>None</code> <code>metadata</code> <code>Optional[MetadataType]</code> <p>A dictionary of metadata that describes the <code>Annotation</code>.</p> <code>None</code> <code>bounding_box</code> <code>Optional[BoundingBox]</code> <p>A bounding box to assign to the <code>Annotation</code>.</p> <code>None</code> <code>polygon</code> <code>Optional[Polygon]</code> <p>A polygon to assign to the <code>Annotation</code>.</p> <code>None</code> <code>multipolygon</code> <code>Optional[MultiPolygon]</code> <p>A multipolygon to assign to the <code>Annotation</code>.</p> <code>None</code> <code>raster</code> <code>Optional[Raster]</code> <p>A raster to assign to the <code>Annotation</code>.</p> <code>None</code> <code>embedding</code> <code>Optional[List[float]]</code> <p>An embedding, described by a list of values with type float and a maximum length of 16,000.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>geometric_area</code> <code>float</code> <p>The area of the annotation.</p> <p>Examples:</p> <p>Classification</p> <pre><code>&gt;&gt;&gt; Annotation(\n...     task_type=TaskType.CLASSIFICATION,\n...     labels=[\n...         Label(key=\"class\", value=\"dog\"),\n...         Label(key=\"category\", value=\"animal\"),\n...     ]\n... )\n</code></pre> <p>Object-Detection BoundingBox</p> <pre><code>&gt;&gt;&gt; annotation = Annotation(\n...     task_type=TaskType.OBJECT_DETECTION,\n...     labels=[Label(key=\"k1\", value=\"v1\")],\n...     bounding_box=box2,\n... )\n</code></pre> <p>Object-Detection Polygon</p> <pre><code>&gt;&gt;&gt; annotation = Annotation(\n...     task_type=TaskType.OBJECT_DETECTION,\n...     labels=[Label(key=\"k1\", value=\"v1\")],\n...     polygon=polygon1,\n... )\n</code></pre> <p>Object-Detection Mulitpolygon</p> <pre><code>&gt;&gt;&gt; annotation = Annotation(\n...     task_type=TaskType.OBJECT_DETECTION,\n...     labels=[Label(key=\"k1\", value=\"v1\")],\n...     multipolygon=multipolygon,\n... )\n</code></pre> <p>Object-Detection Raster</p> <pre><code>&gt;&gt;&gt; annotation = Annotation(\n...     task_type=TaskType.OBJECT_DETECTION,\n...     labels=[Label(key=\"k1\", value=\"v1\")],\n...     raster=raster1,\n... )\n</code></pre> <p>Semantic-Segmentation Raster</p> <pre><code>&gt;&gt;&gt; annotation = Annotation(\n...     task_type=TaskType.SEMANTIC_SEGMENTATION,\n...     labels=[Label(key=\"k1\", value=\"v1\")],\n...     raster=raster1,\n... )\n</code></pre> <p>Defining all supported annotation types for a given <code>task_type</code> is allowed!</p> <pre><code>&gt;&gt;&gt; Annotation(\n...     task_type=TaskType.OBJECT_DETECTION,\n...     labels=[Label(key=\"k1\", value=\"v1\")],\n...     bounding_box=box1,\n...     polygon=polygon1,\n...     multipolygon=multipolygon,\n...     raster=raster1,\n... )\n</code></pre> Source code in <code>valor/coretypes.py</code> <pre><code>class Annotation:\n    \"\"\"\n    A class used to annotate `GroundTruths` and `Predictions`.\n\n    Parameters\n    ----------\n    task_type: TaskType\n        The task type associated with the `Annotation`.\n    labels: List[Label], optional\n        A list of labels to use for the `Annotation`.\n    metadata: Dict[str, Union[int, float, str, bool, datetime.datetime, datetime.date, datetime.time]]\n        A dictionary of metadata that describes the `Annotation`.\n    bounding_box: BoundingBox, optional\n        A bounding box to assign to the `Annotation`.\n    polygon: Polygon, optional\n        A polygon to assign to the `Annotation`.\n    multipolygon: MultiPolygon, optional\n        A multipolygon to assign to the `Annotation`.\n    raster: Raster, optional\n        A raster to assign to the `Annotation`.\n    embedding: List[float], optional\n        An embedding, described by a list of values with type float and a maximum length of 16,000.\n\n    Attributes\n    ----------\n    geometric_area : float\n        The area of the annotation.\n\n    Examples\n    --------\n\n    Classification\n    &gt;&gt;&gt; Annotation(\n    ...     task_type=TaskType.CLASSIFICATION,\n    ...     labels=[\n    ...         Label(key=\"class\", value=\"dog\"),\n    ...         Label(key=\"category\", value=\"animal\"),\n    ...     ]\n    ... )\n\n    Object-Detection BoundingBox\n    &gt;&gt;&gt; annotation = Annotation(\n    ...     task_type=TaskType.OBJECT_DETECTION,\n    ...     labels=[Label(key=\"k1\", value=\"v1\")],\n    ...     bounding_box=box2,\n    ... )\n\n    Object-Detection Polygon\n    &gt;&gt;&gt; annotation = Annotation(\n    ...     task_type=TaskType.OBJECT_DETECTION,\n    ...     labels=[Label(key=\"k1\", value=\"v1\")],\n    ...     polygon=polygon1,\n    ... )\n\n    Object-Detection Mulitpolygon\n    &gt;&gt;&gt; annotation = Annotation(\n    ...     task_type=TaskType.OBJECT_DETECTION,\n    ...     labels=[Label(key=\"k1\", value=\"v1\")],\n    ...     multipolygon=multipolygon,\n    ... )\n\n    Object-Detection Raster\n    &gt;&gt;&gt; annotation = Annotation(\n    ...     task_type=TaskType.OBJECT_DETECTION,\n    ...     labels=[Label(key=\"k1\", value=\"v1\")],\n    ...     raster=raster1,\n    ... )\n\n    Semantic-Segmentation Raster\n    &gt;&gt;&gt; annotation = Annotation(\n    ...     task_type=TaskType.SEMANTIC_SEGMENTATION,\n    ...     labels=[Label(key=\"k1\", value=\"v1\")],\n    ...     raster=raster1,\n    ... )\n\n    Defining all supported annotation types for a given `task_type` is allowed!\n    &gt;&gt;&gt; Annotation(\n    ...     task_type=TaskType.OBJECT_DETECTION,\n    ...     labels=[Label(key=\"k1\", value=\"v1\")],\n    ...     bounding_box=box1,\n    ...     polygon=polygon1,\n    ...     multipolygon=multipolygon,\n    ...     raster=raster1,\n    ... )\n    \"\"\"\n\n    task_type = StringProperty(\"task_types\")\n    labels = LabelProperty(\"labels\")\n    metadata = DictionaryProperty(\"annotation_metadata\")\n    bounding_box = GeometryProperty(\"bounding_box\")\n    polygon = GeometryProperty(\"polygon\")\n    raster = GeometryProperty(\"raster\")\n\n    def __init__(\n        self,\n        task_type: TaskType,\n        labels: Optional[List[Label]] = None,\n        metadata: Optional[MetadataType] = None,\n        bounding_box: Optional[BoundingBox] = None,\n        polygon: Optional[Polygon] = None,\n        multipolygon: Optional[MultiPolygon] = None,\n        raster: Optional[Raster] = None,\n        embedding: Optional[List[float]] = None,\n    ):\n        self.task_type = TaskType(task_type)\n        self.labels = labels if labels else []\n        self.metadata = metadata if metadata else {}\n        self.bounding_box = bounding_box\n        self.polygon = polygon\n        self.multipolygon = multipolygon\n        self.raster = raster\n        self.embedding = embedding\n        self._validate()\n\n    def _validate(self):\n        \"\"\"\n        Validates the parameters used to create an `Annotation` object.\n        \"\"\"\n        # labels\n        if not isinstance(self.labels, list):\n            raise TypeError(\n                \"Attribute `labels` should have type `List[valor.Label]`.\"\n            )\n        for idx, label in enumerate(self.labels):\n            if not isinstance(label, Label):\n                raise TypeError(\n                    f\"Attribute `labels[{idx}]` should have type `valor.Label`.\"\n                )\n\n        # bounding box\n        if self.bounding_box is not None:\n            if not isinstance(self.bounding_box, BoundingBox):\n                raise TypeError(\n                    \"Attribute `bounding_box` should have type `valor.schemas.BoundingBox`.\"\n                )\n\n        # polygon\n        if self.polygon is not None:\n            if not isinstance(self.polygon, Polygon):\n                raise TypeError(\n                    \"Attribute `polygon` should have type `valor.schemas.Polygon`.\"\n                )\n\n        # multipolygon\n        if self.multipolygon is not None:\n            if not isinstance(self.multipolygon, MultiPolygon):\n                raise TypeError(\n                    \"Attribute `multipolygon` should have type `valor.schemas.MultiPolygon`.\"\n                )\n\n        # raster\n        if self.raster is not None:\n            if not isinstance(self.raster, Raster):\n                raise TypeError(\n                    \"Attribute `raster` should have type `valor.schemas.Raster`.\"\n                )\n\n        # embedding\n        if self.embedding is not None:\n            if not isinstance(self.embedding, list):\n                raise TypeError(\n                    \"Attribute `embedding` should have type `List[float]`.\"\n                )\n            for idx, embedding in enumerate(self.embedding):\n                if not isinstance(embedding, (int, float, np.floating)):\n                    raise TypeError(\n                        f\"Attribute `embedding[{idx}]` should have type `float`, received element with type `{type(embedding)}`.\"\n                    )\n\n        # metadata\n        if not isinstance(self.metadata, dict):\n            raise TypeError(\"Attribute `metadata` should have type `dict`.\")\n        validate_metadata(self.metadata)\n\n    @classmethod\n    def from_dict(cls, resp: dict) -&gt; Annotation:\n        \"\"\"\n        Construct an annotation from a dictionary.\n\n        Parameters\n        ----------\n        resp : dict\n            The dictionary containing an annotation.\n\n        Returns\n        -------\n        valor.Annotation\n        \"\"\"\n\n        task_type = TaskType(resp[\"task_type\"])\n        labels = [Label.from_dict(label) for label in resp[\"labels\"]]\n        metadata = load_metadata(resp[\"metadata\"])\n\n        bounding_box = None\n        polygon = None\n        multipolygon = None\n        raster = None\n        embedding = None\n\n        if \"bounding_box\" in resp:\n            bounding_box = (\n                BoundingBox(**resp[\"bounding_box\"])\n                if resp[\"bounding_box\"]\n                else None\n            )\n        if \"polygon\" in resp:\n            polygon = Polygon(**resp[\"polygon\"]) if resp[\"polygon\"] else None\n        if \"multipolygon\" in resp:\n            multipolygon = (\n                MultiPolygon(**resp[\"multipolygon\"])\n                if resp[\"multipolygon\"]\n                else None\n            )\n        if \"raster\" in resp:\n            raster = Raster(**resp[\"raster\"]) if resp[\"raster\"] else None\n        if \"embedding\" in resp:\n            embedding = resp[\"embedding\"]\n\n        return cls(\n            task_type=task_type,\n            labels=labels,\n            metadata=metadata,\n            bounding_box=bounding_box,\n            polygon=polygon,\n            multipolygon=multipolygon,\n            raster=raster,\n            embedding=embedding,\n        )\n\n    def to_dict(self) -&gt; dict:\n        \"\"\"\n        Defines how a `valor.Annotation` object is serialized into a dictionary.\n\n        Returns\n        -------\n        dict\n            A dictionary describing an annotation.\n        \"\"\"\n        return {\n            \"task_type\": self.task_type.value,\n            \"labels\": [label.to_dict() for label in self.labels],\n            \"metadata\": dump_metadata(self.metadata),\n            \"bounding_box\": (\n                asdict(self.bounding_box) if self.bounding_box else None\n            ),\n            \"polygon\": asdict(self.polygon) if self.polygon else None,\n            \"multipolygon\": (\n                asdict(self.multipolygon) if self.multipolygon else None\n            ),\n            \"raster\": asdict(self.raster) if self.raster else None,\n            \"embedding\": self.embedding if self.embedding else None,\n        }\n\n    def __str__(self) -&gt; str:\n        \"\"\"Dumps the object into a JSON formatted string.\"\"\"\n        return json.dumps(self.to_dict(), indent=4)\n\n    def __eq__(self, other) -&gt; bool:\n        \"\"\"\n        Defines how `Annotations` are compared to one another.\n\n        Parameters\n        ----------\n        other : Annotation\n            The object to compare with the `Annotation`.\n\n        Returns\n        ----------\n        boolean\n            A boolean describing whether the two objects are equal.\n        \"\"\"\n        if not isinstance(other, Annotation):\n            raise TypeError(\n                f\"Expected type `{type(Annotation)}`, got `{other}`\"\n            )\n        return self.to_dict() == other.to_dict()\n</code></pre>"},{"location":"client_api/Annotation/#valor.Annotation-functions","title":"Functions","text":""},{"location":"client_api/Annotation/#valor.Annotation.__eq__","title":"<code>valor.Annotation.__eq__(other)</code>","text":"<p>Defines how <code>Annotations</code> are compared to one another.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Annotation</code> <p>The object to compare with the <code>Annotation</code>.</p> required <p>Returns:</p> Type Description <code>boolean</code> <p>A boolean describing whether the two objects are equal.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def __eq__(self, other) -&gt; bool:\n    \"\"\"\n    Defines how `Annotations` are compared to one another.\n\n    Parameters\n    ----------\n    other : Annotation\n        The object to compare with the `Annotation`.\n\n    Returns\n    ----------\n    boolean\n        A boolean describing whether the two objects are equal.\n    \"\"\"\n    if not isinstance(other, Annotation):\n        raise TypeError(\n            f\"Expected type `{type(Annotation)}`, got `{other}`\"\n        )\n    return self.to_dict() == other.to_dict()\n</code></pre>"},{"location":"client_api/Annotation/#valor.Annotation.__str__","title":"<code>valor.Annotation.__str__()</code>","text":"<p>Dumps the object into a JSON formatted string.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Dumps the object into a JSON formatted string.\"\"\"\n    return json.dumps(self.to_dict(), indent=4)\n</code></pre>"},{"location":"client_api/Annotation/#valor.Annotation.from_dict","title":"<code>valor.Annotation.from_dict(resp)</code>  <code>classmethod</code>","text":"<p>Construct an annotation from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>resp</code> <code>dict</code> <p>The dictionary containing an annotation.</p> required <p>Returns:</p> Type Description <code>Annotation</code> Source code in <code>valor/coretypes.py</code> <pre><code>@classmethod\ndef from_dict(cls, resp: dict) -&gt; Annotation:\n    \"\"\"\n    Construct an annotation from a dictionary.\n\n    Parameters\n    ----------\n    resp : dict\n        The dictionary containing an annotation.\n\n    Returns\n    -------\n    valor.Annotation\n    \"\"\"\n\n    task_type = TaskType(resp[\"task_type\"])\n    labels = [Label.from_dict(label) for label in resp[\"labels\"]]\n    metadata = load_metadata(resp[\"metadata\"])\n\n    bounding_box = None\n    polygon = None\n    multipolygon = None\n    raster = None\n    embedding = None\n\n    if \"bounding_box\" in resp:\n        bounding_box = (\n            BoundingBox(**resp[\"bounding_box\"])\n            if resp[\"bounding_box\"]\n            else None\n        )\n    if \"polygon\" in resp:\n        polygon = Polygon(**resp[\"polygon\"]) if resp[\"polygon\"] else None\n    if \"multipolygon\" in resp:\n        multipolygon = (\n            MultiPolygon(**resp[\"multipolygon\"])\n            if resp[\"multipolygon\"]\n            else None\n        )\n    if \"raster\" in resp:\n        raster = Raster(**resp[\"raster\"]) if resp[\"raster\"] else None\n    if \"embedding\" in resp:\n        embedding = resp[\"embedding\"]\n\n    return cls(\n        task_type=task_type,\n        labels=labels,\n        metadata=metadata,\n        bounding_box=bounding_box,\n        polygon=polygon,\n        multipolygon=multipolygon,\n        raster=raster,\n        embedding=embedding,\n    )\n</code></pre>"},{"location":"client_api/Annotation/#valor.Annotation.to_dict","title":"<code>valor.Annotation.to_dict()</code>","text":"<p>Defines how a <code>valor.Annotation</code> object is serialized into a dictionary.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary describing an annotation.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def to_dict(self) -&gt; dict:\n    \"\"\"\n    Defines how a `valor.Annotation` object is serialized into a dictionary.\n\n    Returns\n    -------\n    dict\n        A dictionary describing an annotation.\n    \"\"\"\n    return {\n        \"task_type\": self.task_type.value,\n        \"labels\": [label.to_dict() for label in self.labels],\n        \"metadata\": dump_metadata(self.metadata),\n        \"bounding_box\": (\n            asdict(self.bounding_box) if self.bounding_box else None\n        ),\n        \"polygon\": asdict(self.polygon) if self.polygon else None,\n        \"multipolygon\": (\n            asdict(self.multipolygon) if self.multipolygon else None\n        ),\n        \"raster\": asdict(self.raster) if self.raster else None,\n        \"embedding\": self.embedding if self.embedding else None,\n    }\n</code></pre>"},{"location":"client_api/Client/","title":"Client","text":"<p>Valor client object for interacting with the api.</p> <p>Parameters:</p> Name Type Description Default <code>connection</code> <code>ClientConnection</code> <p>Option to use an existing connection object.</p> <code>None</code> Source code in <code>valor/coretypes.py</code> <pre><code>class Client:\n    \"\"\"\n    Valor client object for interacting with the api.\n\n    Parameters\n    ----------\n    connection : ClientConnection, optional\n        Option to use an existing connection object.\n    \"\"\"\n\n    def __init__(self, connection: Optional[ClientConnection] = None):\n        if not connection:\n            connection = get_connection()\n        self.conn = connection\n\n    @classmethod\n    def connect(\n        cls,\n        host: str,\n        access_token: Optional[str] = None,\n        reconnect: bool = False,\n    ) -&gt; Client:\n        \"\"\"\n        Establishes a connection to the Valor API.\n\n        Parameters\n        ----------\n        host : str\n            The host to connect to. Should start with \"http://\" or \"https://\".\n        access_token : str\n            The access token for the host (if the host requires authentication).\n        \"\"\"\n        connect(host=host, access_token=access_token, reconnect=reconnect)\n        return cls(get_connection())\n\n    def get_labels(\n        self,\n        filter_by: Optional[FilterType] = None,\n    ) -&gt; List[Label]:\n        \"\"\"\n        Gets all labels using an optional filter.\n\n        Parameters\n        ----------\n        filter_by : FilterType, optional\n            Optional constraints to filter by.\n\n        Returns\n        ------\n        List[valor.Label]\n            A list of labels.\n        \"\"\"\n        filter_ = _format_filter(filter_by)\n        filter_ = asdict(filter_)\n        return [\n            Label.from_dict(label) for label in self.conn.get_labels(filter_)\n        ]\n\n    def get_labels_from_dataset(\n        self, dataset: Union[Dataset, str]\n    ) -&gt; List[Label]:\n        \"\"\"\n        Get all labels associated with a dataset's ground truths.\n\n        Parameters\n        ----------\n        dataset : valor.Dataset\n            The dataset to search by.\n\n        Returns\n        ------\n        List[valor.Label]\n            A list of labels.\n        \"\"\"\n        dataset_name = (\n            dataset.name if isinstance(dataset, Dataset) else dataset\n        )\n        return [\n            Label.from_dict(label)\n            for label in self.conn.get_labels_from_dataset(dataset_name)\n        ]\n\n    def get_labels_from_model(self, model: Union[Model, str]) -&gt; List[Label]:\n        \"\"\"\n        Get all labels associated with a model's ground truths.\n\n        Parameters\n        ----------\n        model : valor.Model\n            The model to search by.\n\n        Returns\n        ------\n        List[valor.Label]\n            A list of labels.\n        \"\"\"\n        model_name = model.name if isinstance(model, Model) else model\n        return [\n            Label.from_dict(label)\n            for label in self.conn.get_labels_from_model(model_name)\n        ]\n\n    def create_dataset(\n        self,\n        dataset: Union[Dataset, dict],\n    ) -&gt; None:\n        \"\"\"\n        Creates a dataset.\n\n        Parameters\n        ----------\n        dataset : valor.Dataset\n            The dataset to create.\n        \"\"\"\n        if isinstance(dataset, Dataset):\n            dataset = dataset.to_dict()\n        self.conn.create_dataset(dataset)\n\n    def create_groundtruths(\n        self,\n        dataset: Dataset,\n        groundtruths: List[GroundTruth],\n    ):\n        \"\"\"\n        Creates ground truths.\n\n        Parameters\n        ----------\n\n        dataset : valor.Dataset\n            The dataset to create the ground truth for.\n        groundtruths : List[valor.GroundTruth]\n            The ground truths to create.\n        \"\"\"\n        groundtruths_json = []\n        for groundtruth in groundtruths:\n            if not isinstance(groundtruth, GroundTruth):\n                raise TypeError(\n                    f\"Expected ground truth to be of type 'valor.GroundTruth' not '{type(groundtruth)}'.\"\n                )\n            if len(groundtruth.annotations) == 0:\n                warnings.warn(\n                    f\"GroundTruth for datum with uid `{groundtruth.datum.uid}` contains no annotations.\"\n                )\n            groundtruths_json.append(\n                groundtruth.to_dict(dataset_name=dataset.name)\n            )\n        self.conn.create_groundtruths(groundtruths_json)\n\n    def get_groundtruth(\n        self,\n        dataset: Union[Dataset, str],\n        datum: Union[Datum, str],\n    ) -&gt; Union[GroundTruth, None]:\n        \"\"\"\n        Get a particular ground truth.\n\n        Parameters\n        ----------\n        dataset: Union[Dataset, str]\n            The dataset the datum belongs to.\n        datum: Union[Datum, str]\n            The desired datum.\n\n        Returns\n        ----------\n        Union[GroundTruth, None]\n            The matching ground truth or 'None' if it doesn't exist.\n        \"\"\"\n        dataset_name = (\n            dataset.name if isinstance(dataset, Dataset) else dataset\n        )\n        datum_uid = datum.uid if isinstance(datum, Datum) else datum\n\n        try:\n            resp = self.conn.get_groundtruth(\n                dataset_name=dataset_name, datum_uid=datum_uid\n            )\n            return GroundTruth.from_dict(resp)\n        except ClientException as e:\n            if e.status_code == 404:\n                return None\n            raise e\n\n    def finalize_dataset(self, dataset: Union[Dataset, str]) -&gt; None:\n        \"\"\"\n        Finalizes a dataset such that new ground truths cannot be added to it.\n\n        Parameters\n        ----------\n        dataset : str\n            The dataset to be finalized.\n        \"\"\"\n        dataset_name = (\n            dataset.name if isinstance(dataset, Dataset) else dataset\n        )\n        return self.conn.finalize_dataset(name=dataset_name)\n\n    def get_dataset(\n        self,\n        name: str,\n    ) -&gt; Union[Dataset, None]:\n        \"\"\"\n        Gets a dataset by name.\n\n        Parameters\n        ----------\n        name : str\n            The name of the dataset to fetch.\n\n        Returns\n        -------\n        Union[Dataset, None]\n            A Dataset with a matching name, or 'None' if one doesn't exist.\n        \"\"\"\n        try:\n            return Dataset.from_dict(\n                self.conn.get_dataset(name), connection=self.conn\n            )\n        except ClientException as e:\n            if e.status_code == 404:\n                return None\n            raise e\n\n    def get_datasets(\n        self,\n        filter_by: Optional[FilterType] = None,\n    ) -&gt; List[Dataset]:\n        \"\"\"\n        Get all datasets, with an option to filter results according to some user-defined parameters.\n\n        Parameters\n        ----------\n        filter_by : FilterType, optional\n            Optional constraints to filter by.\n\n        Returns\n        ------\n        List[valor.Dataset]\n            A list of datasets.\n        \"\"\"\n        filter_ = _format_filter(filter_by)\n        if isinstance(filter_, Filter):\n            filter_ = asdict(filter_)\n        return [\n            Dataset.from_dict(dataset, connection=self.conn)\n            for dataset in self.conn.get_datasets(filter_)\n        ]\n\n    def get_datums(\n        self,\n        filter_by: Optional[FilterType] = None,\n    ) -&gt; List[Datum]:\n        \"\"\"\n        Get all datums using an optional filter.\n\n        Parameters\n        ----------\n        filter_by : FilterType, optional\n            Optional constraints to filter by.\n\n        Returns\n        -------\n        List[valor.Datum]\n            A list datums.\n        \"\"\"\n        filter_ = _format_filter(filter_by)\n        if isinstance(filter_, Filter):\n            filter_ = asdict(filter_)\n        return [\n            Datum.from_dict(datum) for datum in self.conn.get_datums(filter_)\n        ]\n\n    def get_datum(\n        self,\n        dataset: Union[Dataset, str],\n        uid: str,\n    ) -&gt; Union[Datum, None]:\n        \"\"\"\n        Get datum.\n        `GET` endpoint.\n        Parameters\n        ----------\n        dataset : valor.Dataset\n            The dataset the datum belongs to.\n        uid : str\n            The UID of the datum.\n        Returns\n        -------\n        valor.Datum\n            The requested datum or 'None' if it doesn't exist.\n        \"\"\"\n        dataset_name = (\n            dataset.name if isinstance(dataset, Dataset) else dataset\n        )\n        try:\n            resp = self.conn.get_datum(dataset_name=dataset_name, uid=uid)\n            return Datum.from_dict(resp)\n        except ClientException as e:\n            if e.status_code == 404:\n                return None\n            raise e\n\n    def get_dataset_status(\n        self,\n        name: str,\n    ) -&gt; Union[TableStatus, None]:\n        \"\"\"\n        Get the state of a given dataset.\n\n        Parameters\n        ----------\n        name : str\n            The name of the dataset we want to fetch the state of.\n\n        Returns\n        ------\n        TableStatus | None\n            The state of the dataset, or 'None' if the dataset does not exist.\n        \"\"\"\n        try:\n            return self.conn.get_dataset_status(name)\n        except ClientException as e:\n            if e.status_code == 404:\n                return None\n            raise e\n\n    def get_dataset_summary(self, name: str) -&gt; DatasetSummary:\n        \"\"\"\n        Gets the summary of a dataset.\n\n        Parameters\n        ----------\n        name : str\n            The name of the dataset to create a summary for.\n\n        Returns\n        -------\n        DatasetSummary\n            A dataclass containing the dataset summary.\n        \"\"\"\n        return DatasetSummary(**self.conn.get_dataset_summary(name))\n\n    def delete_dataset(self, name: str, timeout: int = 0) -&gt; None:\n        \"\"\"\n        Deletes a dataset.\n\n        Parameters\n        ----------\n        name : str\n            The name of the dataset to be deleted.\n        timeout : int\n            The number of seconds to wait in order to confirm that the dataset was deleted.\n        \"\"\"\n        self.conn.delete_dataset(name)\n        if timeout:\n            for _ in range(timeout):\n                if self.get_dataset(name) is None:\n                    break\n                else:\n                    time.sleep(1)\n            else:\n                raise TimeoutError(\n                    \"Dataset wasn't deleted within timeout interval\"\n                )\n\n    def create_model(\n        self,\n        model: Union[Model, dict],\n    ):\n        \"\"\"\n        Creates a model.\n\n        Parameters\n        ----------\n        model : valor.Model\n            The model to create.\n        \"\"\"\n        if isinstance(model, Model):\n            model = model.to_dict()\n        self.conn.create_model(model)\n\n    def create_predictions(\n        self,\n        dataset: Dataset,\n        model: Model,\n        predictions: List[Prediction],\n    ) -&gt; None:\n        \"\"\"\n        Creates predictions.\n\n        Parameters\n        ----------\n        dataset : valor.Dataset\n            The dataset that is being operated over.\n        model : valor.Model\n            The model making the prediction.\n        predictions : List[valor.Prediction]\n            The predictions to create.\n        \"\"\"\n        predictions_json = []\n        for prediction in predictions:\n            if not isinstance(prediction, Prediction):\n                raise TypeError(\n                    f\"Expected prediction to be of type 'valor.Prediction' not '{type(prediction)}'.\"\n                )\n            if len(prediction.annotations) == 0:\n                warnings.warn(\n                    f\"Prediction for datum with uid `{prediction.datum.uid}` contains no annotations.\"\n                )\n            predictions_json.append(\n                prediction.to_dict(\n                    dataset_name=dataset.name,\n                    model_name=model.name,\n                )\n            )\n        self.conn.create_predictions(predictions_json)\n\n    def get_prediction(\n        self,\n        dataset: Union[Dataset, str],\n        model: Union[Model, str],\n        datum: Union[Datum, str],\n    ) -&gt; Union[Prediction, None]:\n        \"\"\"\n        Get a particular prediction.\n\n        Parameters\n        ----------\n        dataset: Union[Dataset, str]\n            The dataset the datum belongs to.\n        model: Union[Model, str]\n            The model that made the prediction.\n        datum: Union[Datum, str]\n            The desired datum.\n\n        Returns\n        ----------\n        Union[Prediction, None]\n            The matching prediction or 'None' if it doesn't exist.\n        \"\"\"\n        dataset_name = (\n            dataset.name if isinstance(dataset, Dataset) else dataset\n        )\n        model_name = model.name if isinstance(model, Model) else model\n        datum_uid = datum.uid if isinstance(datum, Datum) else datum\n\n        try:\n            resp = self.conn.get_prediction(\n                dataset_name=dataset_name,\n                model_name=model_name,\n                datum_uid=datum_uid,\n            )\n            return Prediction.from_dict(resp)\n        except ClientException as e:\n            if e.status_code == 404:\n                return None\n            raise e\n\n    def finalize_inferences(\n        self, dataset: Union[Dataset, str], model: Union[Model, str]\n    ) -&gt; None:\n        \"\"\"\n        Finalizes a model-dataset pairing such that new predictions cannot be added to it.\n        \"\"\"\n        dataset_name = (\n            dataset.name if isinstance(dataset, Dataset) else dataset\n        )\n        model_name = model.name if isinstance(model, Model) else model\n        return self.conn.finalize_inferences(\n            dataset_name=dataset_name,\n            model_name=model_name,\n        )\n\n    def get_model(\n        self,\n        name: str,\n    ) -&gt; Union[Model, None]:\n        \"\"\"\n        Gets a model by name.\n\n        Parameters\n        ----------\n        name : str\n            The name of the model to fetch.\n\n        Returns\n        -------\n        Union[valor.Model, None]\n            A Model with matching name or 'None' if one doesn't exist.\n        \"\"\"\n        try:\n            return Model.from_dict(\n                self.conn.get_model(name), connection=self.conn\n            )\n        except ClientException as e:\n            if e.status_code == 404:\n                return None\n            raise e\n\n    def get_models(\n        self,\n        filter_by: Optional[FilterType] = None,\n    ) -&gt; List[Model]:\n        \"\"\"\n        Get all models using an optional filter.\n\n        Parameters\n        ----------\n        filter_by : FilterType, optional\n            Optional constraints to filter by.\n\n        Returns\n        ------\n        List[valor.Model]\n            A list of models.\n        \"\"\"\n        filter_ = _format_filter(filter_by)\n        if isinstance(filter_, Filter):\n            filter_ = asdict(filter_)\n        return [\n            Model.from_dict(model, connection=self.conn)\n            for model in self.conn.get_models(filter_)\n        ]\n\n    def get_model_status(\n        self,\n        dataset_name: str,\n        model_name: str,\n    ) -&gt; Optional[TableStatus]:\n        \"\"\"\n        Get the state of a given model over a dataset.\n\n        Parameters\n        ----------\n        dataset_name : str\n            The name of the dataset that the model is operating over.\n        model_name : str\n            The name of the model we want to fetch the state of.\n\n        Returns\n        ------\n        Union[TableStatus, None]\n            The state of the model or 'None' if the model doesn't exist.\n        \"\"\"\n        try:\n            return self.conn.get_model_status(dataset_name, model_name)\n        except ClientException as e:\n            if e.status_code == 404:\n                return None\n            raise e\n\n    def get_model_eval_requests(\n        self, model: Union[Model, str]\n    ) -&gt; List[Evaluation]:\n        \"\"\"\n        Get all evaluations that have been created for a model.\n\n        This does not return evaluation results.\n\n        `GET` endpoint.\n\n        Parameters\n        ----------\n        model : str\n            The model to search by.\n\n        Returns\n        -------\n        List[Evaluation]\n            A list of evaluations.\n        \"\"\"\n        model_name = model.name if isinstance(model, Model) else model\n        return [\n            Evaluation(**evaluation, connection=self.conn)\n            for evaluation in self.conn.get_model_eval_requests(model_name)\n        ]\n\n    def delete_model(self, name: str, timeout: int = 0) -&gt; None:\n        \"\"\"\n        Deletes a model.\n\n        Parameters\n        ----------\n        name : str\n            The name of the model to be deleted.\n        timeout : int\n            The number of seconds to wait in order to confirm that the model was deleted.\n        \"\"\"\n        self.conn.delete_model(name)\n        if timeout:\n            for _ in range(timeout):\n                if self.get_model(name) is None:\n                    break\n                else:\n                    time.sleep(1)\n            else:\n                raise TimeoutError(\n                    \"Model wasn't deleted within timeout interval\"\n                )\n\n    def get_evaluations(\n        self,\n        *,\n        evaluation_ids: Optional[List[int]] = None,\n        models: Union[List[Model], List[str], None] = None,\n        datasets: Union[List[Dataset], List[str], None] = None,\n    ) -&gt; List[Evaluation]:\n        \"\"\"\n        Returns all evaluations associated with user-supplied dataset and/or model names.\n\n        Parameters\n        ----------\n        evaluation_ids : List[int], optional.\n            A list of job IDs to return metrics for.\n        models : Union[List[valor.Model], List[str]], optional\n            A list of model names that we want to return metrics for.\n        datasets : Union[List[valor.Dataset], List[str]], optional\n            A list of dataset names that we want to return metrics for.\n\n        Returns\n        -------\n        List[valor.Evaluation]\n            A list of evaluations.\n        \"\"\"\n        if isinstance(datasets, list):\n            datasets = [\n                element.name if isinstance(element, Dataset) else element\n                for element in datasets\n            ]\n        if isinstance(models, list):\n            models = [\n                element.name if isinstance(element, Model) else element\n                for element in models\n            ]\n        return [\n            Evaluation(connection=self.conn, **evaluation)\n            for evaluation in self.conn.get_evaluations(\n                evaluation_ids=evaluation_ids,\n                models=models,\n                datasets=datasets,\n            )\n        ]\n\n    def evaluate(self, request: EvaluationRequest) -&gt; List[Evaluation]:\n        \"\"\"\n        Creates as many evaluations as necessary to fulfill the request.\n\n        Parameters\n        ----------\n        request : schemas.EvaluationRequest\n            The requested evaluation parameters.\n\n        Returns\n        -------\n        List[Evaluation]\n            A list of evaluations that meet the parameters.\n        \"\"\"\n        return [\n            Evaluation(**evaluation)\n            for evaluation in self.conn.evaluate(request)\n        ]\n</code></pre>"},{"location":"client_api/Client/#valor.Client-functions","title":"Functions","text":""},{"location":"client_api/Client/#valor.Client.connect","title":"<code>valor.Client.connect(host, access_token=None, reconnect=False)</code>  <code>classmethod</code>","text":"<p>Establishes a connection to the Valor API.</p> <p>Parameters:</p> Name Type Description Default <code>host</code> <code>str</code> <p>The host to connect to. Should start with \"http://\" or \"https://\".</p> required <code>access_token</code> <code>str</code> <p>The access token for the host (if the host requires authentication).</p> <code>None</code> Source code in <code>valor/coretypes.py</code> <pre><code>@classmethod\ndef connect(\n    cls,\n    host: str,\n    access_token: Optional[str] = None,\n    reconnect: bool = False,\n) -&gt; Client:\n    \"\"\"\n    Establishes a connection to the Valor API.\n\n    Parameters\n    ----------\n    host : str\n        The host to connect to. Should start with \"http://\" or \"https://\".\n    access_token : str\n        The access token for the host (if the host requires authentication).\n    \"\"\"\n    connect(host=host, access_token=access_token, reconnect=reconnect)\n    return cls(get_connection())\n</code></pre>"},{"location":"client_api/Client/#valor.Client.create_dataset","title":"<code>valor.Client.create_dataset(dataset)</code>","text":"<p>Creates a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>The dataset to create.</p> required Source code in <code>valor/coretypes.py</code> <pre><code>def create_dataset(\n    self,\n    dataset: Union[Dataset, dict],\n) -&gt; None:\n    \"\"\"\n    Creates a dataset.\n\n    Parameters\n    ----------\n    dataset : valor.Dataset\n        The dataset to create.\n    \"\"\"\n    if isinstance(dataset, Dataset):\n        dataset = dataset.to_dict()\n    self.conn.create_dataset(dataset)\n</code></pre>"},{"location":"client_api/Client/#valor.Client.create_groundtruths","title":"<code>valor.Client.create_groundtruths(dataset, groundtruths)</code>","text":"<p>Creates ground truths.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>The dataset to create the ground truth for.</p> required <code>groundtruths</code> <code>List[GroundTruth]</code> <p>The ground truths to create.</p> required Source code in <code>valor/coretypes.py</code> <pre><code>def create_groundtruths(\n    self,\n    dataset: Dataset,\n    groundtruths: List[GroundTruth],\n):\n    \"\"\"\n    Creates ground truths.\n\n    Parameters\n    ----------\n\n    dataset : valor.Dataset\n        The dataset to create the ground truth for.\n    groundtruths : List[valor.GroundTruth]\n        The ground truths to create.\n    \"\"\"\n    groundtruths_json = []\n    for groundtruth in groundtruths:\n        if not isinstance(groundtruth, GroundTruth):\n            raise TypeError(\n                f\"Expected ground truth to be of type 'valor.GroundTruth' not '{type(groundtruth)}'.\"\n            )\n        if len(groundtruth.annotations) == 0:\n            warnings.warn(\n                f\"GroundTruth for datum with uid `{groundtruth.datum.uid}` contains no annotations.\"\n            )\n        groundtruths_json.append(\n            groundtruth.to_dict(dataset_name=dataset.name)\n        )\n    self.conn.create_groundtruths(groundtruths_json)\n</code></pre>"},{"location":"client_api/Client/#valor.Client.create_model","title":"<code>valor.Client.create_model(model)</code>","text":"<p>Creates a model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Model</code> <p>The model to create.</p> required Source code in <code>valor/coretypes.py</code> <pre><code>def create_model(\n    self,\n    model: Union[Model, dict],\n):\n    \"\"\"\n    Creates a model.\n\n    Parameters\n    ----------\n    model : valor.Model\n        The model to create.\n    \"\"\"\n    if isinstance(model, Model):\n        model = model.to_dict()\n    self.conn.create_model(model)\n</code></pre>"},{"location":"client_api/Client/#valor.Client.create_predictions","title":"<code>valor.Client.create_predictions(dataset, model, predictions)</code>","text":"<p>Creates predictions.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>The dataset that is being operated over.</p> required <code>model</code> <code>Model</code> <p>The model making the prediction.</p> required <code>predictions</code> <code>List[Prediction]</code> <p>The predictions to create.</p> required Source code in <code>valor/coretypes.py</code> <pre><code>def create_predictions(\n    self,\n    dataset: Dataset,\n    model: Model,\n    predictions: List[Prediction],\n) -&gt; None:\n    \"\"\"\n    Creates predictions.\n\n    Parameters\n    ----------\n    dataset : valor.Dataset\n        The dataset that is being operated over.\n    model : valor.Model\n        The model making the prediction.\n    predictions : List[valor.Prediction]\n        The predictions to create.\n    \"\"\"\n    predictions_json = []\n    for prediction in predictions:\n        if not isinstance(prediction, Prediction):\n            raise TypeError(\n                f\"Expected prediction to be of type 'valor.Prediction' not '{type(prediction)}'.\"\n            )\n        if len(prediction.annotations) == 0:\n            warnings.warn(\n                f\"Prediction for datum with uid `{prediction.datum.uid}` contains no annotations.\"\n            )\n        predictions_json.append(\n            prediction.to_dict(\n                dataset_name=dataset.name,\n                model_name=model.name,\n            )\n        )\n    self.conn.create_predictions(predictions_json)\n</code></pre>"},{"location":"client_api/Client/#valor.Client.delete_dataset","title":"<code>valor.Client.delete_dataset(name, timeout=0)</code>","text":"<p>Deletes a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the dataset to be deleted.</p> required <code>timeout</code> <code>int</code> <p>The number of seconds to wait in order to confirm that the dataset was deleted.</p> <code>0</code> Source code in <code>valor/coretypes.py</code> <pre><code>def delete_dataset(self, name: str, timeout: int = 0) -&gt; None:\n    \"\"\"\n    Deletes a dataset.\n\n    Parameters\n    ----------\n    name : str\n        The name of the dataset to be deleted.\n    timeout : int\n        The number of seconds to wait in order to confirm that the dataset was deleted.\n    \"\"\"\n    self.conn.delete_dataset(name)\n    if timeout:\n        for _ in range(timeout):\n            if self.get_dataset(name) is None:\n                break\n            else:\n                time.sleep(1)\n        else:\n            raise TimeoutError(\n                \"Dataset wasn't deleted within timeout interval\"\n            )\n</code></pre>"},{"location":"client_api/Client/#valor.Client.delete_model","title":"<code>valor.Client.delete_model(name, timeout=0)</code>","text":"<p>Deletes a model.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the model to be deleted.</p> required <code>timeout</code> <code>int</code> <p>The number of seconds to wait in order to confirm that the model was deleted.</p> <code>0</code> Source code in <code>valor/coretypes.py</code> <pre><code>def delete_model(self, name: str, timeout: int = 0) -&gt; None:\n    \"\"\"\n    Deletes a model.\n\n    Parameters\n    ----------\n    name : str\n        The name of the model to be deleted.\n    timeout : int\n        The number of seconds to wait in order to confirm that the model was deleted.\n    \"\"\"\n    self.conn.delete_model(name)\n    if timeout:\n        for _ in range(timeout):\n            if self.get_model(name) is None:\n                break\n            else:\n                time.sleep(1)\n        else:\n            raise TimeoutError(\n                \"Model wasn't deleted within timeout interval\"\n            )\n</code></pre>"},{"location":"client_api/Client/#valor.Client.evaluate","title":"<code>valor.Client.evaluate(request)</code>","text":"<p>Creates as many evaluations as necessary to fulfill the request.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>EvaluationRequest</code> <p>The requested evaluation parameters.</p> required <p>Returns:</p> Type Description <code>List[Evaluation]</code> <p>A list of evaluations that meet the parameters.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def evaluate(self, request: EvaluationRequest) -&gt; List[Evaluation]:\n    \"\"\"\n    Creates as many evaluations as necessary to fulfill the request.\n\n    Parameters\n    ----------\n    request : schemas.EvaluationRequest\n        The requested evaluation parameters.\n\n    Returns\n    -------\n    List[Evaluation]\n        A list of evaluations that meet the parameters.\n    \"\"\"\n    return [\n        Evaluation(**evaluation)\n        for evaluation in self.conn.evaluate(request)\n    ]\n</code></pre>"},{"location":"client_api/Client/#valor.Client.finalize_dataset","title":"<code>valor.Client.finalize_dataset(dataset)</code>","text":"<p>Finalizes a dataset such that new ground truths cannot be added to it.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>str</code> <p>The dataset to be finalized.</p> required Source code in <code>valor/coretypes.py</code> <pre><code>def finalize_dataset(self, dataset: Union[Dataset, str]) -&gt; None:\n    \"\"\"\n    Finalizes a dataset such that new ground truths cannot be added to it.\n\n    Parameters\n    ----------\n    dataset : str\n        The dataset to be finalized.\n    \"\"\"\n    dataset_name = (\n        dataset.name if isinstance(dataset, Dataset) else dataset\n    )\n    return self.conn.finalize_dataset(name=dataset_name)\n</code></pre>"},{"location":"client_api/Client/#valor.Client.finalize_inferences","title":"<code>valor.Client.finalize_inferences(dataset, model)</code>","text":"<p>Finalizes a model-dataset pairing such that new predictions cannot be added to it.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def finalize_inferences(\n    self, dataset: Union[Dataset, str], model: Union[Model, str]\n) -&gt; None:\n    \"\"\"\n    Finalizes a model-dataset pairing such that new predictions cannot be added to it.\n    \"\"\"\n    dataset_name = (\n        dataset.name if isinstance(dataset, Dataset) else dataset\n    )\n    model_name = model.name if isinstance(model, Model) else model\n    return self.conn.finalize_inferences(\n        dataset_name=dataset_name,\n        model_name=model_name,\n    )\n</code></pre>"},{"location":"client_api/Client/#valor.Client.get_dataset","title":"<code>valor.Client.get_dataset(name)</code>","text":"<p>Gets a dataset by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the dataset to fetch.</p> required <p>Returns:</p> Type Description <code>Union[Dataset, None]</code> <p>A Dataset with a matching name, or 'None' if one doesn't exist.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def get_dataset(\n    self,\n    name: str,\n) -&gt; Union[Dataset, None]:\n    \"\"\"\n    Gets a dataset by name.\n\n    Parameters\n    ----------\n    name : str\n        The name of the dataset to fetch.\n\n    Returns\n    -------\n    Union[Dataset, None]\n        A Dataset with a matching name, or 'None' if one doesn't exist.\n    \"\"\"\n    try:\n        return Dataset.from_dict(\n            self.conn.get_dataset(name), connection=self.conn\n        )\n    except ClientException as e:\n        if e.status_code == 404:\n            return None\n        raise e\n</code></pre>"},{"location":"client_api/Client/#valor.Client.get_dataset_status","title":"<code>valor.Client.get_dataset_status(name)</code>","text":"<p>Get the state of a given dataset.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the dataset we want to fetch the state of.</p> required <p>Returns:</p> Type Description <code>TableStatus | None</code> <p>The state of the dataset, or 'None' if the dataset does not exist.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def get_dataset_status(\n    self,\n    name: str,\n) -&gt; Union[TableStatus, None]:\n    \"\"\"\n    Get the state of a given dataset.\n\n    Parameters\n    ----------\n    name : str\n        The name of the dataset we want to fetch the state of.\n\n    Returns\n    ------\n    TableStatus | None\n        The state of the dataset, or 'None' if the dataset does not exist.\n    \"\"\"\n    try:\n        return self.conn.get_dataset_status(name)\n    except ClientException as e:\n        if e.status_code == 404:\n            return None\n        raise e\n</code></pre>"},{"location":"client_api/Client/#valor.Client.get_dataset_summary","title":"<code>valor.Client.get_dataset_summary(name)</code>","text":"<p>Gets the summary of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the dataset to create a summary for.</p> required <p>Returns:</p> Type Description <code>DatasetSummary</code> <p>A dataclass containing the dataset summary.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def get_dataset_summary(self, name: str) -&gt; DatasetSummary:\n    \"\"\"\n    Gets the summary of a dataset.\n\n    Parameters\n    ----------\n    name : str\n        The name of the dataset to create a summary for.\n\n    Returns\n    -------\n    DatasetSummary\n        A dataclass containing the dataset summary.\n    \"\"\"\n    return DatasetSummary(**self.conn.get_dataset_summary(name))\n</code></pre>"},{"location":"client_api/Client/#valor.Client.get_datasets","title":"<code>valor.Client.get_datasets(filter_by=None)</code>","text":"<p>Get all datasets, with an option to filter results according to some user-defined parameters.</p> <p>Parameters:</p> Name Type Description Default <code>filter_by</code> <code>FilterType</code> <p>Optional constraints to filter by.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[Dataset]</code> <p>A list of datasets.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def get_datasets(\n    self,\n    filter_by: Optional[FilterType] = None,\n) -&gt; List[Dataset]:\n    \"\"\"\n    Get all datasets, with an option to filter results according to some user-defined parameters.\n\n    Parameters\n    ----------\n    filter_by : FilterType, optional\n        Optional constraints to filter by.\n\n    Returns\n    ------\n    List[valor.Dataset]\n        A list of datasets.\n    \"\"\"\n    filter_ = _format_filter(filter_by)\n    if isinstance(filter_, Filter):\n        filter_ = asdict(filter_)\n    return [\n        Dataset.from_dict(dataset, connection=self.conn)\n        for dataset in self.conn.get_datasets(filter_)\n    ]\n</code></pre>"},{"location":"client_api/Client/#valor.Client.get_datum","title":"<code>valor.Client.get_datum(dataset, uid)</code>","text":"<p>Get datum. <code>GET</code> endpoint.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>The dataset the datum belongs to.</p> required <code>uid</code> <code>str</code> <p>The UID of the datum.</p> required <p>Returns:</p> Type Description <code>Datum</code> <p>The requested datum or 'None' if it doesn't exist.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def get_datum(\n    self,\n    dataset: Union[Dataset, str],\n    uid: str,\n) -&gt; Union[Datum, None]:\n    \"\"\"\n    Get datum.\n    `GET` endpoint.\n    Parameters\n    ----------\n    dataset : valor.Dataset\n        The dataset the datum belongs to.\n    uid : str\n        The UID of the datum.\n    Returns\n    -------\n    valor.Datum\n        The requested datum or 'None' if it doesn't exist.\n    \"\"\"\n    dataset_name = (\n        dataset.name if isinstance(dataset, Dataset) else dataset\n    )\n    try:\n        resp = self.conn.get_datum(dataset_name=dataset_name, uid=uid)\n        return Datum.from_dict(resp)\n    except ClientException as e:\n        if e.status_code == 404:\n            return None\n        raise e\n</code></pre>"},{"location":"client_api/Client/#valor.Client.get_datums","title":"<code>valor.Client.get_datums(filter_by=None)</code>","text":"<p>Get all datums using an optional filter.</p> <p>Parameters:</p> Name Type Description Default <code>filter_by</code> <code>FilterType</code> <p>Optional constraints to filter by.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[Datum]</code> <p>A list datums.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def get_datums(\n    self,\n    filter_by: Optional[FilterType] = None,\n) -&gt; List[Datum]:\n    \"\"\"\n    Get all datums using an optional filter.\n\n    Parameters\n    ----------\n    filter_by : FilterType, optional\n        Optional constraints to filter by.\n\n    Returns\n    -------\n    List[valor.Datum]\n        A list datums.\n    \"\"\"\n    filter_ = _format_filter(filter_by)\n    if isinstance(filter_, Filter):\n        filter_ = asdict(filter_)\n    return [\n        Datum.from_dict(datum) for datum in self.conn.get_datums(filter_)\n    ]\n</code></pre>"},{"location":"client_api/Client/#valor.Client.get_evaluations","title":"<code>valor.Client.get_evaluations(*, evaluation_ids=None, models=None, datasets=None)</code>","text":"<p>Returns all evaluations associated with user-supplied dataset and/or model names.</p> <p>Parameters:</p> Name Type Description Default <code>evaluation_ids</code> <code>List[int], optional.</code> <p>A list of job IDs to return metrics for.</p> <code>None</code> <code>models</code> <code>Union[List[Model], List[str]]</code> <p>A list of model names that we want to return metrics for.</p> <code>None</code> <code>datasets</code> <code>Union[List[Dataset], List[str]]</code> <p>A list of dataset names that we want to return metrics for.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[Evaluation]</code> <p>A list of evaluations.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def get_evaluations(\n    self,\n    *,\n    evaluation_ids: Optional[List[int]] = None,\n    models: Union[List[Model], List[str], None] = None,\n    datasets: Union[List[Dataset], List[str], None] = None,\n) -&gt; List[Evaluation]:\n    \"\"\"\n    Returns all evaluations associated with user-supplied dataset and/or model names.\n\n    Parameters\n    ----------\n    evaluation_ids : List[int], optional.\n        A list of job IDs to return metrics for.\n    models : Union[List[valor.Model], List[str]], optional\n        A list of model names that we want to return metrics for.\n    datasets : Union[List[valor.Dataset], List[str]], optional\n        A list of dataset names that we want to return metrics for.\n\n    Returns\n    -------\n    List[valor.Evaluation]\n        A list of evaluations.\n    \"\"\"\n    if isinstance(datasets, list):\n        datasets = [\n            element.name if isinstance(element, Dataset) else element\n            for element in datasets\n        ]\n    if isinstance(models, list):\n        models = [\n            element.name if isinstance(element, Model) else element\n            for element in models\n        ]\n    return [\n        Evaluation(connection=self.conn, **evaluation)\n        for evaluation in self.conn.get_evaluations(\n            evaluation_ids=evaluation_ids,\n            models=models,\n            datasets=datasets,\n        )\n    ]\n</code></pre>"},{"location":"client_api/Client/#valor.Client.get_groundtruth","title":"<code>valor.Client.get_groundtruth(dataset, datum)</code>","text":"<p>Get a particular ground truth.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Union[Dataset, str]</code> <p>The dataset the datum belongs to.</p> required <code>datum</code> <code>Union[Datum, str]</code> <p>The desired datum.</p> required <p>Returns:</p> Type Description <code>Union[GroundTruth, None]</code> <p>The matching ground truth or 'None' if it doesn't exist.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def get_groundtruth(\n    self,\n    dataset: Union[Dataset, str],\n    datum: Union[Datum, str],\n) -&gt; Union[GroundTruth, None]:\n    \"\"\"\n    Get a particular ground truth.\n\n    Parameters\n    ----------\n    dataset: Union[Dataset, str]\n        The dataset the datum belongs to.\n    datum: Union[Datum, str]\n        The desired datum.\n\n    Returns\n    ----------\n    Union[GroundTruth, None]\n        The matching ground truth or 'None' if it doesn't exist.\n    \"\"\"\n    dataset_name = (\n        dataset.name if isinstance(dataset, Dataset) else dataset\n    )\n    datum_uid = datum.uid if isinstance(datum, Datum) else datum\n\n    try:\n        resp = self.conn.get_groundtruth(\n            dataset_name=dataset_name, datum_uid=datum_uid\n        )\n        return GroundTruth.from_dict(resp)\n    except ClientException as e:\n        if e.status_code == 404:\n            return None\n        raise e\n</code></pre>"},{"location":"client_api/Client/#valor.Client.get_labels","title":"<code>valor.Client.get_labels(filter_by=None)</code>","text":"<p>Gets all labels using an optional filter.</p> <p>Parameters:</p> Name Type Description Default <code>filter_by</code> <code>FilterType</code> <p>Optional constraints to filter by.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[Label]</code> <p>A list of labels.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def get_labels(\n    self,\n    filter_by: Optional[FilterType] = None,\n) -&gt; List[Label]:\n    \"\"\"\n    Gets all labels using an optional filter.\n\n    Parameters\n    ----------\n    filter_by : FilterType, optional\n        Optional constraints to filter by.\n\n    Returns\n    ------\n    List[valor.Label]\n        A list of labels.\n    \"\"\"\n    filter_ = _format_filter(filter_by)\n    filter_ = asdict(filter_)\n    return [\n        Label.from_dict(label) for label in self.conn.get_labels(filter_)\n    ]\n</code></pre>"},{"location":"client_api/Client/#valor.Client.get_labels_from_dataset","title":"<code>valor.Client.get_labels_from_dataset(dataset)</code>","text":"<p>Get all labels associated with a dataset's ground truths.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>The dataset to search by.</p> required <p>Returns:</p> Type Description <code>List[Label]</code> <p>A list of labels.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def get_labels_from_dataset(\n    self, dataset: Union[Dataset, str]\n) -&gt; List[Label]:\n    \"\"\"\n    Get all labels associated with a dataset's ground truths.\n\n    Parameters\n    ----------\n    dataset : valor.Dataset\n        The dataset to search by.\n\n    Returns\n    ------\n    List[valor.Label]\n        A list of labels.\n    \"\"\"\n    dataset_name = (\n        dataset.name if isinstance(dataset, Dataset) else dataset\n    )\n    return [\n        Label.from_dict(label)\n        for label in self.conn.get_labels_from_dataset(dataset_name)\n    ]\n</code></pre>"},{"location":"client_api/Client/#valor.Client.get_labels_from_model","title":"<code>valor.Client.get_labels_from_model(model)</code>","text":"<p>Get all labels associated with a model's ground truths.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Model</code> <p>The model to search by.</p> required <p>Returns:</p> Type Description <code>List[Label]</code> <p>A list of labels.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def get_labels_from_model(self, model: Union[Model, str]) -&gt; List[Label]:\n    \"\"\"\n    Get all labels associated with a model's ground truths.\n\n    Parameters\n    ----------\n    model : valor.Model\n        The model to search by.\n\n    Returns\n    ------\n    List[valor.Label]\n        A list of labels.\n    \"\"\"\n    model_name = model.name if isinstance(model, Model) else model\n    return [\n        Label.from_dict(label)\n        for label in self.conn.get_labels_from_model(model_name)\n    ]\n</code></pre>"},{"location":"client_api/Client/#valor.Client.get_model","title":"<code>valor.Client.get_model(name)</code>","text":"<p>Gets a model by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the model to fetch.</p> required <p>Returns:</p> Type Description <code>Union[Model, None]</code> <p>A Model with matching name or 'None' if one doesn't exist.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def get_model(\n    self,\n    name: str,\n) -&gt; Union[Model, None]:\n    \"\"\"\n    Gets a model by name.\n\n    Parameters\n    ----------\n    name : str\n        The name of the model to fetch.\n\n    Returns\n    -------\n    Union[valor.Model, None]\n        A Model with matching name or 'None' if one doesn't exist.\n    \"\"\"\n    try:\n        return Model.from_dict(\n            self.conn.get_model(name), connection=self.conn\n        )\n    except ClientException as e:\n        if e.status_code == 404:\n            return None\n        raise e\n</code></pre>"},{"location":"client_api/Client/#valor.Client.get_model_eval_requests","title":"<code>valor.Client.get_model_eval_requests(model)</code>","text":"<p>Get all evaluations that have been created for a model.</p> <p>This does not return evaluation results.</p> <p><code>GET</code> endpoint.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>The model to search by.</p> required <p>Returns:</p> Type Description <code>List[Evaluation]</code> <p>A list of evaluations.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def get_model_eval_requests(\n    self, model: Union[Model, str]\n) -&gt; List[Evaluation]:\n    \"\"\"\n    Get all evaluations that have been created for a model.\n\n    This does not return evaluation results.\n\n    `GET` endpoint.\n\n    Parameters\n    ----------\n    model : str\n        The model to search by.\n\n    Returns\n    -------\n    List[Evaluation]\n        A list of evaluations.\n    \"\"\"\n    model_name = model.name if isinstance(model, Model) else model\n    return [\n        Evaluation(**evaluation, connection=self.conn)\n        for evaluation in self.conn.get_model_eval_requests(model_name)\n    ]\n</code></pre>"},{"location":"client_api/Client/#valor.Client.get_model_status","title":"<code>valor.Client.get_model_status(dataset_name, model_name)</code>","text":"<p>Get the state of a given model over a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_name</code> <code>str</code> <p>The name of the dataset that the model is operating over.</p> required <code>model_name</code> <code>str</code> <p>The name of the model we want to fetch the state of.</p> required <p>Returns:</p> Type Description <code>Union[TableStatus, None]</code> <p>The state of the model or 'None' if the model doesn't exist.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def get_model_status(\n    self,\n    dataset_name: str,\n    model_name: str,\n) -&gt; Optional[TableStatus]:\n    \"\"\"\n    Get the state of a given model over a dataset.\n\n    Parameters\n    ----------\n    dataset_name : str\n        The name of the dataset that the model is operating over.\n    model_name : str\n        The name of the model we want to fetch the state of.\n\n    Returns\n    ------\n    Union[TableStatus, None]\n        The state of the model or 'None' if the model doesn't exist.\n    \"\"\"\n    try:\n        return self.conn.get_model_status(dataset_name, model_name)\n    except ClientException as e:\n        if e.status_code == 404:\n            return None\n        raise e\n</code></pre>"},{"location":"client_api/Client/#valor.Client.get_models","title":"<code>valor.Client.get_models(filter_by=None)</code>","text":"<p>Get all models using an optional filter.</p> <p>Parameters:</p> Name Type Description Default <code>filter_by</code> <code>FilterType</code> <p>Optional constraints to filter by.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[Model]</code> <p>A list of models.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def get_models(\n    self,\n    filter_by: Optional[FilterType] = None,\n) -&gt; List[Model]:\n    \"\"\"\n    Get all models using an optional filter.\n\n    Parameters\n    ----------\n    filter_by : FilterType, optional\n        Optional constraints to filter by.\n\n    Returns\n    ------\n    List[valor.Model]\n        A list of models.\n    \"\"\"\n    filter_ = _format_filter(filter_by)\n    if isinstance(filter_, Filter):\n        filter_ = asdict(filter_)\n    return [\n        Model.from_dict(model, connection=self.conn)\n        for model in self.conn.get_models(filter_)\n    ]\n</code></pre>"},{"location":"client_api/Client/#valor.Client.get_prediction","title":"<code>valor.Client.get_prediction(dataset, model, datum)</code>","text":"<p>Get a particular prediction.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Union[Dataset, str]</code> <p>The dataset the datum belongs to.</p> required <code>model</code> <code>Union[Model, str]</code> <p>The model that made the prediction.</p> required <code>datum</code> <code>Union[Datum, str]</code> <p>The desired datum.</p> required <p>Returns:</p> Type Description <code>Union[Prediction, None]</code> <p>The matching prediction or 'None' if it doesn't exist.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def get_prediction(\n    self,\n    dataset: Union[Dataset, str],\n    model: Union[Model, str],\n    datum: Union[Datum, str],\n) -&gt; Union[Prediction, None]:\n    \"\"\"\n    Get a particular prediction.\n\n    Parameters\n    ----------\n    dataset: Union[Dataset, str]\n        The dataset the datum belongs to.\n    model: Union[Model, str]\n        The model that made the prediction.\n    datum: Union[Datum, str]\n        The desired datum.\n\n    Returns\n    ----------\n    Union[Prediction, None]\n        The matching prediction or 'None' if it doesn't exist.\n    \"\"\"\n    dataset_name = (\n        dataset.name if isinstance(dataset, Dataset) else dataset\n    )\n    model_name = model.name if isinstance(model, Model) else model\n    datum_uid = datum.uid if isinstance(datum, Datum) else datum\n\n    try:\n        resp = self.conn.get_prediction(\n            dataset_name=dataset_name,\n            model_name=model_name,\n            datum_uid=datum_uid,\n        )\n        return Prediction.from_dict(resp)\n    except ClientException as e:\n        if e.status_code == 404:\n            return None\n        raise e\n</code></pre>"},{"location":"client_api/Dataset/","title":"Dataset","text":"<p>A class describing a given dataset.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the dataset.</p> required <code>metadata</code> <code>dict</code> <p>A dictionary of metadata that describes the dataset.</p> <code>None</code> Source code in <code>valor/coretypes.py</code> <pre><code>class Dataset:\n    \"\"\"\n    A class describing a given dataset.\n\n    Parameters\n    ----------\n    name : str\n        The name of the dataset.\n    metadata : dict\n        A dictionary of metadata that describes the dataset.\n    \"\"\"\n\n    name = StringProperty(\"dataset_names\")\n    metadata = DictionaryProperty(\"dataset_metadata\")\n\n    def __init__(\n        self,\n        name: str,\n        metadata: Optional[MetadataType] = None,\n        connection: Optional[ClientConnection] = None,\n    ):\n        \"\"\"\n        Create or get a `Dataset` object.\n\n        Parameters\n        ----------\n        name : str\n            The name of the dataset.\n        metadata : dict\n            An optional dictionary of metadata that describes the dataset.\n        connection : ClientConnnetion\n            An optional Valor client object for interacting with the API.\n        \"\"\"\n        self.conn = connection\n        self.name = name\n        self.metadata = metadata if metadata else {}\n\n        # validation\n        if not isinstance(self.name, str):\n            raise TypeError(\"`name` should be of type `str`\")\n        validate_metadata(self.metadata)\n\n    @classmethod\n    def create(\n        cls,\n        name: str,\n        metadata: Optional[MetadataType] = None,\n    ) -&gt; Dataset:\n        \"\"\"\n        Creates a dataset that persists in the back end.\n\n        Parameters\n        ----------\n        name : str\n            The name of the dataset.\n        metadata : dict\n            A dictionary of metadata that describes the dataset.\n\n        Returns\n        -------\n        valor.Dataset\n            The created dataset.\n        \"\"\"\n        dataset = cls(\n            name=name,\n            metadata=metadata,\n        )\n        Client(dataset.conn).create_dataset(dataset)\n        return dataset\n\n    @classmethod\n    def get(\n        cls,\n        name: str,\n    ) -&gt; Union[Dataset, None]:\n        \"\"\"\n        Retrieves a dataset from the back end database.\n\n        Parameters\n        ----------\n        name : str\n            The name of the dataset.\n\n        Returns\n        -------\n        Union[valor.Dataset, None]\n            The dataset or 'None' if it doesn't exist.\n        \"\"\"\n        return Client().get_dataset(name)\n\n    @classmethod\n    def from_dict(\n        cls, resp: dict, connection: Optional[ClientConnection] = None\n    ) -&gt; Dataset:\n        \"\"\"\n        Construct a dataset from a dictionary.\n\n        Parameters\n        ----------\n        resp : dict\n            The dictionary containing a dataset.\n        connection : ClientConnection, optional\n            Option to share a ClientConnection rather than request a new one.\n\n        Returns\n        -------\n        valor.Dataset\n        \"\"\"\n        resp.pop(\"id\")\n        resp[\"metadata\"] = load_metadata(resp[\"metadata\"])\n        return cls(**resp, connection=connection)\n\n    def to_dict(self, id: Optional[int] = None) -&gt; dict:\n        \"\"\"\n        Defines how a `valor.Dataset` object is serialized into a dictionary.\n\n        Returns\n        ----------\n        dict\n            A dictionary describing a model.\n        \"\"\"\n        return {\n            \"id\": id,\n            \"name\": self.name,\n            \"metadata\": dump_metadata(self.metadata),\n        }\n\n    def __str__(self) -&gt; str:\n        \"\"\"Dumps the object into a JSON formatted string.\"\"\"\n        objdict = self.to_dict()\n        objdict.pop(\"id\")\n        return json.dumps(objdict, indent=4)\n\n    def add_groundtruth(\n        self,\n        groundtruth: GroundTruth,\n    ) -&gt; None:\n        \"\"\"\n        Add a ground truth to the dataset.\n\n        Parameters\n        ----------\n        groundtruth : GroundTruth\n            The ground truth to create.\n        \"\"\"\n        Client(self.conn).create_groundtruths(\n            dataset=self,\n            groundtruths=[groundtruth],\n        )\n\n    def add_groundtruths(\n        self,\n        groundtruths: List[GroundTruth],\n    ) -&gt; None:\n        \"\"\"\n        Add multiple ground truths to the dataset.\n\n        Parameters\n        ----------\n        groundtruths : List[GroundTruth]\n            The ground truths to create.\n        \"\"\"\n        Client(self.conn).create_groundtruths(\n            dataset=self,\n            groundtruths=groundtruths,\n        )\n\n    def get_groundtruth(\n        self,\n        datum: Union[Datum, str],\n    ) -&gt; Union[GroundTruth, None]:\n        \"\"\"\n        Get a particular ground truth.\n\n        Parameters\n        ----------\n        datum: Union[Datum, str]\n            The desired datum.\n\n        Returns\n        ----------\n        Union[GroundTruth, None]\n            The matching ground truth or 'None' if it doesn't exist.\n        \"\"\"\n        return Client(self.conn).get_groundtruth(dataset=self, datum=datum)\n\n    def get_labels(\n        self,\n    ) -&gt; List[Label]:\n        \"\"\"\n        Get all labels associated with a given dataset.\n\n        Returns\n        ----------\n        List[Label]\n            A list of `Labels` associated with the dataset.\n        \"\"\"\n        return Client(self.conn).get_labels_from_dataset(self)\n\n    def get_datums(self) -&gt; List[Datum]:\n        \"\"\"\n        Get all datums associated with a given dataset.\n\n        Returns\n        ----------\n        List[Datum]\n            A list of `Datums` associated with the dataset.\n        \"\"\"\n        return Client(self.conn).get_datums(\n            filter_by=Filter(dataset_names=[self.name])\n        )\n\n    def get_evaluations(\n        self,\n    ) -&gt; List[Evaluation]:\n        \"\"\"\n        Get all evaluations associated with a given dataset.\n\n        Returns\n        ----------\n        List[Evaluation]\n            A list of `Evaluations` associated with the dataset.\n        \"\"\"\n        return Client(self.conn).get_evaluations(datasets=[self])\n\n    def get_summary(self) -&gt; DatasetSummary:\n        \"\"\"\n        Get the summary of a given dataset.\n\n        Returns\n        -------\n        DatasetSummary\n            The summary of the dataset. This class has the following fields:\n\n            name: name of the dataset\n\n            num_datums: total number of datums in the dataset\n\n            num_annotations: total number of labeled annotations in the dataset; if an\n            object (such as a bounding box) has multiple labels, then each label is counted separately\n\n            num_bounding_boxes: total number of bounding boxes in the dataset\n\n            num_polygons: total number of polygons in the dataset\n\n            num_rasters: total number of rasters in the dataset\n\n            task_types: list of the unique task types in the dataset\n\n            labels: list of the unique labels in the dataset\n\n            datum_metadata: list of the unique metadata dictionaries in the dataset that are associated\n            to datums\n\n            groundtruth_annotation_metadata: list of the unique metadata dictionaries in the dataset that are\n            associated to annotations\n        \"\"\"\n        return Client(self.conn).get_dataset_summary(self.name)\n\n    def finalize(\n        self,\n    ):\n        \"\"\"\n        Finalizes the dataset such that new ground truths cannot be added to it.\n        \"\"\"\n        return Client(self.conn).finalize_dataset(self)\n\n    def delete(\n        self,\n        timeout: int = 0,\n    ):\n        \"\"\"\n        Delete the dataset from the back end.\n\n        Parameters\n        ----------\n        timeout : int, default=0\n            Sets a timeout in seconds.\n        \"\"\"\n        Client(self.conn).delete_dataset(self.name, timeout)\n</code></pre>"},{"location":"client_api/Dataset/#valor.Dataset-functions","title":"Functions","text":""},{"location":"client_api/Dataset/#valor.Dataset.__init__","title":"<code>valor.Dataset.__init__(name, metadata=None, connection=None)</code>","text":"<p>Create or get a <code>Dataset</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the dataset.</p> required <code>metadata</code> <code>dict</code> <p>An optional dictionary of metadata that describes the dataset.</p> <code>None</code> <code>connection</code> <code>ClientConnnetion</code> <p>An optional Valor client object for interacting with the API.</p> <code>None</code> Source code in <code>valor/coretypes.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    metadata: Optional[MetadataType] = None,\n    connection: Optional[ClientConnection] = None,\n):\n    \"\"\"\n    Create or get a `Dataset` object.\n\n    Parameters\n    ----------\n    name : str\n        The name of the dataset.\n    metadata : dict\n        An optional dictionary of metadata that describes the dataset.\n    connection : ClientConnnetion\n        An optional Valor client object for interacting with the API.\n    \"\"\"\n    self.conn = connection\n    self.name = name\n    self.metadata = metadata if metadata else {}\n\n    # validation\n    if not isinstance(self.name, str):\n        raise TypeError(\"`name` should be of type `str`\")\n    validate_metadata(self.metadata)\n</code></pre>"},{"location":"client_api/Dataset/#valor.Dataset.__str__","title":"<code>valor.Dataset.__str__()</code>","text":"<p>Dumps the object into a JSON formatted string.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Dumps the object into a JSON formatted string.\"\"\"\n    objdict = self.to_dict()\n    objdict.pop(\"id\")\n    return json.dumps(objdict, indent=4)\n</code></pre>"},{"location":"client_api/Dataset/#valor.Dataset.add_groundtruth","title":"<code>valor.Dataset.add_groundtruth(groundtruth)</code>","text":"<p>Add a ground truth to the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>groundtruth</code> <code>GroundTruth</code> <p>The ground truth to create.</p> required Source code in <code>valor/coretypes.py</code> <pre><code>def add_groundtruth(\n    self,\n    groundtruth: GroundTruth,\n) -&gt; None:\n    \"\"\"\n    Add a ground truth to the dataset.\n\n    Parameters\n    ----------\n    groundtruth : GroundTruth\n        The ground truth to create.\n    \"\"\"\n    Client(self.conn).create_groundtruths(\n        dataset=self,\n        groundtruths=[groundtruth],\n    )\n</code></pre>"},{"location":"client_api/Dataset/#valor.Dataset.add_groundtruths","title":"<code>valor.Dataset.add_groundtruths(groundtruths)</code>","text":"<p>Add multiple ground truths to the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>groundtruths</code> <code>List[GroundTruth]</code> <p>The ground truths to create.</p> required Source code in <code>valor/coretypes.py</code> <pre><code>def add_groundtruths(\n    self,\n    groundtruths: List[GroundTruth],\n) -&gt; None:\n    \"\"\"\n    Add multiple ground truths to the dataset.\n\n    Parameters\n    ----------\n    groundtruths : List[GroundTruth]\n        The ground truths to create.\n    \"\"\"\n    Client(self.conn).create_groundtruths(\n        dataset=self,\n        groundtruths=groundtruths,\n    )\n</code></pre>"},{"location":"client_api/Dataset/#valor.Dataset.create","title":"<code>valor.Dataset.create(name, metadata=None)</code>  <code>classmethod</code>","text":"<p>Creates a dataset that persists in the back end.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the dataset.</p> required <code>metadata</code> <code>dict</code> <p>A dictionary of metadata that describes the dataset.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dataset</code> <p>The created dataset.</p> Source code in <code>valor/coretypes.py</code> <pre><code>@classmethod\ndef create(\n    cls,\n    name: str,\n    metadata: Optional[MetadataType] = None,\n) -&gt; Dataset:\n    \"\"\"\n    Creates a dataset that persists in the back end.\n\n    Parameters\n    ----------\n    name : str\n        The name of the dataset.\n    metadata : dict\n        A dictionary of metadata that describes the dataset.\n\n    Returns\n    -------\n    valor.Dataset\n        The created dataset.\n    \"\"\"\n    dataset = cls(\n        name=name,\n        metadata=metadata,\n    )\n    Client(dataset.conn).create_dataset(dataset)\n    return dataset\n</code></pre>"},{"location":"client_api/Dataset/#valor.Dataset.delete","title":"<code>valor.Dataset.delete(timeout=0)</code>","text":"<p>Delete the dataset from the back end.</p> <p>Parameters:</p> Name Type Description Default <code>timeout</code> <code>int</code> <p>Sets a timeout in seconds.</p> <code>0</code> Source code in <code>valor/coretypes.py</code> <pre><code>def delete(\n    self,\n    timeout: int = 0,\n):\n    \"\"\"\n    Delete the dataset from the back end.\n\n    Parameters\n    ----------\n    timeout : int, default=0\n        Sets a timeout in seconds.\n    \"\"\"\n    Client(self.conn).delete_dataset(self.name, timeout)\n</code></pre>"},{"location":"client_api/Dataset/#valor.Dataset.finalize","title":"<code>valor.Dataset.finalize()</code>","text":"<p>Finalizes the dataset such that new ground truths cannot be added to it.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def finalize(\n    self,\n):\n    \"\"\"\n    Finalizes the dataset such that new ground truths cannot be added to it.\n    \"\"\"\n    return Client(self.conn).finalize_dataset(self)\n</code></pre>"},{"location":"client_api/Dataset/#valor.Dataset.from_dict","title":"<code>valor.Dataset.from_dict(resp, connection=None)</code>  <code>classmethod</code>","text":"<p>Construct a dataset from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>resp</code> <code>dict</code> <p>The dictionary containing a dataset.</p> required <code>connection</code> <code>ClientConnection</code> <p>Option to share a ClientConnection rather than request a new one.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dataset</code> Source code in <code>valor/coretypes.py</code> <pre><code>@classmethod\ndef from_dict(\n    cls, resp: dict, connection: Optional[ClientConnection] = None\n) -&gt; Dataset:\n    \"\"\"\n    Construct a dataset from a dictionary.\n\n    Parameters\n    ----------\n    resp : dict\n        The dictionary containing a dataset.\n    connection : ClientConnection, optional\n        Option to share a ClientConnection rather than request a new one.\n\n    Returns\n    -------\n    valor.Dataset\n    \"\"\"\n    resp.pop(\"id\")\n    resp[\"metadata\"] = load_metadata(resp[\"metadata\"])\n    return cls(**resp, connection=connection)\n</code></pre>"},{"location":"client_api/Dataset/#valor.Dataset.get","title":"<code>valor.Dataset.get(name)</code>  <code>classmethod</code>","text":"<p>Retrieves a dataset from the back end database.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the dataset.</p> required <p>Returns:</p> Type Description <code>Union[Dataset, None]</code> <p>The dataset or 'None' if it doesn't exist.</p> Source code in <code>valor/coretypes.py</code> <pre><code>@classmethod\ndef get(\n    cls,\n    name: str,\n) -&gt; Union[Dataset, None]:\n    \"\"\"\n    Retrieves a dataset from the back end database.\n\n    Parameters\n    ----------\n    name : str\n        The name of the dataset.\n\n    Returns\n    -------\n    Union[valor.Dataset, None]\n        The dataset or 'None' if it doesn't exist.\n    \"\"\"\n    return Client().get_dataset(name)\n</code></pre>"},{"location":"client_api/Dataset/#valor.Dataset.get_datums","title":"<code>valor.Dataset.get_datums()</code>","text":"<p>Get all datums associated with a given dataset.</p> <p>Returns:</p> Type Description <code>List[Datum]</code> <p>A list of <code>Datums</code> associated with the dataset.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def get_datums(self) -&gt; List[Datum]:\n    \"\"\"\n    Get all datums associated with a given dataset.\n\n    Returns\n    ----------\n    List[Datum]\n        A list of `Datums` associated with the dataset.\n    \"\"\"\n    return Client(self.conn).get_datums(\n        filter_by=Filter(dataset_names=[self.name])\n    )\n</code></pre>"},{"location":"client_api/Dataset/#valor.Dataset.get_evaluations","title":"<code>valor.Dataset.get_evaluations()</code>","text":"<p>Get all evaluations associated with a given dataset.</p> <p>Returns:</p> Type Description <code>List[Evaluation]</code> <p>A list of <code>Evaluations</code> associated with the dataset.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def get_evaluations(\n    self,\n) -&gt; List[Evaluation]:\n    \"\"\"\n    Get all evaluations associated with a given dataset.\n\n    Returns\n    ----------\n    List[Evaluation]\n        A list of `Evaluations` associated with the dataset.\n    \"\"\"\n    return Client(self.conn).get_evaluations(datasets=[self])\n</code></pre>"},{"location":"client_api/Dataset/#valor.Dataset.get_groundtruth","title":"<code>valor.Dataset.get_groundtruth(datum)</code>","text":"<p>Get a particular ground truth.</p> <p>Parameters:</p> Name Type Description Default <code>datum</code> <code>Union[Datum, str]</code> <p>The desired datum.</p> required <p>Returns:</p> Type Description <code>Union[GroundTruth, None]</code> <p>The matching ground truth or 'None' if it doesn't exist.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def get_groundtruth(\n    self,\n    datum: Union[Datum, str],\n) -&gt; Union[GroundTruth, None]:\n    \"\"\"\n    Get a particular ground truth.\n\n    Parameters\n    ----------\n    datum: Union[Datum, str]\n        The desired datum.\n\n    Returns\n    ----------\n    Union[GroundTruth, None]\n        The matching ground truth or 'None' if it doesn't exist.\n    \"\"\"\n    return Client(self.conn).get_groundtruth(dataset=self, datum=datum)\n</code></pre>"},{"location":"client_api/Dataset/#valor.Dataset.get_labels","title":"<code>valor.Dataset.get_labels()</code>","text":"<p>Get all labels associated with a given dataset.</p> <p>Returns:</p> Type Description <code>List[Label]</code> <p>A list of <code>Labels</code> associated with the dataset.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def get_labels(\n    self,\n) -&gt; List[Label]:\n    \"\"\"\n    Get all labels associated with a given dataset.\n\n    Returns\n    ----------\n    List[Label]\n        A list of `Labels` associated with the dataset.\n    \"\"\"\n    return Client(self.conn).get_labels_from_dataset(self)\n</code></pre>"},{"location":"client_api/Dataset/#valor.Dataset.get_summary","title":"<code>valor.Dataset.get_summary()</code>","text":"<p>Get the summary of a given dataset.</p> <p>Returns:</p> Type Description <code>DatasetSummary</code> <p>The summary of the dataset. This class has the following fields:</p> <p>name: name of the dataset</p> <p>num_datums: total number of datums in the dataset</p> <p>num_annotations: total number of labeled annotations in the dataset; if an object (such as a bounding box) has multiple labels, then each label is counted separately</p> <p>num_bounding_boxes: total number of bounding boxes in the dataset</p> <p>num_polygons: total number of polygons in the dataset</p> <p>num_rasters: total number of rasters in the dataset</p> <p>task_types: list of the unique task types in the dataset</p> <p>labels: list of the unique labels in the dataset</p> <p>datum_metadata: list of the unique metadata dictionaries in the dataset that are associated to datums</p> <p>groundtruth_annotation_metadata: list of the unique metadata dictionaries in the dataset that are associated to annotations</p> Source code in <code>valor/coretypes.py</code> <pre><code>def get_summary(self) -&gt; DatasetSummary:\n    \"\"\"\n    Get the summary of a given dataset.\n\n    Returns\n    -------\n    DatasetSummary\n        The summary of the dataset. This class has the following fields:\n\n        name: name of the dataset\n\n        num_datums: total number of datums in the dataset\n\n        num_annotations: total number of labeled annotations in the dataset; if an\n        object (such as a bounding box) has multiple labels, then each label is counted separately\n\n        num_bounding_boxes: total number of bounding boxes in the dataset\n\n        num_polygons: total number of polygons in the dataset\n\n        num_rasters: total number of rasters in the dataset\n\n        task_types: list of the unique task types in the dataset\n\n        labels: list of the unique labels in the dataset\n\n        datum_metadata: list of the unique metadata dictionaries in the dataset that are associated\n        to datums\n\n        groundtruth_annotation_metadata: list of the unique metadata dictionaries in the dataset that are\n        associated to annotations\n    \"\"\"\n    return Client(self.conn).get_dataset_summary(self.name)\n</code></pre>"},{"location":"client_api/Dataset/#valor.Dataset.to_dict","title":"<code>valor.Dataset.to_dict(id=None)</code>","text":"<p>Defines how a <code>valor.Dataset</code> object is serialized into a dictionary.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary describing a model.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def to_dict(self, id: Optional[int] = None) -&gt; dict:\n    \"\"\"\n    Defines how a `valor.Dataset` object is serialized into a dictionary.\n\n    Returns\n    ----------\n    dict\n        A dictionary describing a model.\n    \"\"\"\n    return {\n        \"id\": id,\n        \"name\": self.name,\n        \"metadata\": dump_metadata(self.metadata),\n    }\n</code></pre>"},{"location":"client_api/Datum/","title":"Datum","text":"<p>A class used to store datum about <code>GroundTruths</code> and <code>Predictions</code>.</p> <p>Parameters:</p> Name Type Description Default <code>uid</code> <code>str</code> <p>The UID of the <code>Datum</code>.</p> required <code>metadata</code> <code>dict</code> <p>A dictionary of metadata that describes the <code>Datum</code>.</p> <code>None</code> Source code in <code>valor/coretypes.py</code> <pre><code>class Datum:\n    \"\"\"\n    A class used to store datum about `GroundTruths` and `Predictions`.\n\n    Parameters\n    ----------\n    uid : str\n        The UID of the `Datum`.\n    metadata : dict\n        A dictionary of metadata that describes the `Datum`.\n    \"\"\"\n\n    uid = StringProperty(\"datum_uids\")\n    metadata = DictionaryProperty(\"datum_metadata\")\n\n    def __init__(\n        self,\n        uid: str,\n        metadata: Optional[MetadataType] = None,\n    ):\n        self.uid = uid\n        self.metadata = metadata if metadata else {}\n\n        if not isinstance(self.uid, str):\n            raise TypeError(\"Attribute `uid` should have type `str`.\")\n        validate_metadata(self.metadata)\n\n    def to_dict(self, dataset_name: Optional[str] = None) -&gt; dict:\n        \"\"\"\n        Defines how a `valor.Datum` object is serialized into a dictionary.\n\n        Returns\n        ----------\n        dict\n            A dictionary describing a datum.\n        \"\"\"\n        return {\n            \"dataset_name\": dataset_name,\n            \"uid\": self.uid,\n            \"metadata\": dump_metadata(self.metadata),\n        }\n\n    @classmethod\n    def from_dict(cls, resp: dict) -&gt; Datum:\n        \"\"\"\n        Construct a datum from a dictionary.\n\n        Parameters\n        ----------\n        resp : dict\n            The dictionary containing a datum.\n\n        Returns\n        -------\n        valor.Datum\n        \"\"\"\n        resp.pop(\"dataset_name\", None)\n        resp[\"metadata\"] = load_metadata(resp[\"metadata\"])\n        return cls(**resp)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Dumps the object into a JSON formatted string.\"\"\"\n        objdict = self.to_dict(dataset_name=None)\n        objdict.pop(\"dataset_name\")\n        return json.dumps(objdict, indent=4)\n\n    def __eq__(self, other) -&gt; bool:\n        \"\"\"\n        Defines how `Datums` are compared to one another.\n\n        Parameters\n        ----------\n        other : Datum\n            The object to compare with the `Datum`.\n\n        Returns\n        ----------\n        bool\n            A boolean describing whether the two objects are equal.\n        \"\"\"\n        if not isinstance(other, Datum):\n            raise TypeError(f\"Expected type `{type(Datum)}`, got `{other}`\")\n        return self.to_dict() == other.to_dict()\n</code></pre>"},{"location":"client_api/Datum/#valor.Datum-functions","title":"Functions","text":""},{"location":"client_api/Datum/#valor.Datum.__eq__","title":"<code>valor.Datum.__eq__(other)</code>","text":"<p>Defines how <code>Datums</code> are compared to one another.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Datum</code> <p>The object to compare with the <code>Datum</code>.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>A boolean describing whether the two objects are equal.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def __eq__(self, other) -&gt; bool:\n    \"\"\"\n    Defines how `Datums` are compared to one another.\n\n    Parameters\n    ----------\n    other : Datum\n        The object to compare with the `Datum`.\n\n    Returns\n    ----------\n    bool\n        A boolean describing whether the two objects are equal.\n    \"\"\"\n    if not isinstance(other, Datum):\n        raise TypeError(f\"Expected type `{type(Datum)}`, got `{other}`\")\n    return self.to_dict() == other.to_dict()\n</code></pre>"},{"location":"client_api/Datum/#valor.Datum.__str__","title":"<code>valor.Datum.__str__()</code>","text":"<p>Dumps the object into a JSON formatted string.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Dumps the object into a JSON formatted string.\"\"\"\n    objdict = self.to_dict(dataset_name=None)\n    objdict.pop(\"dataset_name\")\n    return json.dumps(objdict, indent=4)\n</code></pre>"},{"location":"client_api/Datum/#valor.Datum.from_dict","title":"<code>valor.Datum.from_dict(resp)</code>  <code>classmethod</code>","text":"<p>Construct a datum from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>resp</code> <code>dict</code> <p>The dictionary containing a datum.</p> required <p>Returns:</p> Type Description <code>Datum</code> Source code in <code>valor/coretypes.py</code> <pre><code>@classmethod\ndef from_dict(cls, resp: dict) -&gt; Datum:\n    \"\"\"\n    Construct a datum from a dictionary.\n\n    Parameters\n    ----------\n    resp : dict\n        The dictionary containing a datum.\n\n    Returns\n    -------\n    valor.Datum\n    \"\"\"\n    resp.pop(\"dataset_name\", None)\n    resp[\"metadata\"] = load_metadata(resp[\"metadata\"])\n    return cls(**resp)\n</code></pre>"},{"location":"client_api/Datum/#valor.Datum.to_dict","title":"<code>valor.Datum.to_dict(dataset_name=None)</code>","text":"<p>Defines how a <code>valor.Datum</code> object is serialized into a dictionary.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary describing a datum.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def to_dict(self, dataset_name: Optional[str] = None) -&gt; dict:\n    \"\"\"\n    Defines how a `valor.Datum` object is serialized into a dictionary.\n\n    Returns\n    ----------\n    dict\n        A dictionary describing a datum.\n    \"\"\"\n    return {\n        \"dataset_name\": dataset_name,\n        \"uid\": self.uid,\n        \"metadata\": dump_metadata(self.metadata),\n    }\n</code></pre>"},{"location":"client_api/Evaluation/","title":"Evaluation","text":"<p>Wraps <code>valor.client.Job</code> to provide evaluation-specifc members.</p> Source code in <code>valor/coretypes.py</code> <pre><code>class Evaluation:\n    \"\"\"\n    Wraps `valor.client.Job` to provide evaluation-specifc members.\n    \"\"\"\n\n    def __init__(\n        self, connection: Optional[ClientConnection] = None, **kwargs\n    ):\n        \"\"\"\n        Defines important attributes of the API's `EvaluationResult`.\n\n        Attributes\n        ----------\n        id : int\n            The ID of the evaluation.\n        model_name : str\n            The name of the evaluated model.\n        datum_filter : schemas.Filter\n            The filter used to select the datums for evaluation.\n        status : EvaluationStatus\n            The status of the evaluation.\n        metrics : List[dict]\n            A list of metric dictionaries returned by the job.\n        confusion_matrices : List[dict]\n            A list of confusion matrix dictionaries returned by the job.\n        \"\"\"\n        if not connection:\n            connection = get_connection()\n        self.conn = connection\n        self.update(**kwargs)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Dumps the object into a JSON formatted string.\"\"\"\n        return json.dumps(self.to_dict(), indent=4)\n\n    def to_dict(self) -&gt; dict:\n        \"\"\"\n        Defines how a `valor.Evaluation` object is serialized into a dictionary.\n\n        Returns\n        ----------\n        dict\n            A dictionary describing an evaluation.\n        \"\"\"\n        return {\n            \"id\": self.id,\n            \"model_name\": self.model_name,\n            \"datum_filter\": asdict(self.datum_filter),\n            \"parameters\": asdict(self.parameters),\n            \"status\": self.status.value,\n            \"metrics\": self.metrics,\n            \"confusion_matrices\": self.confusion_matrices,\n            **self.kwargs,\n        }\n\n    def update(\n        self,\n        *_,\n        id: int,\n        model_name: str,\n        datum_filter: Filter,\n        parameters: EvaluationParameters,\n        status: EvaluationStatus,\n        metrics: List[Dict],\n        confusion_matrices: List[Dict],\n        **kwargs,\n    ):\n        self.id = id\n        self.model_name = model_name\n        self.datum_filter = (\n            Filter(**datum_filter)\n            if isinstance(datum_filter, dict)\n            else datum_filter\n        )\n        self.parameters = (\n            EvaluationParameters(**parameters)\n            if isinstance(parameters, dict)\n            else parameters\n        )\n        self.status = EvaluationStatus(status)\n        self.metrics = metrics\n        self.confusion_matrices = confusion_matrices\n        self.kwargs = kwargs\n        self.ignored_pred_labels: Optional[List[Label]] = None\n        self.missing_pred_labels: Optional[List[Label]] = None\n        self.ignored_pred_keys: Optional[List[str]] = None\n        self.missing_pred_keys: Optional[List[str]] = None\n\n        for k, v in kwargs.items():\n            setattr(self, k, v)\n\n    def poll(self) -&gt; EvaluationStatus:\n        \"\"\"\n        Poll the back end.\n\n        Updates the evaluation with the latest state from the back end.\n\n        Returns\n        -------\n        enums.EvaluationStatus\n            The status of the evaluation.\n\n        Raises\n        ----------\n        ClientException\n            If an Evaluation with the given `evaluation_id` is not found.\n        \"\"\"\n        response = self.conn.get_evaluations(evaluation_ids=[self.id])\n        if not response:\n            raise ClientException(\"Not Found\")\n        self.update(**response[0])\n        return self.status\n\n    def wait_for_completion(\n        self,\n        *,\n        timeout: Optional[int] = None,\n        interval: float = 1.0,\n    ) -&gt; EvaluationStatus:\n        \"\"\"\n        Blocking function that waits for evaluation to finish.\n\n        Parameters\n        ----------\n        timeout : int, optional\n            Length of timeout in seconds.\n        interval : float, default=1.0\n            Polling interval in seconds.\n        \"\"\"\n        t_start = time.time()\n        while self.poll() not in [\n            EvaluationStatus.DONE,\n            EvaluationStatus.FAILED,\n        ]:\n            time.sleep(interval)\n            if timeout and time.time() - t_start &gt; timeout:\n                raise TimeoutError\n        return self.status\n\n    def to_dataframe(\n        self,\n        stratify_by: Optional[Tuple[str, str]] = None,\n    ):\n        \"\"\"\n        Get all metrics associated with a Model and return them in a `pd.DataFrame`.\n\n        Returns\n        ----------\n        pd.DataFrame\n            Evaluation metrics being displayed in a `pd.DataFrame`.\n\n        Raises\n        ------\n        ModuleNotFoundError\n            This function requires the use of `pandas.DataFrame`.\n\n        \"\"\"\n        try:\n            import pandas as pd\n        except ModuleNotFoundError:\n            raise ModuleNotFoundError(\n                \"Must have pandas installed to use `get_metric_dataframes`.\"\n            )\n\n        if not stratify_by:\n            column_type = \"evaluation\"\n            column_name = self.id\n        else:\n            column_type = stratify_by[0]\n            column_name = stratify_by[1]\n\n        metrics = [\n            {**metric, column_type: column_name} for metric in self.metrics\n        ]\n        df = pd.DataFrame(metrics)\n        for k in [\"label\", \"parameters\"]:\n            df[k] = df[k].fillna(\"n/a\")\n        df[\"parameters\"] = df[\"parameters\"].apply(json.dumps)\n        df[\"label\"] = df[\"label\"].apply(\n            lambda x: f\"{x['key']}: {x['value']}\" if x != \"n/a\" else x\n        )\n        df = df.pivot(\n            index=[\"type\", \"parameters\", \"label\"], columns=[column_type]\n        )\n        return df\n</code></pre>"},{"location":"client_api/Evaluation/#valor.Evaluation-functions","title":"Functions","text":""},{"location":"client_api/Evaluation/#valor.Evaluation.__init__","title":"<code>valor.Evaluation.__init__(connection=None, **kwargs)</code>","text":"<p>Defines important attributes of the API's <code>EvaluationResult</code>.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>int</code> <p>The ID of the evaluation.</p> <code>model_name</code> <code>str</code> <p>The name of the evaluated model.</p> <code>datum_filter</code> <code>Filter</code> <p>The filter used to select the datums for evaluation.</p> <code>status</code> <code>EvaluationStatus</code> <p>The status of the evaluation.</p> <code>metrics</code> <code>List[dict]</code> <p>A list of metric dictionaries returned by the job.</p> <code>confusion_matrices</code> <code>List[dict]</code> <p>A list of confusion matrix dictionaries returned by the job.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def __init__(\n    self, connection: Optional[ClientConnection] = None, **kwargs\n):\n    \"\"\"\n    Defines important attributes of the API's `EvaluationResult`.\n\n    Attributes\n    ----------\n    id : int\n        The ID of the evaluation.\n    model_name : str\n        The name of the evaluated model.\n    datum_filter : schemas.Filter\n        The filter used to select the datums for evaluation.\n    status : EvaluationStatus\n        The status of the evaluation.\n    metrics : List[dict]\n        A list of metric dictionaries returned by the job.\n    confusion_matrices : List[dict]\n        A list of confusion matrix dictionaries returned by the job.\n    \"\"\"\n    if not connection:\n        connection = get_connection()\n    self.conn = connection\n    self.update(**kwargs)\n</code></pre>"},{"location":"client_api/Evaluation/#valor.Evaluation.__str__","title":"<code>valor.Evaluation.__str__()</code>","text":"<p>Dumps the object into a JSON formatted string.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Dumps the object into a JSON formatted string.\"\"\"\n    return json.dumps(self.to_dict(), indent=4)\n</code></pre>"},{"location":"client_api/Evaluation/#valor.Evaluation.poll","title":"<code>valor.Evaluation.poll()</code>","text":"<p>Poll the back end.</p> <p>Updates the evaluation with the latest state from the back end.</p> <p>Returns:</p> Type Description <code>EvaluationStatus</code> <p>The status of the evaluation.</p> <p>Raises:</p> Type Description <code>ClientException</code> <p>If an Evaluation with the given <code>evaluation_id</code> is not found.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def poll(self) -&gt; EvaluationStatus:\n    \"\"\"\n    Poll the back end.\n\n    Updates the evaluation with the latest state from the back end.\n\n    Returns\n    -------\n    enums.EvaluationStatus\n        The status of the evaluation.\n\n    Raises\n    ----------\n    ClientException\n        If an Evaluation with the given `evaluation_id` is not found.\n    \"\"\"\n    response = self.conn.get_evaluations(evaluation_ids=[self.id])\n    if not response:\n        raise ClientException(\"Not Found\")\n    self.update(**response[0])\n    return self.status\n</code></pre>"},{"location":"client_api/Evaluation/#valor.Evaluation.to_dataframe","title":"<code>valor.Evaluation.to_dataframe(stratify_by=None)</code>","text":"<p>Get all metrics associated with a Model and return them in a <code>pd.DataFrame</code>.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Evaluation metrics being displayed in a <code>pd.DataFrame</code>.</p> <p>Raises:</p> Type Description <code>ModuleNotFoundError</code> <p>This function requires the use of <code>pandas.DataFrame</code>.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def to_dataframe(\n    self,\n    stratify_by: Optional[Tuple[str, str]] = None,\n):\n    \"\"\"\n    Get all metrics associated with a Model and return them in a `pd.DataFrame`.\n\n    Returns\n    ----------\n    pd.DataFrame\n        Evaluation metrics being displayed in a `pd.DataFrame`.\n\n    Raises\n    ------\n    ModuleNotFoundError\n        This function requires the use of `pandas.DataFrame`.\n\n    \"\"\"\n    try:\n        import pandas as pd\n    except ModuleNotFoundError:\n        raise ModuleNotFoundError(\n            \"Must have pandas installed to use `get_metric_dataframes`.\"\n        )\n\n    if not stratify_by:\n        column_type = \"evaluation\"\n        column_name = self.id\n    else:\n        column_type = stratify_by[0]\n        column_name = stratify_by[1]\n\n    metrics = [\n        {**metric, column_type: column_name} for metric in self.metrics\n    ]\n    df = pd.DataFrame(metrics)\n    for k in [\"label\", \"parameters\"]:\n        df[k] = df[k].fillna(\"n/a\")\n    df[\"parameters\"] = df[\"parameters\"].apply(json.dumps)\n    df[\"label\"] = df[\"label\"].apply(\n        lambda x: f\"{x['key']}: {x['value']}\" if x != \"n/a\" else x\n    )\n    df = df.pivot(\n        index=[\"type\", \"parameters\", \"label\"], columns=[column_type]\n    )\n    return df\n</code></pre>"},{"location":"client_api/Evaluation/#valor.Evaluation.to_dict","title":"<code>valor.Evaluation.to_dict()</code>","text":"<p>Defines how a <code>valor.Evaluation</code> object is serialized into a dictionary.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary describing an evaluation.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def to_dict(self) -&gt; dict:\n    \"\"\"\n    Defines how a `valor.Evaluation` object is serialized into a dictionary.\n\n    Returns\n    ----------\n    dict\n        A dictionary describing an evaluation.\n    \"\"\"\n    return {\n        \"id\": self.id,\n        \"model_name\": self.model_name,\n        \"datum_filter\": asdict(self.datum_filter),\n        \"parameters\": asdict(self.parameters),\n        \"status\": self.status.value,\n        \"metrics\": self.metrics,\n        \"confusion_matrices\": self.confusion_matrices,\n        **self.kwargs,\n    }\n</code></pre>"},{"location":"client_api/Evaluation/#valor.Evaluation.wait_for_completion","title":"<code>valor.Evaluation.wait_for_completion(*, timeout=None, interval=1.0)</code>","text":"<p>Blocking function that waits for evaluation to finish.</p> <p>Parameters:</p> Name Type Description Default <code>timeout</code> <code>int</code> <p>Length of timeout in seconds.</p> <code>None</code> <code>interval</code> <code>float</code> <p>Polling interval in seconds.</p> <code>1.0</code> Source code in <code>valor/coretypes.py</code> <pre><code>def wait_for_completion(\n    self,\n    *,\n    timeout: Optional[int] = None,\n    interval: float = 1.0,\n) -&gt; EvaluationStatus:\n    \"\"\"\n    Blocking function that waits for evaluation to finish.\n\n    Parameters\n    ----------\n    timeout : int, optional\n        Length of timeout in seconds.\n    interval : float, default=1.0\n        Polling interval in seconds.\n    \"\"\"\n    t_start = time.time()\n    while self.poll() not in [\n        EvaluationStatus.DONE,\n        EvaluationStatus.FAILED,\n    ]:\n        time.sleep(interval)\n        if timeout and time.time() - t_start &gt; timeout:\n            raise TimeoutError\n    return self.status\n</code></pre>"},{"location":"client_api/Groundtruth/","title":"Groundtruth","text":"<p>An object describing a ground truth (e.g., a human-drawn bounding box on an image).</p> <p>Parameters:</p> Name Type Description Default <code>datum</code> <code>Datum</code> <p>The <code>Datum</code> associated with the <code>GroundTruth</code>.</p> required <code>annotations</code> <code>List[Annotation]</code> <p>The list of <code>Annotations</code> associated with the <code>GroundTruth</code>.</p> required Source code in <code>valor/coretypes.py</code> <pre><code>class GroundTruth:\n    \"\"\"\n    An object describing a ground truth (e.g., a human-drawn bounding box on an image).\n\n    Parameters\n    ----------\n    datum : Datum\n        The `Datum` associated with the `GroundTruth`.\n    annotations : List[Annotation]\n        The list of `Annotations` associated with the `GroundTruth`.\n    \"\"\"\n\n    def __init__(self, datum: Datum, annotations: List[Annotation]):\n        self.datum = datum\n        self.annotations = annotations\n        self._validate()\n\n    def _validate(self):\n        \"\"\"\n        Validate the inputs of the `GroundTruth`.\n        \"\"\"\n        # validate datum\n        if not isinstance(self.datum, Datum):\n            raise TypeError(\n                \"Attribute `datum` should have type `valor.Datum`.\"\n            )\n\n        # validate annotations\n        if not isinstance(self.annotations, list):\n            raise TypeError(\n                \"Attribute `datum` should have type `List[valor.Annotation]`.\"\n            )\n        for idx, annotation in enumerate(self.annotations):\n            if not isinstance(annotation, Annotation):\n                raise TypeError(\n                    f\"Attribute `annotations[{idx}]` should have type `valor.Annotation`.\"\n                )\n\n    def to_dict(\n        self,\n        dataset_name: Optional[str] = None,\n    ) -&gt; dict:\n        \"\"\"\n        Defines how a `valor.GroundTruth` object is serialized into a dictionary.\n\n        Returns\n        ----------\n        dict\n            A dictionary describing a ground truth.\n        \"\"\"\n        return {\n            \"datum\": self.datum.to_dict(dataset_name),\n            \"annotations\": [\n                annotation.to_dict() for annotation in self.annotations\n            ],\n        }\n\n    @classmethod\n    def from_dict(cls, resp: dict) -&gt; GroundTruth:\n        \"\"\"\n        Construct a ground truth from a dictionary.\n\n        Parameters\n        ----------\n        resp : dict\n            The dictionary containing a ground truth.\n\n        Returns\n        -------\n        valor.GroundTruth\n        \"\"\"\n        expected_keys = {\"datum\", \"annotations\"}\n        if set(resp.keys()) != expected_keys:\n            raise ValueError(\n                f\"Expected keys `{expected_keys}`, received `{set(resp.keys())}`.\"\n            )\n        if not isinstance(resp[\"annotations\"], list):\n            raise TypeError(\"Expected `annotations` member to be a `list`.\")\n        return cls(\n            datum=Datum.from_dict(resp[\"datum\"]),\n            annotations=[\n                Annotation.from_dict(annotation)\n                for annotation in resp[\"annotations\"]\n            ],\n        )\n\n    def __str__(self) -&gt; str:\n        \"\"\"Dumps the object into a JSON formatted string.\"\"\"\n        objdict = self.to_dict(dataset_name=None)\n        objdict[\"datum\"].pop(\"dataset_name\")\n        return json.dumps(objdict, indent=4)\n\n    def __eq__(self, other):\n        \"\"\"\n        Defines how `GroundTruths` are compared to one another.\n\n        Parameters\n        ----------\n        other : GroundTruth\n            The object to compare with the `GroundTruth`.\n\n        Returns\n        ----------\n        boolean\n            A boolean describing whether the two objects are equal.\n        \"\"\"\n        if not isinstance(other, GroundTruth):\n            raise TypeError(\n                f\"Expected type `{type(GroundTruth)}`, got `{other}`\"\n            )\n        return self.to_dict() == other.to_dict()\n</code></pre>"},{"location":"client_api/Groundtruth/#valor.GroundTruth-functions","title":"Functions","text":""},{"location":"client_api/Groundtruth/#valor.GroundTruth.__eq__","title":"<code>valor.GroundTruth.__eq__(other)</code>","text":"<p>Defines how <code>GroundTruths</code> are compared to one another.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>GroundTruth</code> <p>The object to compare with the <code>GroundTruth</code>.</p> required <p>Returns:</p> Type Description <code>boolean</code> <p>A boolean describing whether the two objects are equal.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def __eq__(self, other):\n    \"\"\"\n    Defines how `GroundTruths` are compared to one another.\n\n    Parameters\n    ----------\n    other : GroundTruth\n        The object to compare with the `GroundTruth`.\n\n    Returns\n    ----------\n    boolean\n        A boolean describing whether the two objects are equal.\n    \"\"\"\n    if not isinstance(other, GroundTruth):\n        raise TypeError(\n            f\"Expected type `{type(GroundTruth)}`, got `{other}`\"\n        )\n    return self.to_dict() == other.to_dict()\n</code></pre>"},{"location":"client_api/Groundtruth/#valor.GroundTruth.__str__","title":"<code>valor.GroundTruth.__str__()</code>","text":"<p>Dumps the object into a JSON formatted string.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Dumps the object into a JSON formatted string.\"\"\"\n    objdict = self.to_dict(dataset_name=None)\n    objdict[\"datum\"].pop(\"dataset_name\")\n    return json.dumps(objdict, indent=4)\n</code></pre>"},{"location":"client_api/Groundtruth/#valor.GroundTruth.from_dict","title":"<code>valor.GroundTruth.from_dict(resp)</code>  <code>classmethod</code>","text":"<p>Construct a ground truth from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>resp</code> <code>dict</code> <p>The dictionary containing a ground truth.</p> required <p>Returns:</p> Type Description <code>GroundTruth</code> Source code in <code>valor/coretypes.py</code> <pre><code>@classmethod\ndef from_dict(cls, resp: dict) -&gt; GroundTruth:\n    \"\"\"\n    Construct a ground truth from a dictionary.\n\n    Parameters\n    ----------\n    resp : dict\n        The dictionary containing a ground truth.\n\n    Returns\n    -------\n    valor.GroundTruth\n    \"\"\"\n    expected_keys = {\"datum\", \"annotations\"}\n    if set(resp.keys()) != expected_keys:\n        raise ValueError(\n            f\"Expected keys `{expected_keys}`, received `{set(resp.keys())}`.\"\n        )\n    if not isinstance(resp[\"annotations\"], list):\n        raise TypeError(\"Expected `annotations` member to be a `list`.\")\n    return cls(\n        datum=Datum.from_dict(resp[\"datum\"]),\n        annotations=[\n            Annotation.from_dict(annotation)\n            for annotation in resp[\"annotations\"]\n        ],\n    )\n</code></pre>"},{"location":"client_api/Groundtruth/#valor.GroundTruth.to_dict","title":"<code>valor.GroundTruth.to_dict(dataset_name=None)</code>","text":"<p>Defines how a <code>valor.GroundTruth</code> object is serialized into a dictionary.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary describing a ground truth.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def to_dict(\n    self,\n    dataset_name: Optional[str] = None,\n) -&gt; dict:\n    \"\"\"\n    Defines how a `valor.GroundTruth` object is serialized into a dictionary.\n\n    Returns\n    ----------\n    dict\n        A dictionary describing a ground truth.\n    \"\"\"\n    return {\n        \"datum\": self.datum.to_dict(dataset_name),\n        \"annotations\": [\n            annotation.to_dict() for annotation in self.annotations\n        ],\n    }\n</code></pre>"},{"location":"client_api/ImageMetadata/","title":"ImageMetadata","text":"<p>A class describing the metadata for a particular image.</p> <p>Parameters:</p> Name Type Description Default <code>uid</code> <code>str</code> <p>The UID of the image.</p> required <code>height</code> <code>int</code> <p>The height of the image.</p> required <code>width</code> <code>int</code> <p>The width of the image.</p> required <code>metadata</code> <code>dict</code> <p>A dictionary of metadata that describes the image.</p> <code>None</code> Source code in <code>valor/metatypes.py</code> <pre><code>class ImageMetadata:\n    \"\"\"\n    A class describing the metadata for a particular image.\n\n    Parameters\n    ----------\n    uid : str\n        The UID of the image.\n    height : int\n        The height of the image.\n    width : int\n        The width of the image.\n    metadata : dict\n        A dictionary of metadata that describes the image.\n    \"\"\"\n\n    def __init__(\n        self,\n        uid: str,\n        height: int,\n        width: int,\n        metadata: Optional[MetadataType] = None,\n    ):\n        self.uid = uid\n        self._dataset_name = None\n        self.height = height\n        self.width = width\n        self.metadata: MetadataType = dict(metadata) if metadata else {}\n\n        if not isinstance(self.uid, str):\n            raise TypeError(\"ImageMetadata uid must be a string.\")\n        if not isinstance(self.height, int):\n            raise TypeError(\"ImageMetadata height must be a int.\")\n        if not isinstance(self.width, int):\n            raise TypeError(\"ImageMetadata height must be a int.\")\n        validate_metadata(self.metadata)\n\n    @staticmethod\n    def valid(datum: Datum) -&gt; bool:\n        \"\"\"\n        Asserts whether the `Datum's` height and width is a valid subset of the image's height and width.\n\n        Parameters\n        ----------\n        datum : Datum\n            The `Datum` to check validity for.\n        \"\"\"\n        return {\"height\", \"width\"}.issubset(datum.metadata)\n\n    @classmethod\n    def from_datum(cls, datum: Datum):\n        \"\"\"\n        Creates an `ImageMetadata` object from a `Datum`.\n\n        Parameters\n        ----------\n        datum : Datum\n            The `Datum` to extract metadata from.\n        \"\"\"\n        if not cls.valid(datum):\n            raise ValueError(\n                f\"`datum` does not contain height and/or width in metadata `{datum.metadata}`\"\n            )\n        metadata = dict(datum.metadata)\n        width = cast(int, metadata.pop(\"width\"))\n        height = cast(int, metadata.pop(\"height\"))\n        img = cls(\n            uid=datum.uid,\n            height=int(height),\n            width=int(width),\n            metadata=metadata,\n        )\n        return img\n\n    @classmethod\n    def from_pil(cls, uid: str, image: PIL.Image.Image):\n        \"\"\"\n        Creates an `ImageMetadata` object from an image.\n\n        Parameters\n        ----------\n        uid : str\n            The UID of the image.\n        image : PIL.Image.Image\n            The image to create metadata for.\n        \"\"\"\n        width, height = image.size\n        return cls(\n            uid=uid,\n            height=int(height),\n            width=int(width),\n        )\n\n    def to_datum(self) -&gt; Datum:\n        \"\"\"\n        Converts an `ImageMetadata` object into a `Datum`.\n        \"\"\"\n        metadata = dict(self.metadata) if self.metadata else {}\n\n        metadata[\"height\"] = self.height\n        metadata[\"width\"] = self.width\n        datum = Datum(\n            uid=self.uid,\n            metadata=metadata,\n        )\n        return datum\n</code></pre>"},{"location":"client_api/ImageMetadata/#valor.metatypes.ImageMetadata-functions","title":"Functions","text":""},{"location":"client_api/ImageMetadata/#valor.metatypes.ImageMetadata.from_datum","title":"<code>valor.metatypes.ImageMetadata.from_datum(datum)</code>  <code>classmethod</code>","text":"<p>Creates an <code>ImageMetadata</code> object from a <code>Datum</code>.</p> <p>Parameters:</p> Name Type Description Default <code>datum</code> <code>Datum</code> <p>The <code>Datum</code> to extract metadata from.</p> required Source code in <code>valor/metatypes.py</code> <pre><code>@classmethod\ndef from_datum(cls, datum: Datum):\n    \"\"\"\n    Creates an `ImageMetadata` object from a `Datum`.\n\n    Parameters\n    ----------\n    datum : Datum\n        The `Datum` to extract metadata from.\n    \"\"\"\n    if not cls.valid(datum):\n        raise ValueError(\n            f\"`datum` does not contain height and/or width in metadata `{datum.metadata}`\"\n        )\n    metadata = dict(datum.metadata)\n    width = cast(int, metadata.pop(\"width\"))\n    height = cast(int, metadata.pop(\"height\"))\n    img = cls(\n        uid=datum.uid,\n        height=int(height),\n        width=int(width),\n        metadata=metadata,\n    )\n    return img\n</code></pre>"},{"location":"client_api/ImageMetadata/#valor.metatypes.ImageMetadata.from_pil","title":"<code>valor.metatypes.ImageMetadata.from_pil(uid, image)</code>  <code>classmethod</code>","text":"<p>Creates an <code>ImageMetadata</code> object from an image.</p> <p>Parameters:</p> Name Type Description Default <code>uid</code> <code>str</code> <p>The UID of the image.</p> required <code>image</code> <code>Image</code> <p>The image to create metadata for.</p> required Source code in <code>valor/metatypes.py</code> <pre><code>@classmethod\ndef from_pil(cls, uid: str, image: PIL.Image.Image):\n    \"\"\"\n    Creates an `ImageMetadata` object from an image.\n\n    Parameters\n    ----------\n    uid : str\n        The UID of the image.\n    image : PIL.Image.Image\n        The image to create metadata for.\n    \"\"\"\n    width, height = image.size\n    return cls(\n        uid=uid,\n        height=int(height),\n        width=int(width),\n    )\n</code></pre>"},{"location":"client_api/ImageMetadata/#valor.metatypes.ImageMetadata.to_datum","title":"<code>valor.metatypes.ImageMetadata.to_datum()</code>","text":"<p>Converts an <code>ImageMetadata</code> object into a <code>Datum</code>.</p> Source code in <code>valor/metatypes.py</code> <pre><code>def to_datum(self) -&gt; Datum:\n    \"\"\"\n    Converts an `ImageMetadata` object into a `Datum`.\n    \"\"\"\n    metadata = dict(self.metadata) if self.metadata else {}\n\n    metadata[\"height\"] = self.height\n    metadata[\"width\"] = self.width\n    datum = Datum(\n        uid=self.uid,\n        metadata=metadata,\n    )\n    return datum\n</code></pre>"},{"location":"client_api/ImageMetadata/#valor.metatypes.ImageMetadata.valid","title":"<code>valor.metatypes.ImageMetadata.valid(datum)</code>  <code>staticmethod</code>","text":"<p>Asserts whether the <code>Datum's</code> height and width is a valid subset of the image's height and width.</p> <p>Parameters:</p> Name Type Description Default <code>datum</code> <code>Datum</code> <p>The <code>Datum</code> to check validity for.</p> required Source code in <code>valor/metatypes.py</code> <pre><code>@staticmethod\ndef valid(datum: Datum) -&gt; bool:\n    \"\"\"\n    Asserts whether the `Datum's` height and width is a valid subset of the image's height and width.\n\n    Parameters\n    ----------\n    datum : Datum\n        The `Datum` to check validity for.\n    \"\"\"\n    return {\"height\", \"width\"}.issubset(datum.metadata)\n</code></pre>"},{"location":"client_api/Label/","title":"Label","text":"<p>An object for labeling datasets, models, and annotations.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The class key of the label.</p> required <code>value</code> <code>str</code> <p>The class value of the label.</p> required <code>score</code> <code>float</code> <p>The score associated with the label (if applicable).</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>filter_by</code> <code>filter_factory</code> <p>Declarative mappers used to create filters.</p> Source code in <code>valor/coretypes.py</code> <pre><code>class Label:\n    \"\"\"\n    An object for labeling datasets, models, and annotations.\n\n    Parameters\n    ----------\n    key : str\n        The class key of the label.\n    value : str\n        The class value of the label.\n    score : float, optional\n        The score associated with the label (if applicable).\n\n    Attributes\n    ----------\n    filter_by : filter_factory\n        Declarative mappers used to create filters.\n    \"\"\"\n\n    value = StringProperty(\"label_values\")\n    key = StringProperty(\"label_keys\")\n    score = NumericProperty(\"label_scores\")\n\n    def __init__(\n        self,\n        key: str,\n        value: str,\n        score: Union[float, np.floating, None] = None,\n    ):\n        if not isinstance(key, str):\n            raise TypeError(\"Attribute `key` should have type `str`.\")\n        if not isinstance(value, str):\n            raise TypeError(\"Attribute `value` should have type `str`.\")\n        if score is not None:\n            if not is_float(score):\n                raise TypeError(\n                    \"Attribute `score` should be a floating-point number or `None`.\"\n                )\n\n        self.key = key\n        self.value = value\n        self.score = score\n\n    def __str__(self) -&gt; str:\n        \"\"\"Dumps the object into a JSON formatted string.\"\"\"\n        return json.dumps(self.to_dict(), indent=4)\n\n    def __repr__(self) -&gt; str:\n        return str(self.tuple())\n\n    def to_dict(self) -&gt; Dict[str, Union[str, float, np.floating, None]]:\n        \"\"\"\n        Defines how a `valor.Label` object is serialized into a dictionary.\n\n        Returns\n        ----------\n        dict\n            A dictionary describing a label.\n        \"\"\"\n        return {\n            \"key\": self.key,\n            \"value\": self.value,\n            \"score\": self.score,\n        }\n\n    @classmethod\n    def from_dict(cls, resp) -&gt; Label:\n        \"\"\"\n        Construct a label from a dictionary.\n\n        Parameters\n        ----------\n        resp : dict\n            The dictionary containing a label.\n\n        Returns\n        -------\n        valor.Label\n        \"\"\"\n        return cls(**resp)\n\n    def __eq__(self, other) -&gt; bool:\n        \"\"\"\n        Defines how `Labels` are compared to one another.\n\n        Parameters\n        ----------\n        other : Label\n            The object to compare with the `Label`.\n\n        Returns\n        ----------\n        boolean\n            A boolean describing whether the two objects are equal.\n        \"\"\"\n        # type mismatch\n        if type(other) is not type(self):\n            return False\n\n        # k,v mismatch\n        if self.key != other.key or self.value != other.value:\n            return False\n\n        # score is None\n        if self.score is None or other.score is None:\n            return (other.score is None) == (self.score is None)\n\n        # scores not equal\n        if is_float(self.score) and is_float(other.score):\n            return bool(np.isclose(self.score, other.score))\n\n        return False\n\n    def __hash__(self) -&gt; int:\n        \"\"\"\n        Defines how a `Label` is hashed.\n\n        Returns\n        ----------\n        int\n            The hashed 'Label`.\n        \"\"\"\n        return hash(f\"key:{self.key},value:{self.value},score:{self.score}\")\n\n    def tuple(self) -&gt; Tuple[str, str, Union[float, np.floating, None]]:\n        \"\"\"\n        Defines how the `Label` is turned into a tuple.\n\n        Returns\n        ----------\n        tuple\n            A tuple of the `Label's` arguments.\n        \"\"\"\n        return (self.key, self.value, self.score)\n</code></pre>"},{"location":"client_api/Label/#valor.Label-functions","title":"Functions","text":""},{"location":"client_api/Label/#valor.Label.__eq__","title":"<code>valor.Label.__eq__(other)</code>","text":"<p>Defines how <code>Labels</code> are compared to one another.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Label</code> <p>The object to compare with the <code>Label</code>.</p> required <p>Returns:</p> Type Description <code>boolean</code> <p>A boolean describing whether the two objects are equal.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def __eq__(self, other) -&gt; bool:\n    \"\"\"\n    Defines how `Labels` are compared to one another.\n\n    Parameters\n    ----------\n    other : Label\n        The object to compare with the `Label`.\n\n    Returns\n    ----------\n    boolean\n        A boolean describing whether the two objects are equal.\n    \"\"\"\n    # type mismatch\n    if type(other) is not type(self):\n        return False\n\n    # k,v mismatch\n    if self.key != other.key or self.value != other.value:\n        return False\n\n    # score is None\n    if self.score is None or other.score is None:\n        return (other.score is None) == (self.score is None)\n\n    # scores not equal\n    if is_float(self.score) and is_float(other.score):\n        return bool(np.isclose(self.score, other.score))\n\n    return False\n</code></pre>"},{"location":"client_api/Label/#valor.Label.__hash__","title":"<code>valor.Label.__hash__()</code>","text":"<p>Defines how a <code>Label</code> is hashed.</p> <p>Returns:</p> Type Description <code>int</code> <p>The hashed 'Label`.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def __hash__(self) -&gt; int:\n    \"\"\"\n    Defines how a `Label` is hashed.\n\n    Returns\n    ----------\n    int\n        The hashed 'Label`.\n    \"\"\"\n    return hash(f\"key:{self.key},value:{self.value},score:{self.score}\")\n</code></pre>"},{"location":"client_api/Label/#valor.Label.__str__","title":"<code>valor.Label.__str__()</code>","text":"<p>Dumps the object into a JSON formatted string.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Dumps the object into a JSON formatted string.\"\"\"\n    return json.dumps(self.to_dict(), indent=4)\n</code></pre>"},{"location":"client_api/Label/#valor.Label.from_dict","title":"<code>valor.Label.from_dict(resp)</code>  <code>classmethod</code>","text":"<p>Construct a label from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>resp</code> <code>dict</code> <p>The dictionary containing a label.</p> required <p>Returns:</p> Type Description <code>Label</code> Source code in <code>valor/coretypes.py</code> <pre><code>@classmethod\ndef from_dict(cls, resp) -&gt; Label:\n    \"\"\"\n    Construct a label from a dictionary.\n\n    Parameters\n    ----------\n    resp : dict\n        The dictionary containing a label.\n\n    Returns\n    -------\n    valor.Label\n    \"\"\"\n    return cls(**resp)\n</code></pre>"},{"location":"client_api/Label/#valor.Label.to_dict","title":"<code>valor.Label.to_dict()</code>","text":"<p>Defines how a <code>valor.Label</code> object is serialized into a dictionary.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary describing a label.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def to_dict(self) -&gt; Dict[str, Union[str, float, np.floating, None]]:\n    \"\"\"\n    Defines how a `valor.Label` object is serialized into a dictionary.\n\n    Returns\n    ----------\n    dict\n        A dictionary describing a label.\n    \"\"\"\n    return {\n        \"key\": self.key,\n        \"value\": self.value,\n        \"score\": self.score,\n    }\n</code></pre>"},{"location":"client_api/Label/#valor.Label.tuple","title":"<code>valor.Label.tuple()</code>","text":"<p>Defines how the <code>Label</code> is turned into a tuple.</p> <p>Returns:</p> Type Description <code>tuple</code> <p>A tuple of the <code>Label's</code> arguments.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def tuple(self) -&gt; Tuple[str, str, Union[float, np.floating, None]]:\n    \"\"\"\n    Defines how the `Label` is turned into a tuple.\n\n    Returns\n    ----------\n    tuple\n        A tuple of the `Label's` arguments.\n    \"\"\"\n    return (self.key, self.value, self.score)\n</code></pre>"},{"location":"client_api/Model/","title":"Model","text":"<p>A class describing a model that was trained on a particular dataset.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the model.</p> required <code>metadata</code> <code>dict</code> <p>A dictionary of metadata that describes the model.</p> <code>None</code> Source code in <code>valor/coretypes.py</code> <pre><code>class Model:\n    \"\"\"\n    A class describing a model that was trained on a particular dataset.\n\n    Parameters\n    ----------\n    name : str\n        The name of the model.\n    metadata : dict\n        A dictionary of metadata that describes the model.\n    \"\"\"\n\n    name = StringProperty(\"model_names\")\n    metadata = DictionaryProperty(\"model_metadata\")\n\n    def __init__(\n        self,\n        name: str,\n        metadata: Optional[MetadataType] = None,\n        connection: Optional[ClientConnection] = None,\n    ):\n        \"\"\"\n        Create or get a `Model` object.\n\n        Parameters\n        ----------\n        name : str\n            The name of the model.\n        metadata : dict\n            An optional dictionary of metadata that describes the dataset.\n        connection : ClientConnnetion\n            An optional Valor client object for interacting with the API.\n        \"\"\"\n        self.conn = connection\n        self.name = name\n        self.metadata = metadata if metadata else {}\n\n        # validation\n        if not isinstance(self.name, str):\n            raise TypeError(\"`name` should be of type `str`\")\n        validate_metadata(self.metadata)\n\n    @classmethod\n    def create(\n        cls,\n        name: str,\n        metadata: Optional[MetadataType] = None,\n    ) -&gt; Model:\n        \"\"\"\n        Creates a model that persists in the back end.\n\n        Parameters\n        ----------\n        name : str\n            The name of the model.\n        metadata : dict\n            A dictionary of metadata that describes the model.\n\n        Returns\n        -------\n        valor.Model\n            The created model.\n        \"\"\"\n        model = cls(\n            name=name,\n            metadata=metadata,\n        )\n        Client(model.conn).create_model(model)\n        return model\n\n    @classmethod\n    def get(\n        cls,\n        name: str,\n    ) -&gt; Union[Model, None]:\n        \"\"\"\n        Retrieves a model from the back end database.\n\n        Parameters\n        ----------\n        name : str\n            The name of the model.\n\n        Returns\n        -------\n        Union[valor.Model, None]\n            The model or 'None' if it doesn't exist.\n        \"\"\"\n        return Client().get_model(name)\n\n    @classmethod\n    def from_dict(\n        cls, resp: dict, connection: Optional[ClientConnection] = None\n    ) -&gt; Model:\n        \"\"\"\n        Construct a model from a dictionary.\n\n        Parameters\n        ----------\n        resp : dict\n            The dictionary containing a model.\n        connection : ClientConnection, optional\n            Option to share a ClientConnection rather than request a new one.\n\n        Returns\n        -------\n        valor.Model\n        \"\"\"\n        resp.pop(\"id\")\n        resp[\"metadata\"] = load_metadata(resp[\"metadata\"])\n        return cls(**resp, connection=connection)\n\n    def to_dict(self, id: Optional[int] = None) -&gt; dict:\n        \"\"\"\n        Defines how a `valor.Model` object is serialized into a dictionary.\n\n        Returns\n        ----------\n        dict\n            A dictionary describing a model.\n        \"\"\"\n        return {\n            \"id\": id,\n            \"name\": self.name,\n            \"metadata\": dump_metadata(self.metadata),\n        }\n\n    def __str__(self) -&gt; str:\n        \"\"\"Dumps the object into a JSON formatted string.\"\"\"\n        objdict = self.to_dict()\n        objdict.pop(\"id\")\n        return json.dumps(objdict, indent=4)\n\n    def add_prediction(\n        self,\n        dataset: Dataset,\n        prediction: Prediction,\n    ) -&gt; None:\n        \"\"\"\n        Add a prediction to the model.\n\n        Parameters\n        ----------\n        dataset : valor.Dataset\n            The dataset that is being operated over.\n        prediction : valor.Prediction\n            The prediction to create.\n        \"\"\"\n        Client(self.conn).create_predictions(\n            dataset=dataset,\n            model=self,\n            predictions=[prediction],\n        )\n\n    def add_predictions(\n        self,\n        dataset: Dataset,\n        predictions: List[Prediction],\n    ) -&gt; None:\n        \"\"\"\n        Add multiple predictions to the model.\n\n        Parameters\n        ----------\n        dataset : valor.Dataset\n            The dataset that is being operated over.\n        predictions : List[valor.Prediction]\n            The predictions to create.\n        \"\"\"\n        Client(self.conn).create_predictions(\n            dataset=dataset,\n            model=self,\n            predictions=predictions,\n        )\n\n    def get_prediction(\n        self, dataset: Union[Dataset, str], datum: Union[Datum, str]\n    ) -&gt; Union[Prediction, None]:\n        \"\"\"\n        Get a particular prediction.\n\n        Parameters\n        ----------\n        dataset: Union[Dataset, str]\n            The dataset the datum belongs to.\n        datum: Union[Datum, str]\n            The desired datum.\n\n        Returns\n        ----------\n        Union[Prediction, None]\n            The matching prediction or 'None' if it doesn't exist.\n        \"\"\"\n        return Client(self.conn).get_prediction(\n            dataset=dataset, model=self, datum=datum\n        )\n\n    def finalize_inferences(self, dataset: Union[Dataset, str]) -&gt; None:\n        \"\"\"\n        Finalizes the model over a dataset such that new predictions cannot be added to it.\n        \"\"\"\n        if isinstance(dataset, Dataset):\n            dataset = dataset.name\n        return Client(self.conn).finalize_inferences(\n            dataset=dataset, model=self\n        )\n\n    def _format_constraints(\n        self,\n        datasets: Optional[Union[Dataset, List[Dataset]]] = None,\n        filter_by: Optional[FilterType] = None,\n    ) -&gt; Filter:\n        \"\"\"Formats the 'datum_filter' for any evaluation requests.\"\"\"\n\n        # get list of dataset names\n        dataset_names_from_obj = []\n        if isinstance(datasets, list):\n            dataset_names_from_obj = [dataset.name for dataset in datasets]\n        elif isinstance(datasets, Dataset):\n            dataset_names_from_obj = [datasets.name]\n\n        # create a 'schemas.Filter' object from the constraints.\n        filter_ = _format_filter(filter_by)\n\n        # reset model name\n        filter_.model_names = None\n        filter_.model_metadata = None\n\n        # set dataset names\n        if not filter_.dataset_names:\n            filter_.dataset_names = []\n        filter_.dataset_names.extend(dataset_names_from_obj)\n        return filter_\n\n    def _create_label_map(\n        self,\n        label_map: Optional[Dict[Label, Label]],\n    ) -&gt; Union[List[List[List[str]]], None]:\n        \"\"\"Convert a dictionary of label maps to a serializable list format.\"\"\"\n        if not label_map:\n            return None\n\n        if not isinstance(label_map, dict) or not all(\n            [\n                isinstance(key, Label) and isinstance(value, Label)\n                for key, value in label_map.items()\n            ]\n        ):\n            raise TypeError(\n                \"label_map should be a dictionary with valid Labels for both the key and value.\"\n            )\n\n        return_value = [\n            [[key.key, key.value], [value.key, value.value]]\n            for key, value in label_map.items()\n        ]\n\n        return return_value\n\n    def evaluate_classification(\n        self,\n        datasets: Optional[Union[Dataset, List[Dataset]]] = None,\n        filter_by: Optional[FilterType] = None,\n        label_map: Optional[Dict[Label, Label]] = None,\n    ) -&gt; Evaluation:\n        \"\"\"\n        Start a classification evaluation job.\n\n        Parameters\n        ----------\n        datasets : Union[Dataset, List[Dataset]], optional\n            The dataset or list of datasets to evaluate against.\n        filter_by : FilterType, optional\n            Optional set of constraints to filter evaluation by.\n        label_map : Dict[Label, Label], optional\n            Optional mapping of individual labels to a grouper label. Useful when you need to evaluate performance using labels that differ across datasets and models.\n\n        Returns\n        -------\n        Evaluation\n            A job object that can be used to track the status of the job and get the metrics of it upon completion.\n        \"\"\"\n        if not datasets and not filter_by:\n            raise ValueError(\n                \"Evaluation requires the definition of either datasets, dataset filters or both.\"\n            )\n\n        # format request\n        datum_filter = self._format_constraints(datasets, filter_by)\n        request = EvaluationRequest(\n            model_names=[self.name],\n            datum_filter=datum_filter,\n            parameters=EvaluationParameters(\n                task_type=TaskType.CLASSIFICATION,\n                label_map=self._create_label_map(label_map=label_map),\n            ),\n        )\n\n        # create evaluation\n        evaluation = Client(self.conn).evaluate(request)\n        if len(evaluation) != 1:\n            raise RuntimeError\n        return evaluation[0]\n\n    def evaluate_detection(\n        self,\n        datasets: Optional[Union[Dataset, List[Dataset]]] = None,\n        filter_by: Optional[FilterType] = None,\n        convert_annotations_to_type: Optional[AnnotationType] = None,\n        iou_thresholds_to_compute: Optional[List[float]] = None,\n        iou_thresholds_to_return: Optional[List[float]] = None,\n        label_map: Optional[Dict[Label, Label]] = None,\n        recall_score_threshold: float = 0,\n    ) -&gt; Evaluation:\n        \"\"\"\n        Start an object-detection evaluation job.\n\n        Parameters\n        ----------\n        datasets : Union[Dataset, List[Dataset]], optional\n            The dataset or list of datasets to evaluate against.\n        filter_by : FilterType, optional\n            Optional set of constraints to filter evaluation by.\n        convert_annotations_to_type : enums.AnnotationType, optional\n            Forces the object detection evaluation to compute over this type.\n        iou_thresholds_to_compute : List[float], optional\n            Thresholds to compute mAP against.\n        iou_thresholds_to_return : List[float], optional\n            Thresholds to return AP for. Must be subset of `iou_thresholds_to_compute`.\n        label_map : Dict[Label, Label], optional\n            Optional mapping of individual labels to a grouper label. Useful when you need to evaluate performance using labels that differ across datasets and models.\n        recall_score_threshold: float, default=0\n            The confidence score threshold for use when determining whether to count a prediction as a true positive or not while calculating Average Recall.\n        Returns\n        -------\n        Evaluation\n            A job object that can be used to track the status of the job and get the metrics of it upon completion.\n        \"\"\"\n        if iou_thresholds_to_compute is None:\n            iou_thresholds_to_compute = [\n                round(0.5 + 0.05 * i, 2) for i in range(10)\n            ]\n        if iou_thresholds_to_return is None:\n            iou_thresholds_to_return = [0.5, 0.75]\n\n        # format request\n        parameters = EvaluationParameters(\n            task_type=TaskType.OBJECT_DETECTION,\n            convert_annotations_to_type=convert_annotations_to_type,\n            iou_thresholds_to_compute=iou_thresholds_to_compute,\n            iou_thresholds_to_return=iou_thresholds_to_return,\n            label_map=self._create_label_map(label_map=label_map),\n            recall_score_threshold=recall_score_threshold,\n        )\n        datum_filter = self._format_constraints(datasets, filter_by)\n        request = EvaluationRequest(\n            model_names=[self.name],\n            datum_filter=datum_filter,\n            parameters=parameters,\n        )\n\n        # create evaluation\n        evaluation = Client(self.conn).evaluate(request)\n        if len(evaluation) != 1:\n            raise RuntimeError\n        return evaluation[0]\n\n    def evaluate_segmentation(\n        self,\n        datasets: Optional[Union[Dataset, List[Dataset]]] = None,\n        filter_by: Optional[FilterType] = None,\n        label_map: Optional[Dict[Label, Label]] = None,\n    ) -&gt; Evaluation:\n        \"\"\"\n        Start a semantic-segmentation evaluation job.\n\n        Parameters\n        ----------\n        datasets : Union[Dataset, List[Dataset]], optional\n            The dataset or list of datasets to evaluate against.\n        filter_by : FilterType, optional\n            Optional set of constraints to filter evaluation by.\n        label_map : Dict[Label, Label], optional\n            Optional mapping of individual labels to a grouper label. Useful when you need to evaluate performance using labels that differ across datasets and models.\n\n        Returns\n        -------\n        Evaluation\n            A job object that can be used to track the status of the job and get the metrics of it upon completion\n        \"\"\"\n        # format request\n        datum_filter = self._format_constraints(datasets, filter_by)\n        request = EvaluationRequest(\n            model_names=[self.name],\n            datum_filter=datum_filter,\n            parameters=EvaluationParameters(\n                task_type=TaskType.SEMANTIC_SEGMENTATION,\n                label_map=self._create_label_map(label_map=label_map),\n            ),\n        )\n\n        # create evaluation\n        evaluation = Client(self.conn).evaluate(request)\n        if len(evaluation) != 1:\n            raise RuntimeError\n        return evaluation[0]\n\n    def delete(self, timeout: int = 0):\n        \"\"\"\n        Delete the `Model` object from the back end.\n\n        Parameters\n        ----------\n        timeout : int, default=0\n            Sets a timeout in seconds.\n        \"\"\"\n        Client(self.conn).delete_model(self.name, timeout)\n\n    def get_labels(\n        self,\n    ) -&gt; List[Label]:\n        \"\"\"\n        Get all labels associated with a given model.\n\n        Returns\n        ----------\n        List[Label]\n            A list of `Labels` associated with the model.\n        \"\"\"\n        return Client(self.conn).get_labels_from_model(self)\n\n    def get_evaluations(\n        self,\n    ) -&gt; List[Evaluation]:\n        \"\"\"\n        Get all evaluations associated with a given model.\n\n        Returns\n        ----------\n        List[Evaluation]\n            A list of `Evaluations` associated with the model.\n        \"\"\"\n        return Client(self.conn).get_evaluations(models=[self])\n</code></pre>"},{"location":"client_api/Model/#valor.Model-functions","title":"Functions","text":""},{"location":"client_api/Model/#valor.Model.__init__","title":"<code>valor.Model.__init__(name, metadata=None, connection=None)</code>","text":"<p>Create or get a <code>Model</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the model.</p> required <code>metadata</code> <code>dict</code> <p>An optional dictionary of metadata that describes the dataset.</p> <code>None</code> <code>connection</code> <code>ClientConnnetion</code> <p>An optional Valor client object for interacting with the API.</p> <code>None</code> Source code in <code>valor/coretypes.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    metadata: Optional[MetadataType] = None,\n    connection: Optional[ClientConnection] = None,\n):\n    \"\"\"\n    Create or get a `Model` object.\n\n    Parameters\n    ----------\n    name : str\n        The name of the model.\n    metadata : dict\n        An optional dictionary of metadata that describes the dataset.\n    connection : ClientConnnetion\n        An optional Valor client object for interacting with the API.\n    \"\"\"\n    self.conn = connection\n    self.name = name\n    self.metadata = metadata if metadata else {}\n\n    # validation\n    if not isinstance(self.name, str):\n        raise TypeError(\"`name` should be of type `str`\")\n    validate_metadata(self.metadata)\n</code></pre>"},{"location":"client_api/Model/#valor.Model.__str__","title":"<code>valor.Model.__str__()</code>","text":"<p>Dumps the object into a JSON formatted string.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Dumps the object into a JSON formatted string.\"\"\"\n    objdict = self.to_dict()\n    objdict.pop(\"id\")\n    return json.dumps(objdict, indent=4)\n</code></pre>"},{"location":"client_api/Model/#valor.Model.add_prediction","title":"<code>valor.Model.add_prediction(dataset, prediction)</code>","text":"<p>Add a prediction to the model.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>The dataset that is being operated over.</p> required <code>prediction</code> <code>Prediction</code> <p>The prediction to create.</p> required Source code in <code>valor/coretypes.py</code> <pre><code>def add_prediction(\n    self,\n    dataset: Dataset,\n    prediction: Prediction,\n) -&gt; None:\n    \"\"\"\n    Add a prediction to the model.\n\n    Parameters\n    ----------\n    dataset : valor.Dataset\n        The dataset that is being operated over.\n    prediction : valor.Prediction\n        The prediction to create.\n    \"\"\"\n    Client(self.conn).create_predictions(\n        dataset=dataset,\n        model=self,\n        predictions=[prediction],\n    )\n</code></pre>"},{"location":"client_api/Model/#valor.Model.add_predictions","title":"<code>valor.Model.add_predictions(dataset, predictions)</code>","text":"<p>Add multiple predictions to the model.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>The dataset that is being operated over.</p> required <code>predictions</code> <code>List[Prediction]</code> <p>The predictions to create.</p> required Source code in <code>valor/coretypes.py</code> <pre><code>def add_predictions(\n    self,\n    dataset: Dataset,\n    predictions: List[Prediction],\n) -&gt; None:\n    \"\"\"\n    Add multiple predictions to the model.\n\n    Parameters\n    ----------\n    dataset : valor.Dataset\n        The dataset that is being operated over.\n    predictions : List[valor.Prediction]\n        The predictions to create.\n    \"\"\"\n    Client(self.conn).create_predictions(\n        dataset=dataset,\n        model=self,\n        predictions=predictions,\n    )\n</code></pre>"},{"location":"client_api/Model/#valor.Model.create","title":"<code>valor.Model.create(name, metadata=None)</code>  <code>classmethod</code>","text":"<p>Creates a model that persists in the back end.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the model.</p> required <code>metadata</code> <code>dict</code> <p>A dictionary of metadata that describes the model.</p> <code>None</code> <p>Returns:</p> Type Description <code>Model</code> <p>The created model.</p> Source code in <code>valor/coretypes.py</code> <pre><code>@classmethod\ndef create(\n    cls,\n    name: str,\n    metadata: Optional[MetadataType] = None,\n) -&gt; Model:\n    \"\"\"\n    Creates a model that persists in the back end.\n\n    Parameters\n    ----------\n    name : str\n        The name of the model.\n    metadata : dict\n        A dictionary of metadata that describes the model.\n\n    Returns\n    -------\n    valor.Model\n        The created model.\n    \"\"\"\n    model = cls(\n        name=name,\n        metadata=metadata,\n    )\n    Client(model.conn).create_model(model)\n    return model\n</code></pre>"},{"location":"client_api/Model/#valor.Model.delete","title":"<code>valor.Model.delete(timeout=0)</code>","text":"<p>Delete the <code>Model</code> object from the back end.</p> <p>Parameters:</p> Name Type Description Default <code>timeout</code> <code>int</code> <p>Sets a timeout in seconds.</p> <code>0</code> Source code in <code>valor/coretypes.py</code> <pre><code>def delete(self, timeout: int = 0):\n    \"\"\"\n    Delete the `Model` object from the back end.\n\n    Parameters\n    ----------\n    timeout : int, default=0\n        Sets a timeout in seconds.\n    \"\"\"\n    Client(self.conn).delete_model(self.name, timeout)\n</code></pre>"},{"location":"client_api/Model/#valor.Model.evaluate_classification","title":"<code>valor.Model.evaluate_classification(datasets=None, filter_by=None, label_map=None)</code>","text":"<p>Start a classification evaluation job.</p> <p>Parameters:</p> Name Type Description Default <code>datasets</code> <code>Union[Dataset, List[Dataset]]</code> <p>The dataset or list of datasets to evaluate against.</p> <code>None</code> <code>filter_by</code> <code>FilterType</code> <p>Optional set of constraints to filter evaluation by.</p> <code>None</code> <code>label_map</code> <code>Dict[Label, Label]</code> <p>Optional mapping of individual labels to a grouper label. Useful when you need to evaluate performance using labels that differ across datasets and models.</p> <code>None</code> <p>Returns:</p> Type Description <code>Evaluation</code> <p>A job object that can be used to track the status of the job and get the metrics of it upon completion.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def evaluate_classification(\n    self,\n    datasets: Optional[Union[Dataset, List[Dataset]]] = None,\n    filter_by: Optional[FilterType] = None,\n    label_map: Optional[Dict[Label, Label]] = None,\n) -&gt; Evaluation:\n    \"\"\"\n    Start a classification evaluation job.\n\n    Parameters\n    ----------\n    datasets : Union[Dataset, List[Dataset]], optional\n        The dataset or list of datasets to evaluate against.\n    filter_by : FilterType, optional\n        Optional set of constraints to filter evaluation by.\n    label_map : Dict[Label, Label], optional\n        Optional mapping of individual labels to a grouper label. Useful when you need to evaluate performance using labels that differ across datasets and models.\n\n    Returns\n    -------\n    Evaluation\n        A job object that can be used to track the status of the job and get the metrics of it upon completion.\n    \"\"\"\n    if not datasets and not filter_by:\n        raise ValueError(\n            \"Evaluation requires the definition of either datasets, dataset filters or both.\"\n        )\n\n    # format request\n    datum_filter = self._format_constraints(datasets, filter_by)\n    request = EvaluationRequest(\n        model_names=[self.name],\n        datum_filter=datum_filter,\n        parameters=EvaluationParameters(\n            task_type=TaskType.CLASSIFICATION,\n            label_map=self._create_label_map(label_map=label_map),\n        ),\n    )\n\n    # create evaluation\n    evaluation = Client(self.conn).evaluate(request)\n    if len(evaluation) != 1:\n        raise RuntimeError\n    return evaluation[0]\n</code></pre>"},{"location":"client_api/Model/#valor.Model.evaluate_detection","title":"<code>valor.Model.evaluate_detection(datasets=None, filter_by=None, convert_annotations_to_type=None, iou_thresholds_to_compute=None, iou_thresholds_to_return=None, label_map=None, recall_score_threshold=0)</code>","text":"<p>Start an object-detection evaluation job.</p> <p>Parameters:</p> Name Type Description Default <code>datasets</code> <code>Union[Dataset, List[Dataset]]</code> <p>The dataset or list of datasets to evaluate against.</p> <code>None</code> <code>filter_by</code> <code>FilterType</code> <p>Optional set of constraints to filter evaluation by.</p> <code>None</code> <code>convert_annotations_to_type</code> <code>AnnotationType</code> <p>Forces the object detection evaluation to compute over this type.</p> <code>None</code> <code>iou_thresholds_to_compute</code> <code>List[float]</code> <p>Thresholds to compute mAP against.</p> <code>None</code> <code>iou_thresholds_to_return</code> <code>List[float]</code> <p>Thresholds to return AP for. Must be subset of <code>iou_thresholds_to_compute</code>.</p> <code>None</code> <code>label_map</code> <code>Dict[Label, Label]</code> <p>Optional mapping of individual labels to a grouper label. Useful when you need to evaluate performance using labels that differ across datasets and models.</p> <code>None</code> <code>recall_score_threshold</code> <code>float</code> <p>The confidence score threshold for use when determining whether to count a prediction as a true positive or not while calculating Average Recall.</p> <code>0</code> <p>Returns:</p> Type Description <code>Evaluation</code> <p>A job object that can be used to track the status of the job and get the metrics of it upon completion.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def evaluate_detection(\n    self,\n    datasets: Optional[Union[Dataset, List[Dataset]]] = None,\n    filter_by: Optional[FilterType] = None,\n    convert_annotations_to_type: Optional[AnnotationType] = None,\n    iou_thresholds_to_compute: Optional[List[float]] = None,\n    iou_thresholds_to_return: Optional[List[float]] = None,\n    label_map: Optional[Dict[Label, Label]] = None,\n    recall_score_threshold: float = 0,\n) -&gt; Evaluation:\n    \"\"\"\n    Start an object-detection evaluation job.\n\n    Parameters\n    ----------\n    datasets : Union[Dataset, List[Dataset]], optional\n        The dataset or list of datasets to evaluate against.\n    filter_by : FilterType, optional\n        Optional set of constraints to filter evaluation by.\n    convert_annotations_to_type : enums.AnnotationType, optional\n        Forces the object detection evaluation to compute over this type.\n    iou_thresholds_to_compute : List[float], optional\n        Thresholds to compute mAP against.\n    iou_thresholds_to_return : List[float], optional\n        Thresholds to return AP for. Must be subset of `iou_thresholds_to_compute`.\n    label_map : Dict[Label, Label], optional\n        Optional mapping of individual labels to a grouper label. Useful when you need to evaluate performance using labels that differ across datasets and models.\n    recall_score_threshold: float, default=0\n        The confidence score threshold for use when determining whether to count a prediction as a true positive or not while calculating Average Recall.\n    Returns\n    -------\n    Evaluation\n        A job object that can be used to track the status of the job and get the metrics of it upon completion.\n    \"\"\"\n    if iou_thresholds_to_compute is None:\n        iou_thresholds_to_compute = [\n            round(0.5 + 0.05 * i, 2) for i in range(10)\n        ]\n    if iou_thresholds_to_return is None:\n        iou_thresholds_to_return = [0.5, 0.75]\n\n    # format request\n    parameters = EvaluationParameters(\n        task_type=TaskType.OBJECT_DETECTION,\n        convert_annotations_to_type=convert_annotations_to_type,\n        iou_thresholds_to_compute=iou_thresholds_to_compute,\n        iou_thresholds_to_return=iou_thresholds_to_return,\n        label_map=self._create_label_map(label_map=label_map),\n        recall_score_threshold=recall_score_threshold,\n    )\n    datum_filter = self._format_constraints(datasets, filter_by)\n    request = EvaluationRequest(\n        model_names=[self.name],\n        datum_filter=datum_filter,\n        parameters=parameters,\n    )\n\n    # create evaluation\n    evaluation = Client(self.conn).evaluate(request)\n    if len(evaluation) != 1:\n        raise RuntimeError\n    return evaluation[0]\n</code></pre>"},{"location":"client_api/Model/#valor.Model.evaluate_segmentation","title":"<code>valor.Model.evaluate_segmentation(datasets=None, filter_by=None, label_map=None)</code>","text":"<p>Start a semantic-segmentation evaluation job.</p> <p>Parameters:</p> Name Type Description Default <code>datasets</code> <code>Union[Dataset, List[Dataset]]</code> <p>The dataset or list of datasets to evaluate against.</p> <code>None</code> <code>filter_by</code> <code>FilterType</code> <p>Optional set of constraints to filter evaluation by.</p> <code>None</code> <code>label_map</code> <code>Dict[Label, Label]</code> <p>Optional mapping of individual labels to a grouper label. Useful when you need to evaluate performance using labels that differ across datasets and models.</p> <code>None</code> <p>Returns:</p> Type Description <code>Evaluation</code> <p>A job object that can be used to track the status of the job and get the metrics of it upon completion</p> Source code in <code>valor/coretypes.py</code> <pre><code>def evaluate_segmentation(\n    self,\n    datasets: Optional[Union[Dataset, List[Dataset]]] = None,\n    filter_by: Optional[FilterType] = None,\n    label_map: Optional[Dict[Label, Label]] = None,\n) -&gt; Evaluation:\n    \"\"\"\n    Start a semantic-segmentation evaluation job.\n\n    Parameters\n    ----------\n    datasets : Union[Dataset, List[Dataset]], optional\n        The dataset or list of datasets to evaluate against.\n    filter_by : FilterType, optional\n        Optional set of constraints to filter evaluation by.\n    label_map : Dict[Label, Label], optional\n        Optional mapping of individual labels to a grouper label. Useful when you need to evaluate performance using labels that differ across datasets and models.\n\n    Returns\n    -------\n    Evaluation\n        A job object that can be used to track the status of the job and get the metrics of it upon completion\n    \"\"\"\n    # format request\n    datum_filter = self._format_constraints(datasets, filter_by)\n    request = EvaluationRequest(\n        model_names=[self.name],\n        datum_filter=datum_filter,\n        parameters=EvaluationParameters(\n            task_type=TaskType.SEMANTIC_SEGMENTATION,\n            label_map=self._create_label_map(label_map=label_map),\n        ),\n    )\n\n    # create evaluation\n    evaluation = Client(self.conn).evaluate(request)\n    if len(evaluation) != 1:\n        raise RuntimeError\n    return evaluation[0]\n</code></pre>"},{"location":"client_api/Model/#valor.Model.finalize_inferences","title":"<code>valor.Model.finalize_inferences(dataset)</code>","text":"<p>Finalizes the model over a dataset such that new predictions cannot be added to it.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def finalize_inferences(self, dataset: Union[Dataset, str]) -&gt; None:\n    \"\"\"\n    Finalizes the model over a dataset such that new predictions cannot be added to it.\n    \"\"\"\n    if isinstance(dataset, Dataset):\n        dataset = dataset.name\n    return Client(self.conn).finalize_inferences(\n        dataset=dataset, model=self\n    )\n</code></pre>"},{"location":"client_api/Model/#valor.Model.from_dict","title":"<code>valor.Model.from_dict(resp, connection=None)</code>  <code>classmethod</code>","text":"<p>Construct a model from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>resp</code> <code>dict</code> <p>The dictionary containing a model.</p> required <code>connection</code> <code>ClientConnection</code> <p>Option to share a ClientConnection rather than request a new one.</p> <code>None</code> <p>Returns:</p> Type Description <code>Model</code> Source code in <code>valor/coretypes.py</code> <pre><code>@classmethod\ndef from_dict(\n    cls, resp: dict, connection: Optional[ClientConnection] = None\n) -&gt; Model:\n    \"\"\"\n    Construct a model from a dictionary.\n\n    Parameters\n    ----------\n    resp : dict\n        The dictionary containing a model.\n    connection : ClientConnection, optional\n        Option to share a ClientConnection rather than request a new one.\n\n    Returns\n    -------\n    valor.Model\n    \"\"\"\n    resp.pop(\"id\")\n    resp[\"metadata\"] = load_metadata(resp[\"metadata\"])\n    return cls(**resp, connection=connection)\n</code></pre>"},{"location":"client_api/Model/#valor.Model.get","title":"<code>valor.Model.get(name)</code>  <code>classmethod</code>","text":"<p>Retrieves a model from the back end database.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the model.</p> required <p>Returns:</p> Type Description <code>Union[Model, None]</code> <p>The model or 'None' if it doesn't exist.</p> Source code in <code>valor/coretypes.py</code> <pre><code>@classmethod\ndef get(\n    cls,\n    name: str,\n) -&gt; Union[Model, None]:\n    \"\"\"\n    Retrieves a model from the back end database.\n\n    Parameters\n    ----------\n    name : str\n        The name of the model.\n\n    Returns\n    -------\n    Union[valor.Model, None]\n        The model or 'None' if it doesn't exist.\n    \"\"\"\n    return Client().get_model(name)\n</code></pre>"},{"location":"client_api/Model/#valor.Model.get_evaluations","title":"<code>valor.Model.get_evaluations()</code>","text":"<p>Get all evaluations associated with a given model.</p> <p>Returns:</p> Type Description <code>List[Evaluation]</code> <p>A list of <code>Evaluations</code> associated with the model.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def get_evaluations(\n    self,\n) -&gt; List[Evaluation]:\n    \"\"\"\n    Get all evaluations associated with a given model.\n\n    Returns\n    ----------\n    List[Evaluation]\n        A list of `Evaluations` associated with the model.\n    \"\"\"\n    return Client(self.conn).get_evaluations(models=[self])\n</code></pre>"},{"location":"client_api/Model/#valor.Model.get_labels","title":"<code>valor.Model.get_labels()</code>","text":"<p>Get all labels associated with a given model.</p> <p>Returns:</p> Type Description <code>List[Label]</code> <p>A list of <code>Labels</code> associated with the model.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def get_labels(\n    self,\n) -&gt; List[Label]:\n    \"\"\"\n    Get all labels associated with a given model.\n\n    Returns\n    ----------\n    List[Label]\n        A list of `Labels` associated with the model.\n    \"\"\"\n    return Client(self.conn).get_labels_from_model(self)\n</code></pre>"},{"location":"client_api/Model/#valor.Model.get_prediction","title":"<code>valor.Model.get_prediction(dataset, datum)</code>","text":"<p>Get a particular prediction.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Union[Dataset, str]</code> <p>The dataset the datum belongs to.</p> required <code>datum</code> <code>Union[Datum, str]</code> <p>The desired datum.</p> required <p>Returns:</p> Type Description <code>Union[Prediction, None]</code> <p>The matching prediction or 'None' if it doesn't exist.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def get_prediction(\n    self, dataset: Union[Dataset, str], datum: Union[Datum, str]\n) -&gt; Union[Prediction, None]:\n    \"\"\"\n    Get a particular prediction.\n\n    Parameters\n    ----------\n    dataset: Union[Dataset, str]\n        The dataset the datum belongs to.\n    datum: Union[Datum, str]\n        The desired datum.\n\n    Returns\n    ----------\n    Union[Prediction, None]\n        The matching prediction or 'None' if it doesn't exist.\n    \"\"\"\n    return Client(self.conn).get_prediction(\n        dataset=dataset, model=self, datum=datum\n    )\n</code></pre>"},{"location":"client_api/Model/#valor.Model.to_dict","title":"<code>valor.Model.to_dict(id=None)</code>","text":"<p>Defines how a <code>valor.Model</code> object is serialized into a dictionary.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary describing a model.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def to_dict(self, id: Optional[int] = None) -&gt; dict:\n    \"\"\"\n    Defines how a `valor.Model` object is serialized into a dictionary.\n\n    Returns\n    ----------\n    dict\n        A dictionary describing a model.\n    \"\"\"\n    return {\n        \"id\": id,\n        \"name\": self.name,\n        \"metadata\": dump_metadata(self.metadata),\n    }\n</code></pre>"},{"location":"client_api/Prediction/","title":"Prediction","text":"<p>An object describing a prediction (e.g., a machine-drawn bounding box on an image).</p> <p>Parameters:</p> Name Type Description Default <code>datum</code> <code>Datum</code> <p>The <code>Datum</code> associated with the <code>Prediction</code>.</p> required <code>annotations</code> <code>List[Annotation]</code> <p>The list of <code>Annotations</code> associated with the <code>Prediction</code>.</p> required <p>Attributes:</p> Name Type Description <code>score</code> <code>Union[float, int]</code> <p>The score assigned to the <code>Prediction</code>.</p> Source code in <code>valor/coretypes.py</code> <pre><code>class Prediction:\n    \"\"\"\n    An object describing a prediction (e.g., a machine-drawn bounding box on an image).\n\n    Parameters\n    ----------\n    datum : Datum\n        The `Datum` associated with the `Prediction`.\n    annotations : List[Annotation]\n        The list of `Annotations` associated with the `Prediction`.\n\n    Attributes\n    ----------\n    score : Union[float, int]\n        The score assigned to the `Prediction`.\n    \"\"\"\n\n    def __init__(\n        self,\n        datum: Datum,\n        annotations: List[Annotation],\n    ):\n        self.datum = datum\n        self.annotations = annotations\n        self._validate()\n\n    def _validate(self):\n        \"\"\"\n        Validate the inputs of the `Prediction`.\n        \"\"\"\n        # validate datum\n        if not isinstance(self.datum, Datum):\n            raise TypeError(\n                \"Attribute `datum` should have type `valor.Datum`.\"\n            )\n\n        # validate annotations\n        if not isinstance(self.annotations, list):\n            raise TypeError(\n                \"Attribute `datum` should have type `List[valor.Annotation]`.\"\n            )\n        for idx, annotation in enumerate(self.annotations):\n            if not isinstance(annotation, Annotation):\n                raise TypeError(\n                    f\"Attribute `annotations[{idx}]` should have type `valor.Annotation`.\"\n                )\n\n        # TaskType-specific validations\n        for annotation in self.annotations:\n            if annotation.task_type in [\n                TaskType.CLASSIFICATION,\n                TaskType.OBJECT_DETECTION,\n            ]:\n                for label in annotation.labels:\n                    if label.score is None:\n                        raise ValueError(\n                            f\"For task type `{annotation.task_type}` prediction labels must have scores, but got `None`\"\n                        )\n            if annotation.task_type == TaskType.CLASSIFICATION:\n                label_keys_to_sum = {}\n                for scored_label in annotation.labels:\n                    label_key = scored_label.key\n                    if label_key not in label_keys_to_sum:\n                        label_keys_to_sum[label_key] = 0.0\n                    label_keys_to_sum[label_key] += scored_label.score\n\n                for k, total_score in label_keys_to_sum.items():\n                    if abs(total_score - 1) &gt; 1e-5:\n                        raise ValueError(\n                            \"For each label key, prediction scores must sum to 1, but\"\n                            f\" for label key {k} got scores summing to {total_score}.\"\n                        )\n\n    def to_dict(\n        self,\n        dataset_name: Optional[str] = None,\n        model_name: Optional[str] = None,\n    ) -&gt; dict:\n        \"\"\"\n        Defines how a `valor.Prediction` object is serialized into a dictionary.\n\n        Returns\n        ----------\n        dict\n            A dictionary describing a prediction.\n        \"\"\"\n        return {\n            \"datum\": self.datum.to_dict(dataset_name=dataset_name),\n            \"model_name\": model_name,\n            \"annotations\": [\n                annotation.to_dict() for annotation in self.annotations\n            ],\n        }\n\n    @classmethod\n    def from_dict(cls, resp: dict) -&gt; Prediction:\n        \"\"\"\n        Construct a Prediction from a dictionary.\n\n        Parameters\n        ----------\n        resp : dict\n            The dictionary containing a prediction.\n\n        Returns\n        -------\n        valor.Prediction\n        \"\"\"\n        expected_keys = {\"datum\", \"annotations\", \"model_name\"}\n        if set(resp.keys()) != expected_keys:\n            raise ValueError(\n                f\"Expected keys `{expected_keys}`, received `{set(resp.keys())}`.\"\n            )\n        if not isinstance(resp[\"annotations\"], list):\n            raise TypeError(\"Expected `annotations` member to be a `list`.\")\n        return cls(\n            datum=Datum.from_dict(resp[\"datum\"]),\n            annotations=[\n                Annotation.from_dict(annotation)\n                for annotation in resp[\"annotations\"]\n            ],\n        )\n\n    def __str__(self) -&gt; str:\n        \"\"\"Dumps the object into a JSON formatted string.\"\"\"\n        objdict = self.to_dict(dataset_name=None)\n        objdict[\"datum\"].pop(\"dataset_name\")\n        objdict.pop(\"model_name\")\n        return json.dumps(objdict, indent=4)\n\n    def __eq__(self, other):\n        \"\"\"\n        Defines how `Predictions` are compared to one another.\n\n        Parameters\n        ----------\n        other : Prediction\n            The object to compare with the `Prediction`.\n\n        Returns\n        ----------\n        boolean\n            A boolean describing whether the two objects are equal.\n        \"\"\"\n        if not isinstance(other, Prediction):\n            raise TypeError(\n                f\"Expected type `{type(Prediction)}`, got `{other}`\"\n            )\n        return self.to_dict(None, None) == other.to_dict(None, None)\n</code></pre>"},{"location":"client_api/Prediction/#valor.Prediction-functions","title":"Functions","text":""},{"location":"client_api/Prediction/#valor.Prediction.__eq__","title":"<code>valor.Prediction.__eq__(other)</code>","text":"<p>Defines how <code>Predictions</code> are compared to one another.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Prediction</code> <p>The object to compare with the <code>Prediction</code>.</p> required <p>Returns:</p> Type Description <code>boolean</code> <p>A boolean describing whether the two objects are equal.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def __eq__(self, other):\n    \"\"\"\n    Defines how `Predictions` are compared to one another.\n\n    Parameters\n    ----------\n    other : Prediction\n        The object to compare with the `Prediction`.\n\n    Returns\n    ----------\n    boolean\n        A boolean describing whether the two objects are equal.\n    \"\"\"\n    if not isinstance(other, Prediction):\n        raise TypeError(\n            f\"Expected type `{type(Prediction)}`, got `{other}`\"\n        )\n    return self.to_dict(None, None) == other.to_dict(None, None)\n</code></pre>"},{"location":"client_api/Prediction/#valor.Prediction.__str__","title":"<code>valor.Prediction.__str__()</code>","text":"<p>Dumps the object into a JSON formatted string.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Dumps the object into a JSON formatted string.\"\"\"\n    objdict = self.to_dict(dataset_name=None)\n    objdict[\"datum\"].pop(\"dataset_name\")\n    objdict.pop(\"model_name\")\n    return json.dumps(objdict, indent=4)\n</code></pre>"},{"location":"client_api/Prediction/#valor.Prediction.from_dict","title":"<code>valor.Prediction.from_dict(resp)</code>  <code>classmethod</code>","text":"<p>Construct a Prediction from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>resp</code> <code>dict</code> <p>The dictionary containing a prediction.</p> required <p>Returns:</p> Type Description <code>Prediction</code> Source code in <code>valor/coretypes.py</code> <pre><code>@classmethod\ndef from_dict(cls, resp: dict) -&gt; Prediction:\n    \"\"\"\n    Construct a Prediction from a dictionary.\n\n    Parameters\n    ----------\n    resp : dict\n        The dictionary containing a prediction.\n\n    Returns\n    -------\n    valor.Prediction\n    \"\"\"\n    expected_keys = {\"datum\", \"annotations\", \"model_name\"}\n    if set(resp.keys()) != expected_keys:\n        raise ValueError(\n            f\"Expected keys `{expected_keys}`, received `{set(resp.keys())}`.\"\n        )\n    if not isinstance(resp[\"annotations\"], list):\n        raise TypeError(\"Expected `annotations` member to be a `list`.\")\n    return cls(\n        datum=Datum.from_dict(resp[\"datum\"]),\n        annotations=[\n            Annotation.from_dict(annotation)\n            for annotation in resp[\"annotations\"]\n        ],\n    )\n</code></pre>"},{"location":"client_api/Prediction/#valor.Prediction.to_dict","title":"<code>valor.Prediction.to_dict(dataset_name=None, model_name=None)</code>","text":"<p>Defines how a <code>valor.Prediction</code> object is serialized into a dictionary.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary describing a prediction.</p> Source code in <code>valor/coretypes.py</code> <pre><code>def to_dict(\n    self,\n    dataset_name: Optional[str] = None,\n    model_name: Optional[str] = None,\n) -&gt; dict:\n    \"\"\"\n    Defines how a `valor.Prediction` object is serialized into a dictionary.\n\n    Returns\n    ----------\n    dict\n        A dictionary describing a prediction.\n    \"\"\"\n    return {\n        \"datum\": self.datum.to_dict(dataset_name=dataset_name),\n        \"model_name\": model_name,\n        \"annotations\": [\n            annotation.to_dict() for annotation in self.annotations\n        ],\n    }\n</code></pre>"},{"location":"client_api/VideoFrameMetadata/","title":"VideoFrameMetadata","text":"<p>A class describing the metadata for the frame of a video.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ImageMetadata</code> <p>Metadata describing the frame of the video.</p> required <code>frame</code> <code>int</code> <p>The number of seconds into the video that the frame was taken.</p> required Source code in <code>valor/metatypes.py</code> <pre><code>class VideoFrameMetadata:\n    \"\"\"\n    A class describing the metadata for the frame of a video.\n\n    Parameters\n    ----------\n    image : ImageMetadata\n        Metadata describing the frame of the video.\n    frame: int\n        The number of seconds into the video that the frame was taken.\n    \"\"\"\n\n    def __init__(\n        self,\n        image: ImageMetadata,\n        frame: int,\n    ):\n        self.image = image\n        self.frame = frame\n\n        if not isinstance(self.image, ImageMetadata):\n            raise TypeError(\n                \"`image` should be of type `valor.metatypes.ImageMetadata`\"\n            )\n        if not isinstance(self.frame, int):\n            raise TypeError(\"`frame` should be of type `int`.\")\n\n    @staticmethod\n    def valid(datum: Datum) -&gt; bool:\n        \"\"\"\n        Asserts whether the `Datum's` height and width is a valid subset of the image's height and width.\n\n        Parameters\n        ----------\n        datum : Datum\n            The `Datum` to check validity for.\n        \"\"\"\n        return {\"height\", \"width\", \"frame\"}.issubset(datum.metadata)\n\n    @classmethod\n    def from_datum(cls, datum: Datum):\n        \"\"\"\n        Creates a `VideoFrameMetadata` object from a `Datum`.\n\n        Parameters\n        ----------\n        datum : Datum\n            The `Datum` to extract metadata from.\n        \"\"\"\n        if not cls.valid(datum):\n            raise ValueError(\n                f\"`datum` does not contain height, width and/or frame in metadata `{datum.metadata}`\"\n            )\n        image = ImageMetadata.from_datum(datum)\n        frame = cast(int, image.metadata.pop(\"frame\"))\n        return cls(\n            image=image,\n            frame=int(frame),\n        )\n\n    def to_datum(self) -&gt; Datum:\n        \"\"\"\n        Converts a `VideoFrameMetadata` object into a `Datum`.\n        \"\"\"\n        datum = self.image.to_datum()\n        datum.metadata[\"frame\"] = self.frame\n        return datum\n</code></pre>"},{"location":"client_api/VideoFrameMetadata/#valor.metatypes.VideoFrameMetadata-functions","title":"Functions","text":""},{"location":"client_api/VideoFrameMetadata/#valor.metatypes.VideoFrameMetadata.from_datum","title":"<code>valor.metatypes.VideoFrameMetadata.from_datum(datum)</code>  <code>classmethod</code>","text":"<p>Creates a <code>VideoFrameMetadata</code> object from a <code>Datum</code>.</p> <p>Parameters:</p> Name Type Description Default <code>datum</code> <code>Datum</code> <p>The <code>Datum</code> to extract metadata from.</p> required Source code in <code>valor/metatypes.py</code> <pre><code>@classmethod\ndef from_datum(cls, datum: Datum):\n    \"\"\"\n    Creates a `VideoFrameMetadata` object from a `Datum`.\n\n    Parameters\n    ----------\n    datum : Datum\n        The `Datum` to extract metadata from.\n    \"\"\"\n    if not cls.valid(datum):\n        raise ValueError(\n            f\"`datum` does not contain height, width and/or frame in metadata `{datum.metadata}`\"\n        )\n    image = ImageMetadata.from_datum(datum)\n    frame = cast(int, image.metadata.pop(\"frame\"))\n    return cls(\n        image=image,\n        frame=int(frame),\n    )\n</code></pre>"},{"location":"client_api/VideoFrameMetadata/#valor.metatypes.VideoFrameMetadata.to_datum","title":"<code>valor.metatypes.VideoFrameMetadata.to_datum()</code>","text":"<p>Converts a <code>VideoFrameMetadata</code> object into a <code>Datum</code>.</p> Source code in <code>valor/metatypes.py</code> <pre><code>def to_datum(self) -&gt; Datum:\n    \"\"\"\n    Converts a `VideoFrameMetadata` object into a `Datum`.\n    \"\"\"\n    datum = self.image.to_datum()\n    datum.metadata[\"frame\"] = self.frame\n    return datum\n</code></pre>"},{"location":"client_api/VideoFrameMetadata/#valor.metatypes.VideoFrameMetadata.valid","title":"<code>valor.metatypes.VideoFrameMetadata.valid(datum)</code>  <code>staticmethod</code>","text":"<p>Asserts whether the <code>Datum's</code> height and width is a valid subset of the image's height and width.</p> <p>Parameters:</p> Name Type Description Default <code>datum</code> <code>Datum</code> <p>The <code>Datum</code> to check validity for.</p> required Source code in <code>valor/metatypes.py</code> <pre><code>@staticmethod\ndef valid(datum: Datum) -&gt; bool:\n    \"\"\"\n    Asserts whether the `Datum's` height and width is a valid subset of the image's height and width.\n\n    Parameters\n    ----------\n    datum : Datum\n        The `Datum` to check validity for.\n    \"\"\"\n    return {\"height\", \"width\", \"frame\"}.issubset(datum.metadata)\n</code></pre>"},{"location":"client_api/Viz/","title":"Viz","text":""},{"location":"client_api/Viz/#valor.viz-classes","title":"Classes","text":""},{"location":"client_api/Viz/#valor.viz-functions","title":"Functions","text":""},{"location":"client_api/Viz/#valor.viz.create_combined_segmentation_mask","title":"<code>valor.viz.create_combined_segmentation_mask(annotated_datums, label_key, task_type=None)</code>","text":"<p>Creates a combined segmentation mask from a list of segmentations.</p> <p>Parameters:</p> Name Type Description Default <code>annotated_datums</code> <code>List[Union[GroundTruth, Prediction]]</code> <p>A list of segmentations. These all must have the same <code>image</code> attribute.</p> required <code>label_key</code> <code>str</code> <p>The label key to use.</p> required <code>task_type</code> <code>TaskType</code> <p>The associated task type.</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple</code> <p>The first element of the tuple is the combined mask, as an RGB PIL image. The second element is a color legend: it's a dict with the unique labels as keys and the PIL image swatches as values.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If all segmentations don't belong to the same image or there is a segmentation that doesn't have <code>label_key</code> as the key of one of its labels.</p> <code>ValueError</code> <p>If there aren't any segmentations.</p> Source code in <code>valor/viz.py</code> <pre><code>def create_combined_segmentation_mask(\n    annotated_datums: Sequence[Union[GroundTruth, Prediction]],\n    label_key: str,\n    task_type: Union[enums.TaskType, None] = None,\n) -&gt; Tuple[Image.Image, Dict[str, Image.Image]]:\n    \"\"\"\n    Creates a combined segmentation mask from a list of segmentations.\n\n    Parameters\n    -------\n    annotated_datums : List[Union[GroundTruth, Prediction]]\n        A list of segmentations. These all must have the same `image` attribute.\n    label_key : str\n        The label key to use.\n    task_type : enums.TaskType\n        The associated task type.\n\n\n    Returns\n    -------\n    tuple\n        The first element of the tuple is the combined mask, as an RGB PIL image. The second\n        element is a color legend: it's a dict with the unique labels as keys and the\n        PIL image swatches as values.\n\n    Raises\n    ------\n    RuntimeError\n        If all segmentations don't belong to the same image or there is a\n        segmentation that doesn't have `label_key` as the key of one of its labels.\n    ValueError\n        If there aren't any segmentations.\n    \"\"\"\n\n    if len(annotated_datums) == 0:\n        raise ValueError(\"`segs` cannot be empty.\")\n\n    if (\n        len(\n            set(\n                [\n                    annotated_datum.datum.uid\n                    for annotated_datum in annotated_datums\n                ]\n            )\n        )\n        &gt; 1\n    ):\n        raise RuntimeError(\n            \"Expected all segmentation to belong to the same image\"\n        )\n\n    # Validate task type\n    if task_type is not None and task_type not in [\n        enums.TaskType.OBJECT_DETECTION,\n        enums.TaskType.SEMANTIC_SEGMENTATION,\n    ]:\n        raise RuntimeError(\n            \"Expected either Instance or Semantic segmentation task_type.\"\n        )\n\n    # Create valid task type list\n    if task_type is None:\n        task_types = [\n            enums.TaskType.OBJECT_DETECTION,\n            enums.TaskType.SEMANTIC_SEGMENTATION,\n        ]\n    else:\n        task_types = [task_type]\n\n    # unpack raster annotations\n    annotations: List[Annotation] = []\n    for annotated_datum in annotated_datums:\n        for annotation in annotated_datum.annotations:\n            if annotation.task_type in task_types:\n                annotations.append(annotation)\n\n    label_values = []\n    for annotation in annotations:\n        for label in annotation.labels:\n            if label.key == label_key:\n                label_values.append(label.value)\n    if not label_values:\n        raise RuntimeError(\n            f\"Annotation doesn't have a label with key `{label_key}`\"\n        )\n\n    unique_label_values = list(set(label_values))\n    label_value_to_color = {\n        v: COLOR_MAP[i] for i, v in enumerate(unique_label_values)\n    }\n    seg_colors = [label_value_to_color[v] for v in label_values]\n\n    image = ImageMetadata.from_datum(annotated_datums[0].datum)\n    img_w, img_h = image.width, image.height\n\n    combined_mask = np.zeros((img_h, img_w, 3), dtype=np.uint8)\n    for annotation, color in zip(annotations, seg_colors):\n        if annotation.raster is not None:\n            mask = annotation.raster.to_numpy()\n        elif annotation.multipolygon is not None:\n            mask = _polygons_to_binary_mask(\n                annotation.multipolygon.polygons,\n                img_w=img_w,\n                img_h=img_h,\n            )\n        else:\n            continue\n\n        combined_mask[np.where(mask)] = color\n\n    legend = {\n        v: Image.new(\"RGB\", (20, 20), color)\n        for v, color in label_value_to_color.items()\n    }\n\n    return Image.fromarray(combined_mask), legend\n</code></pre>"},{"location":"client_api/Viz/#valor.viz.draw_bounding_box_on_image","title":"<code>valor.viz.draw_bounding_box_on_image(bounding_box, img, color=(255, 0, 0))</code>","text":"<p>Draws a bounding polygon on an image. This operation is not done in place.</p> <p>Parameters:</p> Name Type Description Default <code>bounding_box</code> <code>BoundingBox</code> <p>Bounding box to draw on the image.</p> required <code>img</code> <code>Image</code> <p>Pillow image to draw on.</p> required <code>color</code> <code>Tuple[int, int, int]</code> <p>RGB tuple of the color to use.</p> <code>(255, 0, 0)</code> <p>Returns:</p> Type Description <code>img</code> <p>Pillow image with bounding box drawn on it.</p> Source code in <code>valor/viz.py</code> <pre><code>def draw_bounding_box_on_image(\n    bounding_box: schemas.BoundingBox,\n    img: Image.Image,\n    color: Tuple[int, int, int] = (255, 0, 0),\n) -&gt; Image.Image:\n    \"\"\"Draws a bounding polygon on an image. This operation is not done in place.\n\n    Parameters\n    ----------\n    bounding_box\n        Bounding box to draw on the image.\n    img\n        Pillow image to draw on.\n    color\n        RGB tuple of the color to use.\n\n    Returns\n    -------\n    img\n        Pillow image with bounding box drawn on it.\n    \"\"\"\n    return _draw_bounding_polygon_on_image(\n        bounding_box.polygon, img, color=color, inplace=False\n    )\n</code></pre>"},{"location":"client_api/Viz/#valor.viz.draw_detections_on_image","title":"<code>valor.viz.draw_detections_on_image(detections, img)</code>","text":"<p>Draws detections (bounding boxes and labels) on an image.</p> <p>Parameters:</p> Name Type Description Default <code>detections</code> <code>List[Union[GroundTruth, Prediction]]</code> <p>A list of <code>GroundTruths</code> or <code>Predictions</code> to draw on the image.</p> required <code>img</code> <code>Image</code> <p>The image to draw the detections on.</p> required <p>Returns:</p> Name Type Description <code>img</code> <code>Image</code> <p>An image with the detections drawn on.</p> Source code in <code>valor/viz.py</code> <pre><code>def draw_detections_on_image(\n    detections: Sequence[Union[GroundTruth, Prediction]],\n    img: Image.Image,\n) -&gt; Image.Image:\n    \"\"\"\n    Draws detections (bounding boxes and labels) on an image.\n\n    Parameters\n    -------\n    detections : List[Union[GroundTruth, Prediction]]\n        A list of `GroundTruths` or `Predictions` to draw on the image.\n    img : Image.Image\n        The image to draw the detections on.\n\n\n    Returns\n    -------\n    img : Image.Image\n        An image with the detections drawn on.\n    \"\"\"\n\n    annotations = []\n    for datum in detections:\n        annotations.extend(datum.annotations)\n\n    for i, detection in enumerate(annotations):\n        if detection.task_type in [enums.TaskType.OBJECT_DETECTION]:\n            img = _draw_detection_on_image(detection, img, inplace=i != 0)\n    return img\n</code></pre>"},{"location":"client_api/Viz/#valor.viz.draw_raster_on_image","title":"<code>valor.viz.draw_raster_on_image(raster, img, color=(255, 0, 0), alpha=0.4)</code>","text":"<p>Draws the raster on top of an image. This operation is not done in place.</p> <p>Parameters:</p> Name Type Description Default <code>img</code> <code>Image</code> <p>pillow image to draw on.</p> required <code>color</code> <code>Tuple[int, int, int]</code> <p>RGB tuple of the color to use</p> <code>(255, 0, 0)</code> <code>alpha</code> <code>float</code> <p>alpha (transparency) value of the mask. 0 is fully transparent, 1 is fully opaque</p> <code>0.4</code> Source code in <code>valor/viz.py</code> <pre><code>def draw_raster_on_image(\n    raster: schemas.Raster,\n    img: Image.Image,\n    color: Tuple[int, int, int] = (255, 0, 0),\n    alpha: float = 0.4,\n) -&gt; Image.Image:\n    \"\"\"Draws the raster on top of an image. This operation is not done in place.\n\n    Parameters\n    ----------\n    img\n        pillow image to draw on.\n    color\n        RGB tuple of the color to use\n    alpha\n        alpha (transparency) value of the mask. 0 is fully transparent, 1 is fully opaque\n    \"\"\"\n    img = img.copy()\n    binary_mask = raster.to_numpy()\n    mask_arr = np.zeros(\n        (binary_mask.shape[0], binary_mask.shape[1], 3), dtype=np.uint8\n    )\n    mask_arr[binary_mask] = color\n    mask_img = Image.fromarray(mask_arr)\n    blend = Image.blend(img, mask_img, alpha=alpha)\n    img.paste(blend, (0, 0), mask=Image.fromarray(binary_mask))\n\n    return img\n</code></pre>"},{"location":"client_api/Schemas/Evaluation/","title":"Evaluation","text":""},{"location":"client_api/Schemas/Evaluation/#valor.schemas.evaluation-classes","title":"Classes","text":""},{"location":"client_api/Schemas/Evaluation/#valor.schemas.evaluation.EvaluationParameters","title":"<code>valor.schemas.evaluation.EvaluationParameters</code>  <code>dataclass</code>","text":"<p>Defines parameters for evaluation methods.</p> <p>Attributes:</p> Name Type Description <code>iou_thresholds_to_compute</code> <code>Optional[List[float]]</code> <p>A list of floats describing which Intersection over Unions (IoUs) to use when calculating metrics (i.e., mAP).</p> <code>iou_thresholds_to_return</code> <code>Optional[List[float]]</code> <p>A list of floats describing which Intersection over Union (IoUs) thresholds to calculate a metric for. Must be a subset of <code>iou_thresholds_to_compute</code>.</p> <code>label_map</code> <code>Optional[List[List[List[str]]]]</code> <p>Optional mapping of individual labels to a grouper label. Useful when you need to evaluate performance using labels that differ across datasets and models.</p> <code>recall_score_threshold</code> <code>float, default=0</code> <p>The confidence score threshold for use when determining whether to count a prediction as a true positive or not while calculating Average Recall.</p> Source code in <code>valor/schemas/evaluation.py</code> <pre><code>@dataclass\nclass EvaluationParameters:\n    \"\"\"\n    Defines parameters for evaluation methods.\n\n    Attributes\n    ----------\n    iou_thresholds_to_compute : Optional[List[float]]\n        A list of floats describing which Intersection over Unions (IoUs) to use when calculating metrics (i.e., mAP).\n    iou_thresholds_to_return: Optional[List[float]]\n        A list of floats describing which Intersection over Union (IoUs) thresholds to calculate a metric for. Must be a subset of `iou_thresholds_to_compute`.\n    label_map: Optional[List[List[List[str]]]]\n        Optional mapping of individual labels to a grouper label. Useful when you need to evaluate performance using labels that differ across datasets and models.\n    recall_score_threshold: float, default=0\n        The confidence score threshold for use when determining whether to count a prediction as a true positive or not while calculating Average Recall.\n    \"\"\"\n\n    task_type: TaskType\n\n    # object detection\n    convert_annotations_to_type: Optional[AnnotationType] = None\n    iou_thresholds_to_compute: Optional[List[float]] = None\n    iou_thresholds_to_return: Optional[List[float]] = None\n    label_map: Optional[List[List[List[str]]]] = None\n    recall_score_threshold: float = 0\n</code></pre>"},{"location":"client_api/Schemas/Evaluation/#valor.schemas.evaluation.EvaluationRequest","title":"<code>valor.schemas.evaluation.EvaluationRequest</code>  <code>dataclass</code>","text":"<p>An evaluation request.</p> <p>Defines important attributes of the API's <code>EvaluationRequest</code>.</p> <p>Attributes:</p> Name Type Description <code>model_names</code> <code>List[str]</code> <p>The list of models we want to evaluate by name.</p> <code>datum_filter</code> <code>Filter</code> <p>The filter object used to define what the model(s) is evaluating against.</p> <code>parameters</code> <code>EvaluationParameters</code> <p>Any parameters that are used to modify an evaluation method.</p> Source code in <code>valor/schemas/evaluation.py</code> <pre><code>@dataclass\nclass EvaluationRequest:\n    \"\"\"\n    An evaluation request.\n\n    Defines important attributes of the API's `EvaluationRequest`.\n\n    Attributes\n    ----------\n    model_names : List[str]\n        The list of models we want to evaluate by name.\n    datum_filter : schemas.Filter\n        The filter object used to define what the model(s) is evaluating against.\n    parameters : EvaluationParameters\n        Any parameters that are used to modify an evaluation method.\n    \"\"\"\n\n    model_names: Union[str, List[str]]\n    datum_filter: Filter\n    parameters: EvaluationParameters\n\n    def __post_init__(self):\n        if isinstance(self.datum_filter, dict):\n            self.datum_filter = Filter(**self.datum_filter)\n        if isinstance(self.parameters, dict):\n            self.parameters = EvaluationParameters(**self.parameters)\n</code></pre>"},{"location":"client_api/Schemas/Filters/","title":"Filters","text":""},{"location":"client_api/Schemas/Filters/#valor.schemas.filters-classes","title":"Classes","text":""},{"location":"client_api/Schemas/Filters/#valor.schemas.filters.Filter","title":"<code>valor.schemas.filters.Filter</code>  <code>dataclass</code>","text":"<p>Used to filter Evaluations according to specific, user-defined criteria.</p> <p>Attributes:</p> Name Type Description <code>dataset_names</code> <code>(List[str], optional)</code> <p>A list of <code>Dataset</code> names to filter on.</p> <code>dataset_metadata</code> <code>(Dict[str, List[Constraint]], optional)</code> <p>A dictionary of <code>Dataset</code> metadata to filter on.</p> <code>model_names</code> <code>(List[str], optional)</code> <p>A list of <code>Model</code> names to filter on.</p> <code>model_metadata</code> <code>(Dict[str, List[Constraint]], optional)</code> <p>A dictionary of <code>Model</code> metadata to filter on.</p> <code>datum_uids</code> <code>(List[str], optional)</code> <p>A list of <code>Datum</code> UIDs to filter on.</p> <code>datum_metadata</code> <code>(Dict[str, List[Constraint]], optional)</code> <p>A dictionary of <code>Datum</code> metadata to filter on.</p> <code>task_types</code> <code>(List[TaskType], optional)</code> <p>A list of task types to filter on.</p> <code>annotation_metadata</code> <code>(Dict[str, List[Constraint]], optional)</code> <p>A dictionary of <code>Annotation</code> metadata to filter on.</p> <code>require_bounding_box</code> <code>(bool, optional)</code> <p>A toggle for filtering by bounding boxes.</p> <code>bounding_box_area</code> <code>(bool, optional)</code> <p>An optional constraint to filter by bounding box area.</p> <code>require_polygon</code> <code>(bool, optional)</code> <p>A toggle for filtering by polygons.</p> <code>polygon_area</code> <code>(bool, optional)</code> <p>An optional constraint to filter by polygon area.</p> <code>require_raster</code> <code>(bool, optional)</code> <p>A toggle for filtering by rasters.</p> <code>raster_area</code> <code>(bool, optional)</code> <p>An optional constraint to filter by raster area.</p> <code>labels</code> <code>(List[Label], optional)</code> <p>A list of `Labels' to filter on.</p> <code>label_ids</code> <code>(List[int], optional)</code> <p>A list of label row id's.</p> <code>label_keys</code> <code>(List[str], optional)</code> <p>A list of <code>Label</code> keys to filter on.</p> <code>label_scores</code> <code>(List[Constraint], optional)</code> <p>A list of <code>Constraints</code> which are used to filter <code>Evaluations</code> according to the <code>Model</code>'s prediction scores.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>value</code> isn't of the correct type.</p> <code>ValueError</code> <p>If the <code>operator</code> doesn't match one of the allowed patterns.</p> Source code in <code>valor/schemas/filters.py</code> <pre><code>@dataclass\nclass Filter:\n    \"\"\"\n    Used to filter Evaluations according to specific, user-defined criteria.\n\n    Attributes\n    ----------\n    dataset_names : List[str], optional\n        A list of `Dataset` names to filter on.\n    dataset_metadata : Dict[str, List[Constraint]], optional\n        A dictionary of `Dataset` metadata to filter on.\n    model_names : List[str], optional\n        A list of `Model` names to filter on.\n    model_metadata : Dict[str, List[Constraint]], optional\n        A dictionary of `Model` metadata to filter on.\n    datum_uids : List[str], optional\n        A list of `Datum` UIDs to filter on.\n    datum_metadata : Dict[str, List[Constraint]], optional\n        A dictionary of `Datum` metadata to filter on.\n    task_types : List[TaskType], optional\n        A list of task types to filter on.\n    annotation_metadata : Dict[str, List[Constraint]], optional\n        A dictionary of `Annotation` metadata to filter on.\n    require_bounding_box : bool, optional\n        A toggle for filtering by bounding boxes.\n    bounding_box_area : bool, optional\n        An optional constraint to filter by bounding box area.\n    require_polygon : bool, optional\n        A toggle for filtering by polygons.\n    polygon_area : bool, optional\n        An optional constraint to filter by polygon area.\n    require_raster : bool, optional\n        A toggle for filtering by rasters.\n    raster_area : bool, optional\n        An optional constraint to filter by raster area.\n    labels : List[Label], optional\n        A list of `Labels' to filter on.\n    label_ids : List[int], optional\n        A list of label row id's.\n    label_keys : List[str], optional\n        A list of `Label` keys to filter on.\n    label_scores : List[Constraint], optional\n        A list of `Constraints` which are used to filter `Evaluations` according to the `Model`'s prediction scores.\n\n    Raises\n    ------\n    TypeError\n        If `value` isn't of the correct type.\n    ValueError\n        If the `operator` doesn't match one of the allowed patterns.\n    \"\"\"\n\n    # datasets\n    dataset_names: Optional[List[str]] = None\n    dataset_metadata: Optional[Dict[str, List[Constraint]]] = None\n\n    # models\n    model_names: Optional[List[str]] = None\n    model_metadata: Optional[Dict[str, List[Constraint]]] = None\n\n    # datums\n    datum_uids: Optional[List[str]] = None\n    datum_metadata: Optional[Dict[str, List[Constraint]]] = None\n\n    # annotations\n    task_types: Optional[List[TaskType]] = None\n    annotation_metadata: Optional[Dict[str, List[Constraint]]] = None\n\n    # geometries\n    require_bounding_box: Optional[bool] = None\n    bounding_box_area: Optional[List[Constraint]] = None\n    require_polygon: Optional[bool] = None\n    polygon_area: Optional[List[Constraint]] = None\n    require_raster: Optional[bool] = None\n    raster_area: Optional[List[Constraint]] = None\n\n    # labels\n    labels: Optional[List[Dict[str, str]]] = None\n    label_ids: Optional[List[int]] = None\n    label_keys: Optional[List[str]] = None\n    label_scores: Optional[List[Constraint]] = None\n\n    def __post_init__(self):\n        def _unpack_metadata(metadata: Optional[dict]) -&gt; Union[dict, None]:\n            if metadata is None:\n                return None\n            for k, vlist in metadata.items():\n                metadata[k] = [\n                    v if isinstance(v, Constraint) else Constraint(**v)\n                    for v in vlist\n                ]\n            return metadata\n\n        # unpack metadata\n        self.dataset_metadata = _unpack_metadata(self.dataset_metadata)\n        self.model_metadata = _unpack_metadata(self.model_metadata)\n        self.datum_metadata = _unpack_metadata(self.datum_metadata)\n        self.annotation_metadata = _unpack_metadata(self.annotation_metadata)\n\n        def _unpack_list(\n            vlist: Optional[list], object_type: type\n        ) -&gt; Optional[list]:\n            def _handle_conversion(v, object_type):\n                if object_type is Constraint:\n                    return object_type(**v)\n                else:\n                    return object_type(v)\n\n            if vlist is None:\n                return None\n\n            return [\n                (\n                    v\n                    if isinstance(v, object_type)\n                    else _handle_conversion(v=v, object_type=object_type)\n                )\n                for v in vlist\n            ]\n\n        # unpack tasktypes\n        self.task_types = _unpack_list(self.task_types, TaskType)\n\n        # unpack area\n        self.bounding_box_area = _unpack_list(\n            self.bounding_box_area, Constraint\n        )\n        self.polygon_area = _unpack_list(self.polygon_area, Constraint)\n        self.raster_area = _unpack_list(self.raster_area, Constraint)\n\n        # scores\n        self.label_scores = _unpack_list(self.label_scores, Constraint)\n\n    @classmethod\n    def create(\n        cls, expressions: List[Union[BinaryExpression, List[BinaryExpression]]]\n    ):\n        \"\"\"\n        Parses a list of `BinaryExpression` to create a `schemas.Filter` object.\n\n        Parameters\n        ----------\n        expressions: Sequence[Union[BinaryExpression, Sequence[BinaryExpression]]]\n            A list of (lists of) `BinaryExpressions' to parse into a `Filter` object.\n        \"\"\"\n\n        def flatten(\n            t: Iterable[Union[BinaryExpression, Iterable[BinaryExpression]]]\n        ) -&gt; Iterator[BinaryExpression]:\n            \"\"\"Flatten a nested iterable of BinaryExpressions.\"\"\"\n            for item in t:\n                if isinstance(item, BinaryExpression):\n                    yield item\n                else:\n                    yield from flatten(item)\n\n        # create dict using expr names as keys\n        expression_dict = {}\n        for expr in flatten(expressions):\n            if expr.name not in expression_dict:\n                expression_dict[expr.name] = []\n            expression_dict[expr.name].append(expr)\n\n        # create filter\n        filter_request = cls()\n\n        # metadata constraints\n        for attr in [\n            \"dataset_metadata\",\n            \"model_metadata\",\n            \"datum_metadata\",\n            \"annotation_metadata\",\n        ]:\n            if attr in expression_dict:\n                for expr in expression_dict[attr]:\n                    if not getattr(filter_request, attr):\n                        setattr(filter_request, attr, {})\n                    __value = getattr(filter_request, attr)\n                    if expr.key not in __value:\n                        __value[expr.key] = []\n                    __value[expr.key].append(expr.constraint)\n                    setattr(filter_request, attr, __value)\n\n        # numeric constraints\n        for attr in [\n            \"bounding_box_area\",\n            \"polygon_area\",\n            \"raster_area\",\n            \"label_scores\",\n        ]:\n            if attr in expression_dict:\n                setattr(\n                    filter_request,\n                    attr,\n                    [expr.constraint for expr in expression_dict[attr]],\n                )\n\n        # boolean constraints\n        for attr in [\n            \"require_bounding_box\",\n            \"require_polygon\",\n            \"require_raster\",\n        ]:\n            if attr in expression_dict:\n                for expr in expression_dict[attr]:\n                    if expr.constraint.operator == \"exists\":\n                        setattr(filter_request, attr, True)\n                    elif expr.constraint.operator == \"is_none\":\n                        setattr(filter_request, attr, False)\n\n        # equality constraints\n        for attr in [\n            \"dataset_names\",\n            \"model_names\",\n            \"datum_uids\",\n            \"task_types\",\n            \"labels\",\n            \"label_keys\",\n        ]:\n            if attr in expression_dict:\n                setattr(\n                    filter_request,\n                    attr,\n                    [expr.constraint.value for expr in expression_dict[attr]],\n                )\n\n        return filter_request\n</code></pre>"},{"location":"client_api/Schemas/Filters/#valor.schemas.filters.Filter-functions","title":"Functions","text":""},{"location":"client_api/Schemas/Filters/#valor.schemas.filters.Filter.create","title":"<code>valor.schemas.filters.Filter.create(expressions)</code>  <code>classmethod</code>","text":"<p>Parses a list of <code>BinaryExpression</code> to create a <code>schemas.Filter</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>expressions</code> <code>List[Union[BinaryExpression, List[BinaryExpression]]]</code> <p>A list of (lists of) <code>BinaryExpressions' to parse into a</code>Filter` object.</p> required Source code in <code>valor/schemas/filters.py</code> <pre><code>@classmethod\ndef create(\n    cls, expressions: List[Union[BinaryExpression, List[BinaryExpression]]]\n):\n    \"\"\"\n    Parses a list of `BinaryExpression` to create a `schemas.Filter` object.\n\n    Parameters\n    ----------\n    expressions: Sequence[Union[BinaryExpression, Sequence[BinaryExpression]]]\n        A list of (lists of) `BinaryExpressions' to parse into a `Filter` object.\n    \"\"\"\n\n    def flatten(\n        t: Iterable[Union[BinaryExpression, Iterable[BinaryExpression]]]\n    ) -&gt; Iterator[BinaryExpression]:\n        \"\"\"Flatten a nested iterable of BinaryExpressions.\"\"\"\n        for item in t:\n            if isinstance(item, BinaryExpression):\n                yield item\n            else:\n                yield from flatten(item)\n\n    # create dict using expr names as keys\n    expression_dict = {}\n    for expr in flatten(expressions):\n        if expr.name not in expression_dict:\n            expression_dict[expr.name] = []\n        expression_dict[expr.name].append(expr)\n\n    # create filter\n    filter_request = cls()\n\n    # metadata constraints\n    for attr in [\n        \"dataset_metadata\",\n        \"model_metadata\",\n        \"datum_metadata\",\n        \"annotation_metadata\",\n    ]:\n        if attr in expression_dict:\n            for expr in expression_dict[attr]:\n                if not getattr(filter_request, attr):\n                    setattr(filter_request, attr, {})\n                __value = getattr(filter_request, attr)\n                if expr.key not in __value:\n                    __value[expr.key] = []\n                __value[expr.key].append(expr.constraint)\n                setattr(filter_request, attr, __value)\n\n    # numeric constraints\n    for attr in [\n        \"bounding_box_area\",\n        \"polygon_area\",\n        \"raster_area\",\n        \"label_scores\",\n    ]:\n        if attr in expression_dict:\n            setattr(\n                filter_request,\n                attr,\n                [expr.constraint for expr in expression_dict[attr]],\n            )\n\n    # boolean constraints\n    for attr in [\n        \"require_bounding_box\",\n        \"require_polygon\",\n        \"require_raster\",\n    ]:\n        if attr in expression_dict:\n            for expr in expression_dict[attr]:\n                if expr.constraint.operator == \"exists\":\n                    setattr(filter_request, attr, True)\n                elif expr.constraint.operator == \"is_none\":\n                    setattr(filter_request, attr, False)\n\n    # equality constraints\n    for attr in [\n        \"dataset_names\",\n        \"model_names\",\n        \"datum_uids\",\n        \"task_types\",\n        \"labels\",\n        \"label_keys\",\n    ]:\n        if attr in expression_dict:\n            setattr(\n                filter_request,\n                attr,\n                [expr.constraint.value for expr in expression_dict[attr]],\n            )\n\n    return filter_request\n</code></pre>"},{"location":"client_api/Schemas/Geometries/","title":"Geometries","text":""},{"location":"client_api/Schemas/Geometries/#valor.schemas.geometry-classes","title":"Classes","text":""},{"location":"client_api/Schemas/Geometries/#valor.schemas.geometry.BasicPolygon","title":"<code>valor.schemas.geometry.BasicPolygon</code>  <code>dataclass</code>","text":"<p>Class for representing a bounding region.</p> <p>Attributes:</p> Name Type Description <code>points</code> <code>(List[Point], optional)</code> <p>List of <code>Point</code> objects representing the vertices of the polygon. Defaults to an empty list.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>points</code> is not a list, or an element in <code>points</code> is not a <code>Point</code>.</p> <code>ValueError</code> <p>If the number of unique points in <code>points</code> is less than 3, making the BasicPolygon invalid.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; BasicPolygon(\n...     points=[\n...         Point(0,0),\n...         Point(0,1),\n...         Point(1,0),\n...     ]\n... )\n</code></pre> Source code in <code>valor/schemas/geometry.py</code> <pre><code>@dataclass\nclass BasicPolygon:\n    \"\"\"\n    Class for representing a bounding region.\n\n    Attributes\n    ----------\n    points : List[Point], optional\n        List of `Point` objects representing the vertices of the polygon. Defaults to an empty list.\n\n    Raises\n    ------\n    TypeError\n        If `points` is not a list, or an element in `points` is not a `Point`.\n    ValueError\n        If the number of unique points in `points` is less than 3,\n        making the BasicPolygon invalid.\n\n    Examples\n    --------\n    &gt;&gt;&gt; BasicPolygon(\n    ...     points=[\n    ...         Point(0,0),\n    ...         Point(0,1),\n    ...         Point(1,0),\n    ...     ]\n    ... )\n    \"\"\"\n\n    points: List[Point] = field(default_factory=list)\n\n    def __post_init__(self):\n        # unpack &amp; validate\n        if not isinstance(self.points, list):\n            raise TypeError(\"Member `points` is not a list.\")\n        for i, point in enumerate(self.points):\n            if isinstance(point, dict):\n                self.points[i] = Point(**point)\n            if not isinstance(self.points[i], Point):\n                raise TypeError(\"Element in points is not a `Point`.\")\n        if len(set(self.points)) &lt; 3:\n            raise ValueError(\n                \"BasicPolygon needs at least 3 unique points to be valid.\"\n            )\n\n    def xy_list(self) -&gt; List[Point]:\n        \"\"\"\n        Returns a list of `Point` objects representing the vertices of the polygon.\n\n        Returns\n        -------\n        List[Point]\n            List of `Point` objects.\n        \"\"\"\n        return self.points.copy()\n\n    def tuple_list(self) -&gt; List[Tuple[float, float]]:\n        \"\"\"\n        Returns a list of points as tuples (x, y).\n\n        Returns\n        -------\n        List[Tuple[float, float]]\n            List of points as tuples.\n        \"\"\"\n        return [(pt.x, pt.y) for pt in self.points]\n\n    @property\n    def xmin(self):\n        \"\"\"Minimum x-coordinate of the polygon.\"\"\"\n        return min(p.x for p in self.points)\n\n    @property\n    def ymin(self):\n        \"\"\"Minimum y-coordinate of the polygon.\"\"\"\n        return min(p.y for p in self.points)\n\n    @property\n    def xmax(self):\n        \"\"\"Maximum x-coordinate of the polygon.\"\"\"\n        return max(p.x for p in self.points)\n\n    @property\n    def ymax(self):\n        \"\"\"Maximum y-coordinate of the polygon.\"\"\"\n        return max(p.y for p in self.points)\n</code></pre>"},{"location":"client_api/Schemas/Geometries/#valor.schemas.geometry.BasicPolygon-attributes","title":"Attributes","text":""},{"location":"client_api/Schemas/Geometries/#valor.schemas.geometry.BasicPolygon.xmax","title":"<code>valor.schemas.geometry.BasicPolygon.xmax</code>  <code>property</code>","text":"<p>Maximum x-coordinate of the polygon.</p>"},{"location":"client_api/Schemas/Geometries/#valor.schemas.geometry.BasicPolygon.xmin","title":"<code>valor.schemas.geometry.BasicPolygon.xmin</code>  <code>property</code>","text":"<p>Minimum x-coordinate of the polygon.</p>"},{"location":"client_api/Schemas/Geometries/#valor.schemas.geometry.BasicPolygon.ymax","title":"<code>valor.schemas.geometry.BasicPolygon.ymax</code>  <code>property</code>","text":"<p>Maximum y-coordinate of the polygon.</p>"},{"location":"client_api/Schemas/Geometries/#valor.schemas.geometry.BasicPolygon.ymin","title":"<code>valor.schemas.geometry.BasicPolygon.ymin</code>  <code>property</code>","text":"<p>Minimum y-coordinate of the polygon.</p>"},{"location":"client_api/Schemas/Geometries/#valor.schemas.geometry.BasicPolygon-functions","title":"Functions","text":""},{"location":"client_api/Schemas/Geometries/#valor.schemas.geometry.BasicPolygon.tuple_list","title":"<code>valor.schemas.geometry.BasicPolygon.tuple_list()</code>","text":"<p>Returns a list of points as tuples (x, y).</p> <p>Returns:</p> Type Description <code>List[Tuple[float, float]]</code> <p>List of points as tuples.</p> Source code in <code>valor/schemas/geometry.py</code> <pre><code>def tuple_list(self) -&gt; List[Tuple[float, float]]:\n    \"\"\"\n    Returns a list of points as tuples (x, y).\n\n    Returns\n    -------\n    List[Tuple[float, float]]\n        List of points as tuples.\n    \"\"\"\n    return [(pt.x, pt.y) for pt in self.points]\n</code></pre>"},{"location":"client_api/Schemas/Geometries/#valor.schemas.geometry.BasicPolygon.xy_list","title":"<code>valor.schemas.geometry.BasicPolygon.xy_list()</code>","text":"<p>Returns a list of <code>Point</code> objects representing the vertices of the polygon.</p> <p>Returns:</p> Type Description <code>List[Point]</code> <p>List of <code>Point</code> objects.</p> Source code in <code>valor/schemas/geometry.py</code> <pre><code>def xy_list(self) -&gt; List[Point]:\n    \"\"\"\n    Returns a list of `Point` objects representing the vertices of the polygon.\n\n    Returns\n    -------\n    List[Point]\n        List of `Point` objects.\n    \"\"\"\n    return self.points.copy()\n</code></pre>"},{"location":"client_api/Schemas/Geometries/#valor.schemas.geometry.BoundingBox","title":"<code>valor.schemas.geometry.BoundingBox</code>  <code>dataclass</code>","text":"<p>Represents a bounding box defined by a 4-point polygon. Note that this does not need to be axis-aligned.</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>BasicPolygon or dict</code> <p>The 4-point polygon defining the bounding box. Can be a <code>BasicPolygon</code> object or a dictionary with the necessary information to create a <code>BasicPolygon</code>.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>polygon</code> is not a <code>BasicPolygon</code> or cannot be converted to one.</p> <code>ValueError</code> <p>If the number of points in <code>polygon</code> is not equal to 4, making it invalid as a bounding box.</p> <p>Examples:</p> <p>Create a BoundingBox from Points. Note that ordering is important to prevent self-intersection!</p> <pre><code>&gt;&gt;&gt; box1 = schemas.BoundingBox(\n...     polygon=schemas.BasicPolygon(\n...         points=[\n...             schemas.Point(0,0),\n...             schemas.Point(0,1),\n...             schemas.Point(1,1),\n...             schemas.Point(1,0),\n...         ]\n...     ),\n... )\n</code></pre> <p>Create a BoundingBox using extrema.</p> <pre><code>&gt;&gt;&gt; box2 = BoundingBox.from_extrema(\n...     xmin=0, xmax=1,\n...     ymin=0, ymax=1,\n... )\n</code></pre> Source code in <code>valor/schemas/geometry.py</code> <pre><code>@dataclass\nclass BoundingBox:\n    \"\"\"\n    Represents a bounding box defined by a 4-point polygon. Note that this does not need to be axis-aligned.\n\n    Parameters\n    ----------\n    polygon : BasicPolygon or dict\n        The 4-point polygon defining the bounding box. Can be a `BasicPolygon` object\n        or a dictionary with the necessary information to create a `BasicPolygon`.\n\n    Raises\n    ------\n    TypeError\n        If `polygon` is not a `BasicPolygon` or cannot be converted to one.\n    ValueError\n        If the number of points in `polygon` is not equal to 4, making it invalid as a bounding box.\n\n    Examples\n    --------\n    Create a BoundingBox from Points.\n    Note that ordering is important to prevent self-intersection!\n    &gt;&gt;&gt; box1 = schemas.BoundingBox(\n    ...     polygon=schemas.BasicPolygon(\n    ...         points=[\n    ...             schemas.Point(0,0),\n    ...             schemas.Point(0,1),\n    ...             schemas.Point(1,1),\n    ...             schemas.Point(1,0),\n    ...         ]\n    ...     ),\n    ... )\n\n    Create a BoundingBox using extrema.\n    &gt;&gt;&gt; box2 = BoundingBox.from_extrema(\n    ...     xmin=0, xmax=1,\n    ...     ymin=0, ymax=1,\n    ... )\n    \"\"\"\n\n    polygon: BasicPolygon\n\n    def __post_init__(self):\n        if isinstance(self.polygon, dict):\n            self.polygon = BasicPolygon(**self.polygon)\n        if not isinstance(self.polygon, BasicPolygon):\n            raise TypeError(\n                \"polygon should be of type `valor.schemas.BasicPolygon`\"\n            )\n        if len(self.polygon.points) != 4:\n            raise ValueError(\n                \"Bounding box should be made of a 4-point polygon.\"\n            )\n\n    @classmethod\n    def from_extrema(cls, xmin: float, xmax: float, ymin: float, ymax: float):\n        \"\"\"\n        Create a BoundingBox from extrema values.\n\n        Parameters\n        ----------\n        xmin : float\n            Minimum x-coordinate of the bounding box.\n        xmax : float\n            Maximum x-coordinate of the bounding box.\n        ymin : float\n            Minimum y-coordinate of the bounding box.\n        ymax : float\n            Maximum y-coordinate of the bounding box.\n\n        Returns\n        -------\n        BoundingBox\n            A BoundingBox created from the provided extrema values.\n        \"\"\"\n        return cls(\n            polygon=BasicPolygon(\n                points=[\n                    Point(x=xmin, y=ymin),\n                    Point(x=xmax, y=ymin),\n                    Point(x=xmax, y=ymax),\n                    Point(x=xmin, y=ymax),\n                ]\n            )\n        )\n\n    @property\n    def xmin(self):\n        \"\"\"Minimum x-coordinate of the bounding box.\"\"\"\n        return self.polygon.xmin\n\n    @property\n    def xmax(self):\n        \"\"\"Maximum x-coordinate of the bounding box.\"\"\"\n        return self.polygon.xmax\n\n    @property\n    def ymin(self):\n        \"\"\"Minimum y-coordinate of the bounding box.\"\"\"\n        return self.polygon.ymin\n\n    @property\n    def ymax(self):\n        \"\"\"Maximum y-coordinate of the bounding box.\"\"\"\n        return self.polygon.ymax\n</code></pre>"},{"location":"client_api/Schemas/Geometries/#valor.schemas.geometry.BoundingBox-attributes","title":"Attributes","text":""},{"location":"client_api/Schemas/Geometries/#valor.schemas.geometry.BoundingBox.xmax","title":"<code>valor.schemas.geometry.BoundingBox.xmax</code>  <code>property</code>","text":"<p>Maximum x-coordinate of the bounding box.</p>"},{"location":"client_api/Schemas/Geometries/#valor.schemas.geometry.BoundingBox.xmin","title":"<code>valor.schemas.geometry.BoundingBox.xmin</code>  <code>property</code>","text":"<p>Minimum x-coordinate of the bounding box.</p>"},{"location":"client_api/Schemas/Geometries/#valor.schemas.geometry.BoundingBox.ymax","title":"<code>valor.schemas.geometry.BoundingBox.ymax</code>  <code>property</code>","text":"<p>Maximum y-coordinate of the bounding box.</p>"},{"location":"client_api/Schemas/Geometries/#valor.schemas.geometry.BoundingBox.ymin","title":"<code>valor.schemas.geometry.BoundingBox.ymin</code>  <code>property</code>","text":"<p>Minimum y-coordinate of the bounding box.</p>"},{"location":"client_api/Schemas/Geometries/#valor.schemas.geometry.BoundingBox-functions","title":"Functions","text":""},{"location":"client_api/Schemas/Geometries/#valor.schemas.geometry.BoundingBox.from_extrema","title":"<code>valor.schemas.geometry.BoundingBox.from_extrema(xmin, xmax, ymin, ymax)</code>  <code>classmethod</code>","text":"<p>Create a BoundingBox from extrema values.</p> <p>Parameters:</p> Name Type Description Default <code>xmin</code> <code>float</code> <p>Minimum x-coordinate of the bounding box.</p> required <code>xmax</code> <code>float</code> <p>Maximum x-coordinate of the bounding box.</p> required <code>ymin</code> <code>float</code> <p>Minimum y-coordinate of the bounding box.</p> required <code>ymax</code> <code>float</code> <p>Maximum y-coordinate of the bounding box.</p> required <p>Returns:</p> Type Description <code>BoundingBox</code> <p>A BoundingBox created from the provided extrema values.</p> Source code in <code>valor/schemas/geometry.py</code> <pre><code>@classmethod\ndef from_extrema(cls, xmin: float, xmax: float, ymin: float, ymax: float):\n    \"\"\"\n    Create a BoundingBox from extrema values.\n\n    Parameters\n    ----------\n    xmin : float\n        Minimum x-coordinate of the bounding box.\n    xmax : float\n        Maximum x-coordinate of the bounding box.\n    ymin : float\n        Minimum y-coordinate of the bounding box.\n    ymax : float\n        Maximum y-coordinate of the bounding box.\n\n    Returns\n    -------\n    BoundingBox\n        A BoundingBox created from the provided extrema values.\n    \"\"\"\n    return cls(\n        polygon=BasicPolygon(\n            points=[\n                Point(x=xmin, y=ymin),\n                Point(x=xmax, y=ymin),\n                Point(x=xmax, y=ymax),\n                Point(x=xmin, y=ymax),\n            ]\n        )\n    )\n</code></pre>"},{"location":"client_api/Schemas/Geometries/#valor.schemas.geometry.MultiPolygon","title":"<code>valor.schemas.geometry.MultiPolygon</code>  <code>dataclass</code>","text":"<p>Represents a collection of polygons.</p> <p>Parameters:</p> Name Type Description Default <code>polygons</code> <code>List[Polygon]</code> <p>List of <code>Polygon</code> objects. Defaults to an empty list.</p> <code>field(default_factory=list)</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>polygons</code> is not a list, or an element in <code>polygons</code> is not a <code>Polygon</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; MultiPolygon(\n...     polygons=[\n...         Polygon(...),\n...         Polygon(...),\n...         Polygon(...),\n...     ]\n... )\n</code></pre> Source code in <code>valor/schemas/geometry.py</code> <pre><code>@dataclass\nclass MultiPolygon:\n    \"\"\"\n    Represents a collection of polygons.\n\n    Parameters\n    ----------\n    polygons : List[Polygon], optional\n        List of `Polygon` objects. Defaults to an empty list.\n\n    Raises\n    ------\n    TypeError\n        If `polygons` is not a list, or an element in `polygons` is not a `Polygon`.\n\n    Examples\n    --------\n    &gt;&gt;&gt; MultiPolygon(\n    ...     polygons=[\n    ...         Polygon(...),\n    ...         Polygon(...),\n    ...         Polygon(...),\n    ...     ]\n    ... )\n    \"\"\"\n\n    polygons: List[Polygon] = field(default_factory=list)\n\n    def __post_init__(self):\n        # unpack &amp; validate\n        if not isinstance(self.polygons, list):\n            raise TypeError(\n                \"polygons should be list of `valor.schemas.Polyon`\"\n            )\n        for i, polygon in enumerate(self.polygons):\n            if isinstance(polygon, dict):\n                self.polygons[i] = Polygon(**polygon)\n            if not isinstance(self.polygons[i], Polygon):\n                raise TypeError(\n                    \"polygons list should contain elements of type `valor.schemas.Polygon`\"\n                )\n</code></pre>"},{"location":"client_api/Schemas/Geometries/#valor.schemas.geometry.Point","title":"<code>valor.schemas.geometry.Point</code>  <code>dataclass</code>","text":"<p>Represents a point in 2D space.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Union[float, int]</code> <p>The x-coordinate of the point.</p> required <code>y</code> <code>Union[float, int]</code> <p>The y-coordinate of the point.</p> required <p>Attributes:</p> Name Type Description <code>x</code> <code>float</code> <p>The x-coordinate of the point.</p> <code>y</code> <code>float</code> <p>The y-coordinate of the point.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the coordinates are not of type <code>float</code> or convertible to <code>float</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; Point(1,2)\nPoint(x=1.0, y=2.0)\n</code></pre> Source code in <code>valor/schemas/geometry.py</code> <pre><code>@dataclass\nclass Point:\n    \"\"\"\n    Represents a point in 2D space.\n\n    Parameters\n    ----------\n    x : Union[float, int]\n        The x-coordinate of the point.\n    y : Union[float, int]\n        The y-coordinate of the point.\n\n    Attributes\n    ----------\n    x : float\n        The x-coordinate of the point.\n    y : float\n        The y-coordinate of the point.\n\n    Raises\n    ------\n    TypeError\n        If the coordinates are not of type `float` or convertible to `float`.\n\n    Examples\n    --------\n    &gt;&gt;&gt; Point(1,2)\n    Point(x=1.0, y=2.0)\n    \"\"\"\n\n    x: float\n    y: float\n\n    def __post_init__(self):\n        self.x = float(self.x)\n        self.y = float(self.y)\n\n    def __hash__(self):\n        return hash(f\"{self.x},{self.y}\")\n\n    def resize(\n        self,\n        og_img_h: int,\n        og_img_w: int,\n        new_img_h: int,\n        new_img_w: int,\n    ) -&gt; \"Point\":\n        \"\"\"\n        Resize the point coordinates based on the scaling factors.\n\n        Parameters\n        ----------\n        og_img_h : int\n            Original image height.\n        og_img_w : int\n            Original image width.\n        new_img_h : int\n            New image height.\n        new_img_w : int\n            New image width.\n\n        Returns\n        -------\n        Point\n            Resized point based on the scaling factors.\n\n        Examples\n        --------\n        &gt;&gt;&gt; p = Point(1,2)\n        &gt;&gt;&gt; p.resize(og_img_h=100,\n        ...          og_img_w=50,\n        ...          new_img_h=1000,\n        ...          new_img_w=1000)\n        Point(x=20.0, y=20.0)\n        \"\"\"\n        h_factor, w_factor = new_img_h / og_img_h, new_img_w / og_img_w\n        return Point(x=w_factor * self.x, y=h_factor * self.y)\n</code></pre>"},{"location":"client_api/Schemas/Geometries/#valor.schemas.geometry.Point-functions","title":"Functions","text":""},{"location":"client_api/Schemas/Geometries/#valor.schemas.geometry.Point.resize","title":"<code>valor.schemas.geometry.Point.resize(og_img_h, og_img_w, new_img_h, new_img_w)</code>","text":"<p>Resize the point coordinates based on the scaling factors.</p> <p>Parameters:</p> Name Type Description Default <code>og_img_h</code> <code>int</code> <p>Original image height.</p> required <code>og_img_w</code> <code>int</code> <p>Original image width.</p> required <code>new_img_h</code> <code>int</code> <p>New image height.</p> required <code>new_img_w</code> <code>int</code> <p>New image width.</p> required <p>Returns:</p> Type Description <code>Point</code> <p>Resized point based on the scaling factors.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; p = Point(1,2)\n&gt;&gt;&gt; p.resize(og_img_h=100,\n...          og_img_w=50,\n...          new_img_h=1000,\n...          new_img_w=1000)\nPoint(x=20.0, y=20.0)\n</code></pre> Source code in <code>valor/schemas/geometry.py</code> <pre><code>def resize(\n    self,\n    og_img_h: int,\n    og_img_w: int,\n    new_img_h: int,\n    new_img_w: int,\n) -&gt; \"Point\":\n    \"\"\"\n    Resize the point coordinates based on the scaling factors.\n\n    Parameters\n    ----------\n    og_img_h : int\n        Original image height.\n    og_img_w : int\n        Original image width.\n    new_img_h : int\n        New image height.\n    new_img_w : int\n        New image width.\n\n    Returns\n    -------\n    Point\n        Resized point based on the scaling factors.\n\n    Examples\n    --------\n    &gt;&gt;&gt; p = Point(1,2)\n    &gt;&gt;&gt; p.resize(og_img_h=100,\n    ...          og_img_w=50,\n    ...          new_img_h=1000,\n    ...          new_img_w=1000)\n    Point(x=20.0, y=20.0)\n    \"\"\"\n    h_factor, w_factor = new_img_h / og_img_h, new_img_w / og_img_w\n    return Point(x=w_factor * self.x, y=h_factor * self.y)\n</code></pre>"},{"location":"client_api/Schemas/Geometries/#valor.schemas.geometry.Polygon","title":"<code>valor.schemas.geometry.Polygon</code>  <code>dataclass</code>","text":"<p>Represents a polygon with a boundary and optional holes.</p> <p>Parameters:</p> Name Type Description Default <code>boundary</code> <code>BasicPolygon or dict</code> <p>The outer boundary of the polygon. Can be a <code>BasicPolygon</code> object or a dictionary with the necessary information to create a <code>BasicPolygon</code>.</p> required <code>holes</code> <code>List[BasicPolygon]</code> <p>List of holes inside the polygon. Defaults to an empty list.</p> <code>field(default_factory=list)</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>boundary</code> is not a <code>BasicPolygon</code> or cannot be converted to one. If <code>holes</code> is not a list, or an element in <code>holes</code> is not a <code>BasicPolygon</code>.</p> <p>Examples:</p> <p>Create component polygons with BasicPolygon</p> <pre><code>&gt;&gt;&gt; basic_polygon1 = BasicPolygon(...)\n&gt;&gt;&gt; basic_polygon2 = BasicPolygon(...)\n&gt;&gt;&gt; basic_polygon3 = BasicPolygon(...)\n</code></pre> <p>Create a polygon from a basic polygon.</p> <pre><code>&gt;&gt;&gt; polygon1 = Polygon(\n...     boundary=basic_polygon1,\n... )\n</code></pre> <p>Create a polygon with holes.</p> <pre><code>&gt;&gt;&gt; polygon2 = Polygon(\n...     boundary=basic_polygon1,\n...     holes=[basic_polygon2, basic_polygon3],\n... )\n</code></pre> Source code in <code>valor/schemas/geometry.py</code> <pre><code>@dataclass\nclass Polygon:\n    \"\"\"\n    Represents a polygon with a boundary and optional holes.\n\n    Parameters\n    ----------\n    boundary : BasicPolygon or dict\n        The outer boundary of the polygon. Can be a `BasicPolygon` object or a\n        dictionary with the necessary information to create a `BasicPolygon`.\n    holes : List[BasicPolygon], optional\n        List of holes inside the polygon. Defaults to an empty list.\n\n    Raises\n    ------\n    TypeError\n        If `boundary` is not a `BasicPolygon` or cannot be converted to one.\n        If `holes` is not a list, or an element in `holes` is not a `BasicPolygon`.\n\n    Examples\n    --------\n    Create component polygons with BasicPolygon\n    &gt;&gt;&gt; basic_polygon1 = BasicPolygon(...)\n    &gt;&gt;&gt; basic_polygon2 = BasicPolygon(...)\n    &gt;&gt;&gt; basic_polygon3 = BasicPolygon(...)\n\n    Create a polygon from a basic polygon.\n    &gt;&gt;&gt; polygon1 = Polygon(\n    ...     boundary=basic_polygon1,\n    ... )\n\n    Create a polygon with holes.\n    &gt;&gt;&gt; polygon2 = Polygon(\n    ...     boundary=basic_polygon1,\n    ...     holes=[basic_polygon2, basic_polygon3],\n    ... )\n    \"\"\"\n\n    boundary: BasicPolygon\n    holes: List[BasicPolygon] = field(default_factory=list)\n\n    def __post_init__(self):\n        # unpack &amp; validate\n        if isinstance(self.boundary, dict):\n            self.boundary = BasicPolygon(**self.boundary)\n        if not isinstance(self.boundary, BasicPolygon):\n            raise TypeError(\n                \"boundary should be of type `valor.schemas.BasicPolygon`\"\n            )\n        if self.holes:\n            if not isinstance(self.holes, list):\n                raise TypeError(\n                    f\"holes should be a list of `valor.schemas.BasicPolygon`. Got `{type(self.holes)}`.\"\n                )\n            for i, hole in enumerate(self.holes):\n                if isinstance(hole, dict):\n                    self.holes[i] = BasicPolygon(**hole)\n                if not isinstance(self.holes[i], BasicPolygon):\n                    raise TypeError(\n                        \"holes list should contain elements of type `valor.schemas.BasicPolygon`\"\n                    )\n        else:\n            self.holes = []\n</code></pre>"},{"location":"client_api/Schemas/Geometries/#valor.schemas.geometry.Raster","title":"<code>valor.schemas.geometry.Raster</code>  <code>dataclass</code>","text":"<p>Represents a raster image or binary mask.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>str</code> <p>Base64-encoded string representing the raster mask.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>mask</code> is not a string.</p> <p>Examples:</p> <p>Generate a random mask.</p> <pre><code>&gt;&gt;&gt; import numpy.random\n&gt;&gt;&gt; height = 640\n&gt;&gt;&gt; width = 480\n&gt;&gt;&gt; array = numpy.random.rand(height, width)\n</code></pre> <p>Convert to binary mask.</p> <pre><code>&gt;&gt;&gt; mask = (array &gt; 0.5)\n</code></pre> <p>Create Raster.</p> <pre><code>&gt;&gt;&gt; Raster.from_numpy(mask)\n</code></pre> Source code in <code>valor/schemas/geometry.py</code> <pre><code>@dataclass\nclass Raster:\n    \"\"\"\n    Represents a raster image or binary mask.\n\n    Parameters\n    ----------\n    mask : str\n        Base64-encoded string representing the raster mask.\n\n    Raises\n    ------\n    TypeError\n        If `mask` is not a string.\n\n    Examples\n    --------\n    Generate a random mask.\n    &gt;&gt;&gt; import numpy.random\n    &gt;&gt;&gt; height = 640\n    &gt;&gt;&gt; width = 480\n    &gt;&gt;&gt; array = numpy.random.rand(height, width)\n\n    Convert to binary mask.\n    &gt;&gt;&gt; mask = (array &gt; 0.5)\n\n    Create Raster.\n    &gt;&gt;&gt; Raster.from_numpy(mask)\n    \"\"\"\n\n    mask: str\n\n    def __post_init__(self):\n        if not isinstance(self.mask, str):\n            raise TypeError(\"mask should be of type `str`\")\n\n    @classmethod\n    def from_numpy(cls, mask: np.ndarray):\n        \"\"\"\n        Create a Raster object from a NumPy array.\n\n        Parameters\n        ----------\n        mask : np.ndarray\n            The 2D binary array representing the mask.\n\n        Returns\n        -------\n        Raster\n            A Raster object created from the provided NumPy array.\n\n        Raises\n        ------\n        ValueError\n            If the input array is not 2D or not of dtype bool.\n        \"\"\"\n        if len(mask.shape) != 2:\n            raise ValueError(\"raster currently only supports 2d arrays\")\n        if mask.dtype != bool:\n            raise ValueError(\n                f\"Expecting a binary mask (i.e. of dtype bool) but got dtype {mask.dtype}\"\n            )\n        f = io.BytesIO()\n        PIL.Image.fromarray(mask).save(f, format=\"PNG\")\n        f.seek(0)\n        mask_bytes = f.read()\n        f.close()\n        return cls(\n            mask=b64encode(mask_bytes).decode(),\n        )\n\n    def to_numpy(self) -&gt; np.ndarray:\n        \"\"\"\n        Convert the base64-encoded mask to a NumPy array.\n\n        Returns\n        -------\n        np.ndarray\n            A 2D binary array representing the mask.\n        \"\"\"\n        mask_bytes = b64decode(self.mask)\n        with io.BytesIO(mask_bytes) as f:\n            img = PIL.Image.open(f)\n            return np.array(img)\n</code></pre>"},{"location":"client_api/Schemas/Geometries/#valor.schemas.geometry.Raster-functions","title":"Functions","text":""},{"location":"client_api/Schemas/Geometries/#valor.schemas.geometry.Raster.from_numpy","title":"<code>valor.schemas.geometry.Raster.from_numpy(mask)</code>  <code>classmethod</code>","text":"<p>Create a Raster object from a NumPy array.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>ndarray</code> <p>The 2D binary array representing the mask.</p> required <p>Returns:</p> Type Description <code>Raster</code> <p>A Raster object created from the provided NumPy array.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input array is not 2D or not of dtype bool.</p> Source code in <code>valor/schemas/geometry.py</code> <pre><code>@classmethod\ndef from_numpy(cls, mask: np.ndarray):\n    \"\"\"\n    Create a Raster object from a NumPy array.\n\n    Parameters\n    ----------\n    mask : np.ndarray\n        The 2D binary array representing the mask.\n\n    Returns\n    -------\n    Raster\n        A Raster object created from the provided NumPy array.\n\n    Raises\n    ------\n    ValueError\n        If the input array is not 2D or not of dtype bool.\n    \"\"\"\n    if len(mask.shape) != 2:\n        raise ValueError(\"raster currently only supports 2d arrays\")\n    if mask.dtype != bool:\n        raise ValueError(\n            f\"Expecting a binary mask (i.e. of dtype bool) but got dtype {mask.dtype}\"\n        )\n    f = io.BytesIO()\n    PIL.Image.fromarray(mask).save(f, format=\"PNG\")\n    f.seek(0)\n    mask_bytes = f.read()\n    f.close()\n    return cls(\n        mask=b64encode(mask_bytes).decode(),\n    )\n</code></pre>"},{"location":"client_api/Schemas/Geometries/#valor.schemas.geometry.Raster.to_numpy","title":"<code>valor.schemas.geometry.Raster.to_numpy()</code>","text":"<p>Convert the base64-encoded mask to a NumPy array.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>A 2D binary array representing the mask.</p> Source code in <code>valor/schemas/geometry.py</code> <pre><code>def to_numpy(self) -&gt; np.ndarray:\n    \"\"\"\n    Convert the base64-encoded mask to a NumPy array.\n\n    Returns\n    -------\n    np.ndarray\n        A 2D binary array representing the mask.\n    \"\"\"\n    mask_bytes = b64decode(self.mask)\n    with io.BytesIO(mask_bytes) as f:\n        img = PIL.Image.open(f)\n        return np.array(img)\n</code></pre>"}]}