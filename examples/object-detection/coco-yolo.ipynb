{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "38ec8ecc",
      "metadata": {},
      "source": [
        "# Object Detection Example\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this notebook, we'll walk through a detailed example of how you can use Valor to evaluate object detections made on [the COCO Panoptic dataset](https://cocodataset.org/#home). We'll use Ultralytics' `YOLOv8` model to predict what objects exist in various COCO photographs and compare performance between bounding box and image segmentation results.\n",
        "\n",
        "For a conceptual introduction to Valor, [check out our project overview](https://striveworks.github.io/valor/). For a higher-level example notebook, [check out our \"Getting Started\" notebook](https://github.com/Striveworks/valor/blob/main/examples/getting_started.ipynb).\n",
        "\n",
        "Before using this notebook, please ensure that the Valor service is running on your machine (for start-up instructions, [click here](https://striveworks.github.io/valor/getting_started/)). To connect to a non-local instance of Valor, update `client = Client(\"http://0.0.0.0:8000\")` in the first code block to point to the correct URL."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff9b26ec",
      "metadata": {},
      "source": [
        "## Defining Our Datasets\n",
        "\n",
        "We start by fetching our dataset and uploading it to Valor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a4d0a509-7500-44ba-b951-3566d4a4fac1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully connected to host at http://localhost:8000/\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/c_/vxjvkhy543l66mrkrtfrb56c0000gn/T/ipykernel_97405/3282455273.py:5: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        }
      ],
      "source": [
        "import ultralytics\n",
        "\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "from valor import Client, Model, Annotation, Label, connect\n",
        "from valor.enums import TaskType, AnnotationType\n",
        "from valor.viz import create_combined_segmentation_mask\n",
        "\n",
        "# connect to Valor API\n",
        "connect(\"http://localhost:8000\")\n",
        "client = Client()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "a28f5e66",
      "metadata": {},
      "source": [
        "The modules included in `./integrations` are helper modules that demonstrate how to ingest datasets and model inferences into Valor. The depth of each integration varies depending on the use case. \n",
        "\n",
        "The `coco_integration` is designed to download, extract, and upload all in one command as you are starting off with all the the data. \n",
        "\n",
        "The `yolo_integration` is much simpler; it is a collection of parser functions that convert YOLO model results into Valor types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "907e3e54",
      "metadata": {},
      "outputs": [],
      "source": [
        "import integrations.coco_integration as coco\n",
        "import integrations.yolo_integration as yolo"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "db64b6c6",
      "metadata": {},
      "source": [
        "# Defining Our Dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "94798123",
      "metadata": {},
      "source": [
        "This block utilizes `create_dataset_from_coco_panoptic` from `integrations/coco_integration.py` to download, extract, and upload the COCO Panoptic validation dataset to Valor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "89ddd815",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "coco already exists at /Users/nthorlind/git/sw/valor/examples/coco!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Formatting: 100%|██████████| 5/5 [00:00<00:00, 71.94it/s]\n",
            "Uploading: 100%|██████████| 5/5 [00:00<00:00,  8.85it/s]\n"
          ]
        }
      ],
      "source": [
        "# create the dataset in Valor\n",
        "valor_dataset = coco.create_dataset_from_coco_panoptic(\n",
        "    destination=Path(\"./\").absolute().parent / Path(\"coco\"),\n",
        "    limit=5,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "40af5eec",
      "metadata": {},
      "source": [
        "## Defining Our Model\n",
        "\n",
        "With our `Dataset` in Valor, we're ready to create our `Model` object and add `Predictions` to it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0e2750a6",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s][W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
            "/opt/homebrew/anaconda3/envs/velour_api_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            " 80%|████████  | 4/5 [00:05<00:01,  1.02s/it]"
          ]
        }
      ],
      "source": [
        "# define the model in Valor. note that we can use any name we'd like\n",
        "valor_model_bbox = Model.create(\"yolov8n-box\")\n",
        "valor_model_seg = Model.create(\"yolov8n-seg\")\n",
        "\n",
        "inference_engine = ultralytics.YOLO(f\"yolov8n-seg.pt\")\n",
        "\n",
        "for datum in tqdm(valor_dataset.get_datums()):\n",
        "\n",
        "    image = coco.download_image(datum)\n",
        "\n",
        "    results = inference_engine(image, verbose=False)\n",
        "\n",
        "    # convert result into Valor Bounding Box prediction\n",
        "    bbox_prediction = yolo.parse_detection_into_bounding_box(\n",
        "        results,            # raw inference\n",
        "        datum=datum,        # valor datum\n",
        "        label_key='name',   # label_key override\n",
        "    )\n",
        "\n",
        "    # convert result into Valor Raster prediction\n",
        "    raster_prediction = yolo.parse_detection_into_raster(\n",
        "        results,            # raw inference\n",
        "        datum=datum,        # valor datum\n",
        "        label_key='name',   # label_key override\n",
        "    )\n",
        "\n",
        "    # add predictions to the model\n",
        "    valor_model_bbox.add_prediction(valor_dataset, bbox_prediction)\n",
        "    valor_model_seg.add_prediction(valor_dataset, raster_prediction)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "159693f4",
      "metadata": {},
      "source": [
        "## Exploring Our Dataset\n",
        "\n",
        "Before we evaluate our results, let's check out what's stored in Valor. Below, we show an example of a COCO image (in this case, the image we added using UID '139')."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14939a3a",
      "metadata": {},
      "outputs": [],
      "source": [
        "groundtruth_139 = valor_dataset.get_groundtruth('139')\n",
        "assert groundtruth_139\n",
        "coco.download_image(groundtruth_139.datum)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c87516a4",
      "metadata": {},
      "source": [
        "Next, we visualize multiple segmentation masks to show all of the objects we want to be able to detect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "737e3e25-aa4a-4934-ad5f-da770bffa44a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO fix \n",
        "instance_mask, instance_legend = create_combined_segmentation_mask(\n",
        "    groundtruth_139, \n",
        "    label_key=\"name\",\n",
        "    task_type=TaskType.OBJECT_DETECTION,\n",
        ")\n",
        "\n",
        "instance_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd651c08-c554-4fb2-9dab-4b44679c500d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# print the color code for the above segmentations\n",
        "for k, v in instance_legend.items():\n",
        "    print(k)\n",
        "    display(v)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "3e8e7aab",
      "metadata": {},
      "source": [
        "## Evaluating Performance\n",
        "\n",
        "With our `Dataset` and `Model` defined, we're ready to evaluate our performance and display the results. Note that we use the `wait_for_completion` method since all evaluations run as background tasks; this method ensures that the evaluation finishes before we display the results.\n",
        "\n",
        "Sometimes, we may only want to calculate metrics for a subset of our data (i.e., we may only want to see how well our model performed at a specific type of detection). To accomplish this task, we can use the `filters` parameter of `evaluation_detection` to specify what types of data to evaluate performance for.\n",
        "\n",
        "We will be running and comparing two different evaluations investigating the performance difference of YOLOv8's bounding box and raster outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50f5d932",
      "metadata": {},
      "outputs": [],
      "source": [
        "# bounding box evaluation\n",
        "eval_bbox = valor_model_bbox.evaluate_detection(\n",
        "    valor_dataset,\n",
        "    filter_by=[\n",
        "        Label.key == \"name\",\n",
        "    ],\n",
        ")\n",
        "eval_bbox.wait_for_completion()\n",
        "eval_bbox.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e55b1f1e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# raster evaluation\n",
        "eval_raster = valor_model_seg.evaluate_detection(\n",
        "    valor_dataset,\n",
        "    filter_by=[\n",
        "        Label.key == \"name\",\n",
        "    ]\n",
        ")\n",
        "eval_raster.wait_for_completion()\n",
        "eval_raster.metrics"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "904e221b",
      "metadata": {},
      "source": [
        "We can compare performance by comparing our results in pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f4212ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "bdf = eval_bbox.to_dataframe((\"annotation type\", \"bbox\"))\n",
        "rdf = eval_raster.to_dataframe((\"annotation type\", \"raster\"))\n",
        "pd.concat([bdf, rdf], axis=1, names=[\"bbox\", \"raster\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "12373159",
      "metadata": {},
      "source": [
        "## Evaluating based on object size.\n",
        "\n",
        "Filters are not limited to annotation type and label keys as shown above. We can also define filters for a pixel-wise geometric area that will help us test the performance of objects that fall within certain size ranges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc78dd1b",
      "metadata": {},
      "outputs": [],
      "source": [
        "lower_bound = 30000\n",
        "upper_bound = 100000"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d51f103c",
      "metadata": {},
      "source": [
        "### Small Object Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1453301",
      "metadata": {},
      "outputs": [],
      "source": [
        "# bounding box evaluation\n",
        "eval_bbox_small = valor_model_bbox.evaluate_detection(\n",
        "    valor_dataset,\n",
        "    filter_by=[\n",
        "        Label.key == \"name\",\n",
        "        Annotation.bounding_box.area < lower_bound,\n",
        "    ],\n",
        ")\n",
        "eval_bbox_small.wait_for_completion()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef904d0b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# raster evaluation\n",
        "eval_raster_small = valor_model_seg.evaluate_detection(\n",
        "    valor_dataset,\n",
        "    filter_by=[\n",
        "        Label.key == \"name\",\n",
        "        Annotation.raster.area < lower_bound,\n",
        "    ]\n",
        ")\n",
        "eval_raster_small.wait_for_completion()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb3dc40d",
      "metadata": {},
      "outputs": [],
      "source": [
        "bbox_df = eval_bbox_small.to_dataframe((\"annotation type\", \"bbox\"))\n",
        "raster_df = eval_raster_small.to_dataframe((\"annotation type\", \"raster\"))\n",
        "pd.concat([bbox_df, raster_df], axis=1, names=[\"bbox\", \"raster\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ece3d955",
      "metadata": {},
      "source": [
        "### Mid-sized Object Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "472fa53b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# bounding box evaluation\n",
        "eval_bbox_mid = valor_model_bbox.evaluate_detection(\n",
        "    valor_dataset,\n",
        "    filter_by=[\n",
        "        Label.key == \"name\",\n",
        "        Annotation.bounding_box.area >= lower_bound,\n",
        "        Annotation.bounding_box.area <= upper_bound,\n",
        "    ],\n",
        ")\n",
        "eval_bbox_mid.wait_for_completion()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28aecb68",
      "metadata": {},
      "outputs": [],
      "source": [
        "# raster evaluation\n",
        "eval_raster_mid = valor_model_seg.evaluate_detection(\n",
        "    valor_dataset,\n",
        "    filter_by=[\n",
        "        Label.key == \"name\",\n",
        "        Annotation.raster.area >= lower_bound,\n",
        "        Annotation.raster.area <= upper_bound,\n",
        "    ]\n",
        ")\n",
        "eval_raster_mid.wait_for_completion()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1834644a",
      "metadata": {},
      "outputs": [],
      "source": [
        "bbox_df = eval_bbox_mid.to_dataframe((\"annotation type\", \"bbox\"))\n",
        "raster_df = eval_raster_mid.to_dataframe((\"annotation type\", \"raster\"))\n",
        "pd.concat([bbox_df, raster_df], axis=1, names=[\"bbox\", \"raster\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ab8fa1ad",
      "metadata": {},
      "source": [
        "### Large Object Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63247d38",
      "metadata": {},
      "outputs": [],
      "source": [
        "# bounding box evaluation\n",
        "eval_bbox_large = valor_model_bbox.evaluate_detection(\n",
        "    valor_dataset,\n",
        "    filter_by=[\n",
        "        Label.key == \"name\",\n",
        "        Annotation.bounding_box.area > upper_bound,\n",
        "    ],\n",
        ")\n",
        "eval_bbox_large.wait_for_completion()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "818f8147",
      "metadata": {},
      "outputs": [],
      "source": [
        "# raster evaluation\n",
        "eval_raster_large = valor_model_seg.evaluate_detection(\n",
        "    valor_dataset,\n",
        "    filter_by=[\n",
        "        Label.key == \"name\",\n",
        "        Annotation.raster.area > upper_bound,\n",
        "    ]\n",
        ")\n",
        "eval_raster_large.wait_for_completion()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7e20df1",
      "metadata": {},
      "outputs": [],
      "source": [
        "bbox_df = eval_bbox_large.to_dataframe((\"annotation type\", \"bbox\"))\n",
        "raster_df = eval_raster_large.to_dataframe((\"annotation type\", \"raster\"))\n",
        "pd.concat([bbox_df, raster_df], axis=1, names=[\"bbox\", \"raster\"])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".env-valor",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
