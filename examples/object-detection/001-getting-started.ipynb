{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Object Detection\n",
    "An introduction to the Velour evaluation service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from velour import Client\n",
    "from velour.coretypes import (\n",
    "    Dataset,\n",
    "    Model,\n",
    "    Datum,\n",
    "    Annotation,\n",
    "    GroundTruth, \n",
    "    Prediction,\n",
    "    Label,\n",
    ")\n",
    "from velour.schemas import BoundingBox\n",
    "from velour.enums import TaskType"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully connected to http://localhost:8000/.\n"
     ]
    }
   ],
   "source": [
    "client = Client(\"http://localhost:8000\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `Dataset` and `Model` using the `create` classmethod. These objects will act as the link to the Backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientException",
     "evalue": "Dataset with name `myDataset` already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39;49mcreate(client, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmyDataset\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m model \u001b[39m=\u001b[39m Model\u001b[39m.\u001b[39mcreate(client, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmyModel\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/velour/.env-velour/lib/python3.10/site-packages/velour/coretypes.py:747\u001b[0m, in \u001b[0;36mDataset.create\u001b[0;34m(cls, client, name, metadata, geospatial, id)\u001b[0m\n\u001b[1;32m    745\u001b[0m dataset\u001b[39m.\u001b[39mid \u001b[39m=\u001b[39m \u001b[39mid\u001b[39m\n\u001b[1;32m    746\u001b[0m dataset\u001b[39m.\u001b[39m_validate()\n\u001b[0;32m--> 747\u001b[0m client\u001b[39m.\u001b[39;49m_requests_post_rel_host(\u001b[39m\"\u001b[39;49m\u001b[39mdatasets\u001b[39;49m\u001b[39m\"\u001b[39;49m, json\u001b[39m=\u001b[39;49mdataset\u001b[39m.\u001b[39;49mdict())\n\u001b[1;32m    748\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mget(client, name)\n",
      "File \u001b[0;32m~/velour/.env-velour/lib/python3.10/site-packages/velour/client.py:90\u001b[0m, in \u001b[0;36mClient._requests_post_rel_host\u001b[0;34m(self, endpoint, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_requests_post_rel_host\u001b[39m(\u001b[39mself\u001b[39m, endpoint: \u001b[39mstr\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     87\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[39m    Helper for handling POST requests.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_requests_wrapper(\n\u001b[1;32m     91\u001b[0m         method_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m, endpoint\u001b[39m=\u001b[39;49mendpoint, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m     92\u001b[0m     )\n",
      "File \u001b[0;32m~/velour/.env-velour/lib/python3.10/site-packages/velour/client.py:80\u001b[0m, in \u001b[0;36mClient._requests_wrapper\u001b[0;34m(self, method_name, endpoint, *args, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m resp\u001b[39m.\u001b[39mok:\n\u001b[1;32m     79\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 80\u001b[0m         \u001b[39mraise\u001b[39;00m ClientException(resp\u001b[39m.\u001b[39mjson()[\u001b[39m\"\u001b[39m\u001b[39mdetail\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     81\u001b[0m     \u001b[39mexcept\u001b[39;00m (requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mJSONDecodeError, \u001b[39mKeyError\u001b[39;00m):\n\u001b[1;32m     82\u001b[0m         resp\u001b[39m.\u001b[39mraise_for_status()\n",
      "\u001b[0;31mClientException\u001b[0m: Dataset with name `myDataset` already exists."
     ]
    }
   ],
   "source": [
    "dataset = Dataset.create(client, name=\"myDataset\")\n",
    "model = Model.create(client, name=\"myModel\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `Datum`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datum = Datum(uid=\"myDatum1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a few `BoundingBox` for use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox1 = BoundingBox.from_extrema(0, 10, 0, 10)\n",
    "bbox2 = BoundingBox.from_extrema(2, 12, 3, 13)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an `Annotation` for a `GroundTruth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bbox1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m annotation \u001b[39m=\u001b[39m Annotation(\n\u001b[1;32m      2\u001b[0m     task_type\u001b[39m=\u001b[39mTaskType\u001b[39m.\u001b[39mDETECTION,\n\u001b[1;32m      3\u001b[0m     labels\u001b[39m=\u001b[39m[\n\u001b[1;32m      4\u001b[0m         Label(key\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mk1\u001b[39m\u001b[39m\"\u001b[39m, value\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mv1\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m      5\u001b[0m         Label(key\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mk2\u001b[39m\u001b[39m\"\u001b[39m, value\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mv2\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m      6\u001b[0m     ],\n\u001b[0;32m----> 7\u001b[0m     bounding_box\u001b[39m=\u001b[39mbbox1,\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bbox1' is not defined"
     ]
    }
   ],
   "source": [
    "annotation = Annotation(\n",
    "    task_type=TaskType.DETECTION,\n",
    "    labels=[\n",
    "        Label(key=\"k1\", value=\"v1\"),\n",
    "        Label(key=\"k2\", value=\"v2\"),\n",
    "    ],\n",
    "    bounding_box=bbox1,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an `Annotation` for a `Prediction`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_with_scores = Annotation(\n",
    "    task_type=TaskType.DETECTION,\n",
    "    labels=[\n",
    "        Label(key=\"k1\", value=\"v1\", score=0.7),\n",
    "        Label(key=\"k1\", value=\"v2\", score=0.3),\n",
    "        Label(key=\"k2\", value=\"v1\", score=0.1),\n",
    "        Label(key=\"k2\", value=\"v2\", score=0.9),\n",
    "    ]\n",
    "    bounding_box=bbox2,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`velour.coretypes` also defines `GroundTruth` and `Prediction`. These are closely related objects with the only difference being the backend target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth = GroundTruth(datum, annotations=[annotation])\n",
    "prediction = Prediction(datum, annotations=[annotation_with_scores])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have everything required to upload to velour! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.add_groundtruth(groundtruth)\n",
    "model.add_prediction(prediction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can run an evaluation we need to finalize our `Dataset` and `Model`. This is a requirement of Velour so that repeat evaluations over a Dataset-Model pairing are guaranteed to return the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.finalize()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Model` finalization is a little different than `Dataset` as it is locking predictions with respect to the dataset they operated over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.finalize_inferences(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a dataset and model representation on the backend that we can evaluate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate_classification(dataset)\n",
    "evaluation.wait_for_completion()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We currently support `classification`, `object-detection`, and `semantic-segmentation` evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluation.results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env-velour",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
