{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Velour Dataset Integrations**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Velour is crafted to seamlessly integrate with your existing workflows.\n",
    "\n",
    "Our client is equipped to handle a wide array of tasks, including classification, object detection, and semantic segmentation.\n",
    "\n",
    "When it comes to integration, think of it as creating a dataloader. The Velour datasets are structured in a hierarchy of standard types that abstract into the datatypes you provide. \n",
    "\n",
    "At the top level, you'll find `velour.Dataset` which contains a list of `velour.GroundTruth`, which, in turn, consist of `velour.Datum` and `velour.Annotation`.\n",
    "\n",
    "The ultimate objective is to effortlessly map all available metadata into Velour, empowering you to utilize it later for precise evaluations and effective stratification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from velour import (\n",
    "    Client,\n",
    "    Dataset,\n",
    "    Model,\n",
    "    Datum,\n",
    "    Annotation,\n",
    "    GroundTruth, \n",
    "    Prediction,\n",
    "    Label,\n",
    ")\n",
    "from velour.schemas import (\n",
    "    BoundingBox, \n",
    "    Polygon, \n",
    "    BasicPolygon, \n",
    "    Point,\n",
    ")\n",
    "from velour.enums import TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully connected to http://0.0.0.0:8000/.\n"
     ]
    }
   ],
   "source": [
    "client = Client(\"http://0.0.0.0:8000\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Creating a Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(\n",
    "    client=client,   \n",
    "    name=\"myDataset\",\n",
    "    metadata={        # optional, metadata can take `str`, `int`, `float` value types.\n",
    "        \"some_string\": \"hello_world\",\n",
    "        \"some_number\": 1234,\n",
    "        \"a_different_number\": 1.234,\n",
    "    },\n",
    "    geospatial=None,  # optional, define a GeoJSON\n",
    "    reset=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Create GroundTruths**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Image Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classifications = [\n",
    "    {\"path\": \"a/b/c/img1.png\", \"annotations\": [{\"class_label\": \"dog\"}]},\n",
    "    {\"path\": \"a/b/c/img2.png\", \"annotations\": [{\"class_label\": \"cat\"}]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_groundtruth_from_image_classification_dict(element: dict):\n",
    "    \n",
    "    # create Datum using filename, save the full filepath into metadata\n",
    "    datum = Datum(\n",
    "        uid=Path(element[\"path\"]).stem,\n",
    "        metadata={\n",
    "            \"path\": element[\"path\"]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # create Annotation\n",
    "    annotations = [\n",
    "        Annotation(\n",
    "            task_type=TaskType.CLASSIFICATION,\n",
    "            labels=[\n",
    "                Label(key=key, value=value)\n",
    "                for label in element[\"annotations\"]\n",
    "                for key, value in label.items()\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # create and return GroundTruth\n",
    "    return GroundTruth(\n",
    "        datum=datum,\n",
    "        annotations=annotations,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datum': {'dataset': 'myDataset', 'uid': 'img1', 'metadata': {'path': 'a/b/c/img1.png'}, 'geospatial': {}}, 'annotations': [{'task_type': 'classification', 'labels': [{'key': 'class_label', 'value': 'dog', 'score': None}], 'metadata': {}, 'bounding_box': None, 'polygon': None, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'img2', 'metadata': {'path': 'a/b/c/img2.png'}, 'geospatial': {}}, 'annotations': [{'task_type': 'classification', 'labels': [{'key': 'class_label', 'value': 'cat', 'score': None}], 'metadata': {}, 'bounding_box': None, 'polygon': None, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n"
     ]
    }
   ],
   "source": [
    "for element in image_classifications:\n",
    "    # create groundtruth\n",
    "    groundtruth = create_groundtruth_from_image_classification_dict(element)\n",
    "\n",
    "    # add groundtruth to dataset\n",
    "    dataset.add_groundtruth(groundtruth)\n",
    "    \n",
    "    print(groundtruth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Image Object Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_detections = [\n",
    "    {\"path\": \"a/b/c/img3.png\", \"annotations\": [{\"class_label\": \"dog\", \"bbox\": {\"xmin\": 16, \"ymin\": 130, \"xmax\": 70, \"ymax\": 150}}, {\"class_label\": \"person\", \"bbox\": {\"xmin\": 89, \"ymin\": 10, \"xmax\": 97, \"ymax\": 110}}]},\n",
    "    {\"path\": \"a/b/c/img4.png\", \"annotations\": [{\"class_label\": \"cat\", \"bbox\": {\"xmin\": 500, \"ymin\": 220, \"xmax\": 530, \"ymax\": 260}}]},\n",
    "    {\"path\": \"a/b/c/img5.png\", \"annotations\": []}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_groundtruth_from_object_detection_dict(element: dict):\n",
    "    \n",
    "    # create Datum using filename, save the full filepath into metadata\n",
    "    datum = Datum(\n",
    "        uid=Path(element[\"path\"]).stem,\n",
    "        metadata={\n",
    "            \"path\": element[\"path\"] \n",
    "        }\n",
    "    )\n",
    "\n",
    "    # create Annotations\n",
    "    annotations = [\n",
    "        Annotation(\n",
    "            task_type=TaskType.DETECTION,\n",
    "            labels=[Label(key=\"class_label\", value=annotation[\"class_label\"])],\n",
    "            bounding_box=BoundingBox.from_extrema(\n",
    "                xmin=annotation[\"bbox\"][\"xmin\"],\n",
    "                xmax=annotation[\"bbox\"][\"xmax\"],\n",
    "                ymin=annotation[\"bbox\"][\"ymin\"],\n",
    "                ymax=annotation[\"bbox\"][\"ymax\"],\n",
    "            )\n",
    "        )\n",
    "        for annotation in element[\"annotations\"]\n",
    "        if len(annotation) > 0\n",
    "    ]\n",
    "\n",
    "    # create and return GroundTruth\n",
    "    return GroundTruth(\n",
    "        datum=datum,\n",
    "        annotations=annotations,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datum': {'dataset': 'myDataset', 'uid': 'img3', 'metadata': {'path': 'a/b/c/img3.png'}, 'geospatial': {}}, 'annotations': [{'task_type': 'object-detection', 'labels': [{'key': 'class_label', 'value': 'dog', 'score': None}], 'metadata': {}, 'bounding_box': {'polygon': {'points': [{'x': 16.0, 'y': 130.0}, {'x': 70.0, 'y': 130.0}, {'x': 70.0, 'y': 150.0}, {'x': 16.0, 'y': 150.0}]}}, 'polygon': None, 'multipolygon': None, 'raster': None, 'jsonb': None}, {'task_type': 'object-detection', 'labels': [{'key': 'class_label', 'value': 'person', 'score': None}], 'metadata': {}, 'bounding_box': {'polygon': {'points': [{'x': 89.0, 'y': 10.0}, {'x': 97.0, 'y': 10.0}, {'x': 97.0, 'y': 110.0}, {'x': 89.0, 'y': 110.0}]}}, 'polygon': None, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'img4', 'metadata': {'path': 'a/b/c/img4.png'}, 'geospatial': {}}, 'annotations': [{'task_type': 'object-detection', 'labels': [{'key': 'class_label', 'value': 'cat', 'score': None}], 'metadata': {}, 'bounding_box': {'polygon': {'points': [{'x': 500.0, 'y': 220.0}, {'x': 530.0, 'y': 220.0}, {'x': 530.0, 'y': 260.0}, {'x': 500.0, 'y': 260.0}]}}, 'polygon': None, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'img5', 'metadata': {'path': 'a/b/c/img5.png'}, 'geospatial': {}}, 'annotations': []}\n"
     ]
    }
   ],
   "source": [
    "for element in object_detections:\n",
    "    # create groundtruth\n",
    "    groundtruth = create_groundtruth_from_object_detection_dict(element)\n",
    "\n",
    "    # add groundtruth to dataset\n",
    "    dataset.add_groundtruth(groundtruth)\n",
    "    \n",
    "    print(groundtruth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Image Semantic Segmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_segmentations = [\n",
    "    {\"path\": \"a/b/c/img6.png\", \"annotations\": [{\"class_label\": \"dog\", \"contour\": [[{\"x\": 10.0, \"y\": 15.5}, {\"x\": 20.9, \"y\": 50.2}, {\"x\": 25.9, \"y\": 28.4}]]}]},\n",
    "    {\"path\": \"a/b/c/img7.png\", \"annotations\": [{\"class_label\": \"cat\", \"contour\": [[{\"x\": 97.2, \"y\": 40.2}, {\"x\": 33.33, \"y\": 44.3}, {\"x\": 10.9, \"y\": 18.7}]]}]},\n",
    "    {\"path\": \"a/b/c/img8.png\", \"annotations\": [{\"class_label\": \"car\", \"contour\": [[{\"x\": 10.0, \"y\": 15.5}, {\"x\": 20.9, \"y\": 50.2}, {\"x\": 25.9, \"y\": 28.4}], [{\"x\": 60.0, \"y\": 15.5}, {\"x\": 70.9, \"y\": 50.2}, {\"x\": 75.9, \"y\": 28.4}]]}]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_groundtruth_from_image_segmentation_dict(element: dict):\n",
    "    \n",
    "    # create Datum using filename, save the full filepath into metadata\n",
    "    datum = Datum(\n",
    "        uid=Path(element[\"path\"]).stem,\n",
    "        metadata={\n",
    "            \"path\": element[\"path\"] \n",
    "        }\n",
    "    )\n",
    "\n",
    "    # create Annotations\n",
    "    annotations = [\n",
    "        Annotation(\n",
    "            task_type=TaskType.SEGMENTATION,\n",
    "            labels=[Label(key=\"class_label\", value=annotation[\"class_label\"])],\n",
    "            polygon=Polygon(\n",
    "                boundary=BasicPolygon(\n",
    "                    points=[\n",
    "                        Point(p[\"x\"], p[\"y\"])\n",
    "                        for p in annotation[\"contour\"][0]\n",
    "                    ],\n",
    "                ),\n",
    "                holes=[\n",
    "                    BasicPolygon(\n",
    "                        points=[\n",
    "                            Point(p[\"x\"], p[\"y\"])\n",
    "                            for p in hole\n",
    "                        ]\n",
    "                    )\n",
    "                    for hole in annotation[\"contour\"][1:]\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        for annotation in element[\"annotations\"]\n",
    "        if len(annotation[\"contour\"]) > 0\n",
    "    ]\n",
    "\n",
    "    # create and return GroundTruth\n",
    "    return GroundTruth(\n",
    "        datum=datum,\n",
    "        annotations=annotations,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datum': {'dataset': 'myDataset', 'uid': 'img6', 'metadata': {'path': 'a/b/c/img6.png'}, 'geospatial': {}}, 'annotations': [{'task_type': 'semantic-segmentation', 'labels': [{'key': 'class_label', 'value': 'dog', 'score': None}], 'metadata': {}, 'bounding_box': None, 'polygon': {'boundary': {'points': [{'x': 10.0, 'y': 15.5}, {'x': 20.9, 'y': 50.2}, {'x': 25.9, 'y': 28.4}]}, 'holes': []}, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'img7', 'metadata': {'path': 'a/b/c/img7.png'}, 'geospatial': {}}, 'annotations': [{'task_type': 'semantic-segmentation', 'labels': [{'key': 'class_label', 'value': 'cat', 'score': None}], 'metadata': {}, 'bounding_box': None, 'polygon': {'boundary': {'points': [{'x': 97.2, 'y': 40.2}, {'x': 33.33, 'y': 44.3}, {'x': 10.9, 'y': 18.7}]}, 'holes': []}, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'img8', 'metadata': {'path': 'a/b/c/img8.png'}, 'geospatial': {}}, 'annotations': [{'task_type': 'semantic-segmentation', 'labels': [{'key': 'class_label', 'value': 'car', 'score': None}], 'metadata': {}, 'bounding_box': None, 'polygon': {'boundary': {'points': [{'x': 10.0, 'y': 15.5}, {'x': 20.9, 'y': 50.2}, {'x': 25.9, 'y': 28.4}]}, 'holes': [{'points': [{'x': 60.0, 'y': 15.5}, {'x': 70.9, 'y': 50.2}, {'x': 75.9, 'y': 28.4}]}]}, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n"
     ]
    }
   ],
   "source": [
    "for element in image_segmentations:\n",
    "    # create groundtruth\n",
    "    groundtruth = create_groundtruth_from_image_segmentation_dict(element)\n",
    "\n",
    "    # add groundtruth to dataset\n",
    "    dataset.add_groundtruth(groundtruth)\n",
    "    \n",
    "    print(groundtruth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Text Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_classifications = [\n",
    "    {\"path\": \"a/b/c/text1.txt\", \"annotations\": [{\"sentiment\": {\"context\": \"Is the content of this product review postive?\", \"label\": \"positive\"}}]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_groundtruth_from_text_classification_dict(element: dict):\n",
    "    \n",
    "    # create Datum using filename, save the full filepath into metadata\n",
    "    datum = Datum(\n",
    "        uid=Path(element[\"path\"]).stem,\n",
    "        metadata={\n",
    "            \"path\": element[\"path\"],\n",
    "            \"context\": element[\"annotations\"][0][\"sentiment\"][\"context\"]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # create Annotation\n",
    "    annotations = [\n",
    "        Annotation(\n",
    "            task_type=TaskType.CLASSIFICATION,\n",
    "            labels=[\n",
    "                Label(\n",
    "                    key=\"label\", \n",
    "                    value=element[\"annotations\"][0][\"sentiment\"][\"label\"]\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # create and return GroundTruth\n",
    "    return GroundTruth(\n",
    "        datum=datum,\n",
    "        annotations=annotations,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datum': {'dataset': 'myDataset', 'uid': 'text1', 'metadata': {'path': 'a/b/c/text1.txt', 'context': 'Is the content of this product review postive?'}, 'geospatial': {}}, 'annotations': [{'task_type': 'classification', 'labels': [{'key': 'label', 'value': 'positive', 'score': None}], 'metadata': {}, 'bounding_box': None, 'polygon': None, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n"
     ]
    }
   ],
   "source": [
    "for element in text_classifications:\n",
    "    # create groundtruth\n",
    "    groundtruth = create_groundtruth_from_text_classification_dict(element)\n",
    "\n",
    "    # add groundtruth to dataset\n",
    "    dataset.add_groundtruth(groundtruth)\n",
    "    \n",
    "    print(groundtruth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Text Token Classification**\n",
    "\n",
    "This example is nuanced because the way datums are communicated is different between the source dictionary and Velour.\n",
    "\n",
    "Specifically, the location of the token is considered the `Datum` as it encodes what the subject of comparison is. We can apply this by encoding the positions into the `Datum` uid. As long as the model shares the same tokenizer as the dataset we can guarantee that this will lead to proper evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1087,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_classifications = [\n",
    "    {\"path\": \"a/b/c/text2.text\", \"annotations\": [{\"token_classification\": {\"start_position\": 19, \"end_position\": 22, \"label\": \"place\"}}]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_groundtruth_from_token_classification_dict(element: dict):\n",
    "\n",
    "    filename = Path(element[\"path\"]).stem\n",
    "    start_position = element[\"annotations\"][0][\"token_classification\"][\"start_position\"]\n",
    "    end_position = element[\"annotations\"][0][\"token_classification\"][\"end_position\"]\n",
    "    \n",
    "    # create Datum using filename, save the full filepath into metadata\n",
    "    datum = Datum(\n",
    "        uid=f\"{filename}_{start_position}_{end_position}\",\n",
    "        metadata={\n",
    "            \"path\": element[\"path\"],\n",
    "            \"filename\": filename,\n",
    "            \"start_position\": start_position,\n",
    "            \"end_position\": end_position,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # create Annotation\n",
    "    annotations = [\n",
    "        Annotation(\n",
    "            task_type=TaskType.CLASSIFICATION,\n",
    "            labels=[\n",
    "                Label(\n",
    "                    key=\"label\", \n",
    "                    value=element[\"annotations\"][0][\"token_classification\"]['label']\n",
    "                )\n",
    "            ],\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # create and return GroundTruth\n",
    "    return GroundTruth(\n",
    "        datum=datum,\n",
    "        annotations=annotations,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datum': {'dataset': 'myDataset', 'uid': 'text2_19_22', 'metadata': {'path': 'a/b/c/text2.text', 'filename': 'text2', 'start_position': 19, 'end_position': 22}, 'geospatial': {}}, 'annotations': [{'task_type': 'classification', 'labels': [{'key': 'label', 'value': 'place', 'score': None}], 'metadata': {}, 'bounding_box': None, 'polygon': None, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n"
     ]
    }
   ],
   "source": [
    "for element in token_classifications:\n",
    "    # create groundtruth\n",
    "    groundtruth = create_groundtruth_from_token_classification_dict(element)\n",
    "\n",
    "    # add groundtruth to dataset\n",
    "    dataset.add_groundtruth(groundtruth)\n",
    "    \n",
    "    print(groundtruth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Datatset Finalization**\n",
    "\n",
    "Now that we are done creating `GroundTruth` objects we can move on to finalizing the `Dataset`. This is required for evaluation but not for `Model` creation so it could also be done later. Velour makes this a requirement for traceability reasons, you can be certain that a `Dataset` that was finalized weeks ago will still be the same today.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 1090,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.finalize()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference by the model populate a dictionary of Datums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [],
   "source": [
    "datums_by_uid = {\n",
    "    datum.uid: datum\n",
    "    for datum in dataset.get_datums()\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Creating a Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    client=client,\n",
    "    name=\"myModel\",\n",
    "    metadata={\n",
    "        \"foo\": \"bar\",\n",
    "        \"some_number\": 4321,\n",
    "    },\n",
    "    geospatial=None,\n",
    "    reset=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Create Predictions**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Image Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classifications = [\n",
    "    {\"path\": \"a/b/c/img1.png\", \"annotations\": [{\"class_label\": \"dog\", \"score\": 0.9}, {\"class_label\": \"cat\", \"score\": 0.1}]},\n",
    "    {\"path\": \"a/b/c/img2.png\", \"annotations\": [{\"class_label\": \"dog\", \"score\": 0.1}, {\"class_label\": \"cat\", \"score\": 0.9}]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prediction_from_image_classification_dict(element: dict) -> Prediction:\n",
    "    \n",
    "    # get datum from dataset using filename\n",
    "    uid=Path(element[\"path\"]).stem\n",
    "    datum = datums_by_uid[uid]\n",
    "\n",
    "    # create Annotation\n",
    "    annotations = [\n",
    "        Annotation(\n",
    "            task_type=TaskType.CLASSIFICATION,\n",
    "            labels=[\n",
    "                Label(key=\"class_label\", value=label[\"class_label\"], score=label[\"score\"])\n",
    "                for label in element[\"annotations\"]\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # create and return Prediction\n",
    "    return Prediction(\n",
    "        model=model,\n",
    "        datum=datum,\n",
    "        annotations=annotations,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datum': {'dataset': 'myDataset', 'uid': 'img1', 'metadata': {'path': 'a/b/c/img1.png'}, 'geospatial': {}}, 'model': 'myModel', 'annotations': [{'task_type': 'classification', 'labels': [{'key': 'class_label', 'value': 'dog', 'score': 0.9}, {'key': 'class_label', 'value': 'cat', 'score': 0.1}], 'metadata': {}, 'bounding_box': None, 'polygon': None, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'img2', 'metadata': {'path': 'a/b/c/img2.png'}, 'geospatial': {}}, 'model': 'myModel', 'annotations': [{'task_type': 'classification', 'labels': [{'key': 'class_label', 'value': 'dog', 'score': 0.1}, {'key': 'class_label', 'value': 'cat', 'score': 0.9}], 'metadata': {}, 'bounding_box': None, 'polygon': None, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n"
     ]
    }
   ],
   "source": [
    "for element in image_classifications:\n",
    "    # create prediction\n",
    "    prediction = create_prediction_from_image_classification_dict(element)\n",
    "\n",
    "    # add prediction to dataset\n",
    "    model.add_prediction(prediction)\n",
    "    \n",
    "    print(prediction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Image Object Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_detections = [\n",
    "    {\"path\": \"a/b/c/img3.png\", \"annotations\": [\n",
    "        {\"labels\": [{\"class_label\": \"dog\", \"score\": 0.8}, {\"class_label\": \"cat\", \"score\": 0.1}, {\"class_label\": \"person\", \"score\": 0.1}], \"bbox\": {\"xmin\": 16, \"ymin\": 130, \"xmax\": 70, \"ymax\": 150}}, \n",
    "        {\"labels\": [{\"class_label\": \"dog\", \"score\": 0.05}, {\"class_label\": \"cat\", \"score\": 0.05}, {\"class_label\": \"person\", \"score\": 0.9}], \"bbox\": {\"xmin\": 89, \"ymin\": 10, \"xmax\": 97, \"ymax\": 110}}\n",
    "    ]},\n",
    "    {\"path\": \"a/b/c/img4.png\", \"annotations\": [\n",
    "        {\"labels\": [{\"class_label\": \"dog\", \"score\": 0.8}, {\"class_label\": \"cat\", \"score\": 0.1}, {\"class_label\": \"person\", \"score\": 0.1}], \"bbox\": {\"xmin\": 500, \"ymin\": 220, \"xmax\": 530, \"ymax\": 260}}\n",
    "    ]},\n",
    "    {\"path\": \"a/b/c/img5.png\", \"annotations\": []}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prediction_from_object_detection_dict(element: dict) -> Prediction:\n",
    "    \n",
    "    # get datum from dataset using filename\n",
    "    uid=Path(element[\"path\"]).stem\n",
    "    datum = datums_by_uid[uid]\n",
    "\n",
    "    # create Annotations\n",
    "    annotations = [\n",
    "        Annotation(\n",
    "            task_type=TaskType.DETECTION,\n",
    "            labels=[\n",
    "                Label(key=\"class_label\", value=label[\"class_label\"], score=label[\"score\"])\n",
    "                for label in annotation[\"labels\"]\n",
    "            ],\n",
    "            bounding_box=BoundingBox.from_extrema(\n",
    "                xmin=annotation[\"bbox\"][\"xmin\"],\n",
    "                xmax=annotation[\"bbox\"][\"xmax\"],\n",
    "                ymin=annotation[\"bbox\"][\"ymin\"],\n",
    "                ymax=annotation[\"bbox\"][\"ymax\"],\n",
    "            )\n",
    "        )\n",
    "        for annotation in element[\"annotations\"]\n",
    "        if len(annotation) > 0\n",
    "    ]\n",
    "\n",
    "    # create and return Prediction\n",
    "    return Prediction(\n",
    "        datum=datum,\n",
    "        annotations=annotations,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1098,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datum': {'dataset': 'myDataset', 'uid': 'img3', 'metadata': {'path': 'a/b/c/img3.png'}, 'geospatial': {}}, 'model': 'myModel', 'annotations': [{'task_type': 'object-detection', 'labels': [{'key': 'class_label', 'value': 'dog', 'score': 0.8}, {'key': 'class_label', 'value': 'cat', 'score': 0.1}, {'key': 'class_label', 'value': 'person', 'score': 0.1}], 'metadata': {}, 'bounding_box': {'polygon': {'points': [{'x': 16.0, 'y': 130.0}, {'x': 70.0, 'y': 130.0}, {'x': 70.0, 'y': 150.0}, {'x': 16.0, 'y': 150.0}]}}, 'polygon': None, 'multipolygon': None, 'raster': None, 'jsonb': None}, {'task_type': 'object-detection', 'labels': [{'key': 'class_label', 'value': 'dog', 'score': 0.05}, {'key': 'class_label', 'value': 'cat', 'score': 0.05}, {'key': 'class_label', 'value': 'person', 'score': 0.9}], 'metadata': {}, 'bounding_box': {'polygon': {'points': [{'x': 89.0, 'y': 10.0}, {'x': 97.0, 'y': 10.0}, {'x': 97.0, 'y': 110.0}, {'x': 89.0, 'y': 110.0}]}}, 'polygon': None, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'img4', 'metadata': {'path': 'a/b/c/img4.png'}, 'geospatial': {}}, 'model': 'myModel', 'annotations': [{'task_type': 'object-detection', 'labels': [{'key': 'class_label', 'value': 'dog', 'score': 0.8}, {'key': 'class_label', 'value': 'cat', 'score': 0.1}, {'key': 'class_label', 'value': 'person', 'score': 0.1}], 'metadata': {}, 'bounding_box': {'polygon': {'points': [{'x': 500.0, 'y': 220.0}, {'x': 530.0, 'y': 220.0}, {'x': 530.0, 'y': 260.0}, {'x': 500.0, 'y': 260.0}]}}, 'polygon': None, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'img5', 'metadata': {'path': 'a/b/c/img5.png'}, 'geospatial': {}}, 'model': 'myModel', 'annotations': []}\n"
     ]
    }
   ],
   "source": [
    "for element in object_detections:\n",
    "    # create prediction\n",
    "    prediction = create_prediction_from_object_detection_dict(element)\n",
    "\n",
    "    # add prediction to model\n",
    "    model.add_prediction(prediction)\n",
    "    \n",
    "    print(prediction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Image Semantic Segmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_segmentations = [\n",
    "    {\n",
    "        \"path\": \"a/b/c/img6.png\", \n",
    "        \"annotations\": [\n",
    "            {\n",
    "                \"class_label\": \"dog\",\n",
    "                \"contour\": [[{\"x\": 10.0, \"y\": 15.5}, {\"x\": 20.9, \"y\": 50.2}, {\"x\": 25.9, \"y\": 28.4}]]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"path\": \"a/b/c/img7.png\", \n",
    "        \"annotations\": [\n",
    "            {\n",
    "                \"class_label\": \"cat\",\n",
    "                \"contour\": [[{\"x\": 97.2, \"y\": 40.2}, {\"x\": 33.33, \"y\": 44.3}, {\"x\": 10.9, \"y\": 18.7}]]\n",
    "            }\n",
    "        ]   \n",
    "    },\n",
    "    {\n",
    "        \"path\": \"a/b/c/img8.png\", \n",
    "        \"annotations\": [\n",
    "            {\n",
    "                \"class_label\": \"car\",\n",
    "                \"contour\": [[{\"x\": 10.0, \"y\": 15.5}, {\"x\": 20.9, \"y\": 50.2}, {\"x\": 25.9, \"y\": 28.4}], [{\"x\": 60.0, \"y\": 15.5}, {\"x\": 70.9, \"y\": 50.2}, {\"x\": 75.9, \"y\": 28.4}]]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prediction_from_image_segmentation_dict(element: dict) -> Prediction:\n",
    "    \n",
    "    # get datum from dataset using filename\n",
    "    uid=Path(element[\"path\"]).stem\n",
    "    datum = datums_by_uid[uid]\n",
    "\n",
    "\n",
    "    # create Annotations\n",
    "    annotations = [\n",
    "        Annotation(\n",
    "            task_type=TaskType.SEGMENTATION,\n",
    "            labels=[\n",
    "                Label(key=\"class_label\", value=annotation[\"class_label\"])\n",
    "            ],\n",
    "            polygon=Polygon(\n",
    "                boundary=BasicPolygon(\n",
    "                    points=[\n",
    "                        Point(p[\"x\"], p[\"y\"])\n",
    "                        for p in annotation[\"contour\"][0]\n",
    "                    ],\n",
    "                ),\n",
    "                holes=[\n",
    "                    BasicPolygon(\n",
    "                        points=[\n",
    "                            Point(p[\"x\"], p[\"y\"])\n",
    "                            for p in hole\n",
    "                        ]\n",
    "                    )\n",
    "                    for hole in annotation[\"contour\"][1:]\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        for annotation in element[\"annotations\"]\n",
    "        if len(annotation[\"contour\"]) > 0\n",
    "    ]\n",
    "\n",
    "    # create and return Prediction\n",
    "    return Prediction(\n",
    "        datum=datum,\n",
    "        annotations=annotations,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datum': {'dataset': 'myDataset', 'uid': 'img6', 'metadata': {'path': 'a/b/c/img6.png'}, 'geospatial': {}}, 'model': 'myModel', 'annotations': [{'task_type': 'semantic-segmentation', 'labels': [{'key': 'class_label', 'value': 'dog', 'score': None}], 'metadata': {}, 'bounding_box': None, 'polygon': {'boundary': {'points': [{'x': 10.0, 'y': 15.5}, {'x': 20.9, 'y': 50.2}, {'x': 25.9, 'y': 28.4}]}, 'holes': []}, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'img7', 'metadata': {'path': 'a/b/c/img7.png'}, 'geospatial': {}}, 'model': 'myModel', 'annotations': [{'task_type': 'semantic-segmentation', 'labels': [{'key': 'class_label', 'value': 'cat', 'score': None}], 'metadata': {}, 'bounding_box': None, 'polygon': {'boundary': {'points': [{'x': 97.2, 'y': 40.2}, {'x': 33.33, 'y': 44.3}, {'x': 10.9, 'y': 18.7}]}, 'holes': []}, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'img8', 'metadata': {'path': 'a/b/c/img8.png'}, 'geospatial': {}}, 'model': 'myModel', 'annotations': [{'task_type': 'semantic-segmentation', 'labels': [{'key': 'class_label', 'value': 'car', 'score': None}], 'metadata': {}, 'bounding_box': None, 'polygon': {'boundary': {'points': [{'x': 10.0, 'y': 15.5}, {'x': 20.9, 'y': 50.2}, {'x': 25.9, 'y': 28.4}]}, 'holes': [{'points': [{'x': 60.0, 'y': 15.5}, {'x': 70.9, 'y': 50.2}, {'x': 75.9, 'y': 28.4}]}]}, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n"
     ]
    }
   ],
   "source": [
    "for element in image_segmentations:\n",
    "    # create prediction\n",
    "    prediction = create_prediction_from_image_segmentation_dict(element)\n",
    "\n",
    "    # add prediction to model\n",
    "    model.add_prediction(prediction)\n",
    "    \n",
    "    print(prediction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Text Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_classifications = [\n",
    "    {\n",
    "        \"path\": \"a/b/c/text1.txt\",\n",
    "        \"annotations\": [\n",
    "            {\"sentiment\": \n",
    "                {\n",
    "                    \"context\": \"Is the content of this product review postive?\", \n",
    "                    \"labels\": [\n",
    "                        {\"label\": \"positive\", \"score\": 0.8},\n",
    "                        {\"label\": \"negative\", \"score\": 0.2}\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prediction_from_text_classification_dict(element: dict) -> Prediction:\n",
    "    \n",
    "    # get datum from dataset using filename\n",
    "    uid=Path(element[\"path\"]).stem\n",
    "    datum = datums_by_uid[uid]\n",
    "\n",
    "    # create Annotation\n",
    "    annotations = [\n",
    "        Annotation(\n",
    "            task_type=TaskType.CLASSIFICATION,\n",
    "            labels=[\n",
    "                Label(\n",
    "                    key=\"label\", \n",
    "                    value=label[\"label\"],\n",
    "                    score=label[\"score\"],\n",
    "                )\n",
    "                for label in element[\"annotations\"][0][\"sentiment\"][\"labels\"]\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # create and return Prediction\n",
    "    return Prediction(\n",
    "        datum=datum,\n",
    "        annotations=annotations,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datum': {'dataset': 'myDataset', 'uid': 'text1', 'metadata': {'path': 'a/b/c/text1.txt', 'context': 'Is the content of this product review postive?'}, 'geospatial': {}}, 'model': 'myModel', 'annotations': [{'task_type': 'classification', 'labels': [{'key': 'label', 'value': 'positive', 'score': 0.8}, {'key': 'label', 'value': 'negative', 'score': 0.2}], 'metadata': {}, 'bounding_box': None, 'polygon': None, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n"
     ]
    }
   ],
   "source": [
    "for element in text_classifications:\n",
    "    # create prediction\n",
    "    prediction = create_prediction_from_text_classification_dict(element)\n",
    "\n",
    "    # add prediction to model\n",
    "    model.add_prediction(prediction)\n",
    "    \n",
    "    print(prediction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Finalization**\n",
    "\n",
    "Now that we are done creating `Prediction` objects we can move on to finalizing the `Model` over the existing `Dataset`. This is required for evaluation for traceability reasons, you can be certain that an inference run will be as useful tomorrow as it is today.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.finalize_inferences(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exploring the Client**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 32,\n",
       "  'name': 'myDataset',\n",
       "  'metadata': {'some_number': 1234.0,\n",
       "   'some_string': 'hello_world',\n",
       "   'a_different_number': 1.234},\n",
       "  'geospatial': {}}]"
      ]
     },
     "execution_count": 1106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 23,\n",
       "  'name': 'myModel',\n",
       "  'metadata': {'foo': 'bar', 'some_number': 4321.0},\n",
       "  'geospatial': {}}]"
      ]
     },
     "execution_count": 1107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_models()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exploring the Dataset**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dataset.get_datums()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': 'myDataset', 'uid': 'img1', 'metadata': {'path': 'a/b/c/img1.png'}, 'geospatial': {}}\n",
      "{'dataset': 'myDataset', 'uid': 'img2', 'metadata': {'path': 'a/b/c/img2.png'}, 'geospatial': {}}\n",
      "{'dataset': 'myDataset', 'uid': 'img3', 'metadata': {'path': 'a/b/c/img3.png'}, 'geospatial': {}}\n",
      "{'dataset': 'myDataset', 'uid': 'img4', 'metadata': {'path': 'a/b/c/img4.png'}, 'geospatial': {}}\n",
      "{'dataset': 'myDataset', 'uid': 'img5', 'metadata': {'path': 'a/b/c/img5.png'}, 'geospatial': {}}\n",
      "{'dataset': 'myDataset', 'uid': 'img6', 'metadata': {'path': 'a/b/c/img6.png'}, 'geospatial': {}}\n",
      "{'dataset': 'myDataset', 'uid': 'img7', 'metadata': {'path': 'a/b/c/img7.png'}, 'geospatial': {}}\n",
      "{'dataset': 'myDataset', 'uid': 'img8', 'metadata': {'path': 'a/b/c/img8.png'}, 'geospatial': {}}\n",
      "{'dataset': 'myDataset', 'uid': 'text1', 'metadata': {'path': 'a/b/c/text1.txt', 'context': 'Is the content of this product review postive?'}, 'geospatial': {}}\n",
      "{'dataset': 'myDataset', 'uid': 'text2_19_22', 'metadata': {'path': 'a/b/c/text2.text', 'filename': 'text2', 'end_position': 22.0, 'start_position': 19.0}, 'geospatial': {}}\n"
     ]
    }
   ],
   "source": [
    "for datum in dataset.get_datums():\n",
    "    print(datum)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dataset.get_groundtruth(uid: str)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datum': {'dataset': 'myDataset', 'uid': 'img1', 'metadata': {'path': 'a/b/c/img1.png'}, 'geospatial': {}}, 'annotations': [{'task_type': 'classification', 'labels': [{'key': 'class_label', 'value': 'dog', 'score': None}], 'metadata': {}, 'bounding_box': None, 'polygon': None, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'img2', 'metadata': {'path': 'a/b/c/img2.png'}, 'geospatial': {}}, 'annotations': [{'task_type': 'classification', 'labels': [{'key': 'class_label', 'value': 'cat', 'score': None}], 'metadata': {}, 'bounding_box': None, 'polygon': None, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'img3', 'metadata': {'path': 'a/b/c/img3.png'}, 'geospatial': {}}, 'annotations': [{'task_type': 'object-detection', 'labels': [{'key': 'class_label', 'value': 'dog', 'score': None}], 'metadata': {}, 'bounding_box': {'polygon': {'points': [{'x': 16.0, 'y': 130.0}, {'x': 70.0, 'y': 130.0}, {'x': 70.0, 'y': 150.0}, {'x': 16.0, 'y': 150.0}]}}, 'polygon': None, 'multipolygon': None, 'raster': None, 'jsonb': None}, {'task_type': 'object-detection', 'labels': [{'key': 'class_label', 'value': 'person', 'score': None}], 'metadata': {}, 'bounding_box': {'polygon': {'points': [{'x': 89.0, 'y': 10.0}, {'x': 97.0, 'y': 10.0}, {'x': 97.0, 'y': 110.0}, {'x': 89.0, 'y': 110.0}]}}, 'polygon': None, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'img4', 'metadata': {'path': 'a/b/c/img4.png'}, 'geospatial': {}}, 'annotations': [{'task_type': 'object-detection', 'labels': [{'key': 'class_label', 'value': 'cat', 'score': None}], 'metadata': {}, 'bounding_box': {'polygon': {'points': [{'x': 500.0, 'y': 220.0}, {'x': 530.0, 'y': 220.0}, {'x': 530.0, 'y': 260.0}, {'x': 500.0, 'y': 260.0}]}}, 'polygon': None, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'img5', 'metadata': {'path': 'a/b/c/img5.png'}, 'geospatial': {}}, 'annotations': []}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'img6', 'metadata': {'path': 'a/b/c/img6.png'}, 'geospatial': {}}, 'annotations': [{'task_type': 'semantic-segmentation', 'labels': [{'key': 'class_label', 'value': 'dog', 'score': None}], 'metadata': {}, 'bounding_box': None, 'polygon': {'boundary': {'points': [{'x': 10.0, 'y': 15.5}, {'x': 20.9, 'y': 50.2}, {'x': 25.9, 'y': 28.4}]}, 'holes': None}, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'img7', 'metadata': {'path': 'a/b/c/img7.png'}, 'geospatial': {}}, 'annotations': [{'task_type': 'semantic-segmentation', 'labels': [{'key': 'class_label', 'value': 'cat', 'score': None}], 'metadata': {}, 'bounding_box': None, 'polygon': {'boundary': {'points': [{'x': 97.2, 'y': 40.2}, {'x': 33.33, 'y': 44.3}, {'x': 10.9, 'y': 18.7}]}, 'holes': None}, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'img8', 'metadata': {'path': 'a/b/c/img8.png'}, 'geospatial': {}}, 'annotations': [{'task_type': 'semantic-segmentation', 'labels': [{'key': 'class_label', 'value': 'car', 'score': None}], 'metadata': {}, 'bounding_box': None, 'polygon': {'boundary': {'points': [{'x': 10.0, 'y': 15.5}, {'x': 20.9, 'y': 50.2}, {'x': 25.9, 'y': 28.4}]}, 'holes': [{'points': [{'x': 60.0, 'y': 15.5}, {'x': 70.9, 'y': 50.2}, {'x': 75.9, 'y': 28.4}]}]}, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'text1', 'metadata': {'path': 'a/b/c/text1.txt', 'context': 'Is the content of this product review postive?'}, 'geospatial': {}}, 'annotations': [{'task_type': 'classification', 'labels': [{'key': 'label', 'value': 'positive', 'score': None}], 'metadata': {}, 'bounding_box': None, 'polygon': None, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'text2_19_22', 'metadata': {'path': 'a/b/c/text2.text', 'filename': 'text2', 'end_position': 22.0, 'start_position': 19.0}, 'geospatial': {}}, 'annotations': [{'task_type': 'classification', 'labels': [{'key': 'label', 'value': 'place', 'score': None}], 'metadata': {}, 'bounding_box': None, 'polygon': None, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n"
     ]
    }
   ],
   "source": [
    "for datum in dataset.get_datums():\n",
    "    groundtruth = dataset.get_groundtruth(datum)\n",
    "    print(groundtruth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dataset.get_labels()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key': 'class_label', 'value': 'car', 'score': None}\n",
      "{'key': 'class_label', 'value': 'cat', 'score': None}\n",
      "{'key': 'class_label', 'value': 'person', 'score': None}\n",
      "{'key': 'class_label', 'value': 'dog', 'score': None}\n",
      "{'key': 'label', 'value': 'positive', 'score': None}\n",
      "{'key': 'label', 'value': 'place', 'score': None}\n"
     ]
    }
   ],
   "source": [
    "for label in dataset.get_labels():\n",
    "    print(label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exploring the Model**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Model.get_prediction(datum: Datum)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datum': {'dataset': 'myDataset', 'uid': 'img1', 'metadata': {'path': 'a/b/c/img1.png'}, 'geospatial': {}}, 'model': 'myModel', 'annotations': [{'task_type': 'classification', 'labels': [{'key': 'class_label', 'value': 'dog', 'score': 0.9}, {'key': 'class_label', 'value': 'cat', 'score': 0.1}], 'metadata': {}, 'bounding_box': None, 'polygon': None, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'img2', 'metadata': {'path': 'a/b/c/img2.png'}, 'geospatial': {}}, 'model': 'myModel', 'annotations': [{'task_type': 'classification', 'labels': [{'key': 'class_label', 'value': 'dog', 'score': 0.1}, {'key': 'class_label', 'value': 'cat', 'score': 0.9}], 'metadata': {}, 'bounding_box': None, 'polygon': None, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'img3', 'metadata': {'path': 'a/b/c/img3.png'}, 'geospatial': {}}, 'model': 'myModel', 'annotations': [{'task_type': 'object-detection', 'labels': [{'key': 'class_label', 'value': 'dog', 'score': 0.8}, {'key': 'class_label', 'value': 'cat', 'score': 0.1}, {'key': 'class_label', 'value': 'person', 'score': 0.1}], 'metadata': {}, 'bounding_box': {'polygon': {'points': [{'x': 16.0, 'y': 130.0}, {'x': 70.0, 'y': 130.0}, {'x': 70.0, 'y': 150.0}, {'x': 16.0, 'y': 150.0}]}}, 'polygon': None, 'multipolygon': None, 'raster': None, 'jsonb': None}, {'task_type': 'object-detection', 'labels': [{'key': 'class_label', 'value': 'dog', 'score': 0.05}, {'key': 'class_label', 'value': 'cat', 'score': 0.05}, {'key': 'class_label', 'value': 'person', 'score': 0.9}], 'metadata': {}, 'bounding_box': {'polygon': {'points': [{'x': 89.0, 'y': 10.0}, {'x': 97.0, 'y': 10.0}, {'x': 97.0, 'y': 110.0}, {'x': 89.0, 'y': 110.0}]}}, 'polygon': None, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'img4', 'metadata': {'path': 'a/b/c/img4.png'}, 'geospatial': {}}, 'model': 'myModel', 'annotations': [{'task_type': 'object-detection', 'labels': [{'key': 'class_label', 'value': 'dog', 'score': 0.8}, {'key': 'class_label', 'value': 'cat', 'score': 0.1}, {'key': 'class_label', 'value': 'person', 'score': 0.1}], 'metadata': {}, 'bounding_box': {'polygon': {'points': [{'x': 500.0, 'y': 220.0}, {'x': 530.0, 'y': 220.0}, {'x': 530.0, 'y': 260.0}, {'x': 500.0, 'y': 260.0}]}}, 'polygon': None, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'img5', 'metadata': {'path': 'a/b/c/img5.png'}, 'geospatial': {}}, 'model': 'myModel', 'annotations': []}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'img6', 'metadata': {'path': 'a/b/c/img6.png'}, 'geospatial': {}}, 'model': 'myModel', 'annotations': [{'task_type': 'semantic-segmentation', 'labels': [{'key': 'class_label', 'value': 'dog', 'score': None}], 'metadata': {}, 'bounding_box': None, 'polygon': {'boundary': {'points': [{'x': 10.0, 'y': 15.5}, {'x': 20.9, 'y': 50.2}, {'x': 25.9, 'y': 28.4}]}, 'holes': None}, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'img7', 'metadata': {'path': 'a/b/c/img7.png'}, 'geospatial': {}}, 'model': 'myModel', 'annotations': [{'task_type': 'semantic-segmentation', 'labels': [{'key': 'class_label', 'value': 'cat', 'score': None}], 'metadata': {}, 'bounding_box': None, 'polygon': {'boundary': {'points': [{'x': 97.2, 'y': 40.2}, {'x': 33.33, 'y': 44.3}, {'x': 10.9, 'y': 18.7}]}, 'holes': None}, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'img8', 'metadata': {'path': 'a/b/c/img8.png'}, 'geospatial': {}}, 'model': 'myModel', 'annotations': [{'task_type': 'semantic-segmentation', 'labels': [{'key': 'class_label', 'value': 'car', 'score': None}], 'metadata': {}, 'bounding_box': None, 'polygon': {'boundary': {'points': [{'x': 10.0, 'y': 15.5}, {'x': 20.9, 'y': 50.2}, {'x': 25.9, 'y': 28.4}]}, 'holes': [{'points': [{'x': 60.0, 'y': 15.5}, {'x': 70.9, 'y': 50.2}, {'x': 75.9, 'y': 28.4}]}]}, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'text1', 'metadata': {'path': 'a/b/c/text1.txt', 'context': 'Is the content of this product review postive?'}, 'geospatial': {}}, 'model': 'myModel', 'annotations': [{'task_type': 'classification', 'labels': [{'key': 'label', 'value': 'positive', 'score': 0.8}, {'key': 'label', 'value': 'negative', 'score': 0.2}], 'metadata': {}, 'bounding_box': None, 'polygon': None, 'multipolygon': None, 'raster': None, 'jsonb': None}]}\n",
      "{'datum': {'dataset': 'myDataset', 'uid': 'text2_19_22', 'metadata': {'path': 'a/b/c/text2.text', 'filename': 'text2', 'end_position': 22.0, 'start_position': 19.0}, 'geospatial': {}}, 'model': 'myModel', 'annotations': []}\n"
     ]
    }
   ],
   "source": [
    "for datum in dataset.get_datums():\n",
    "    print(model.get_prediction(datum))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Model.get_labels()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key': 'class_label', 'value': 'car', 'score': None}\n",
      "{'key': 'class_label', 'value': 'cat', 'score': None}\n",
      "{'key': 'class_label', 'value': 'person', 'score': None}\n",
      "{'key': 'label', 'value': 'negative', 'score': None}\n",
      "{'key': 'class_label', 'value': 'dog', 'score': None}\n",
      "{'key': 'label', 'value': 'positive', 'score': None}\n"
     ]
    }
   ],
   "source": [
    "for label in model.get_labels():\n",
    "    print(label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction to Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationResult(dataset='myDataset', model='myModel', settings=EvaluationSettings(parameters=None, filters=None), job_id=64, status='done', metrics=[{'type': 'Accuracy', 'parameters': {'label_key': 'class_label'}, 'value': 1.0}, {'type': 'ROCAUC', 'parameters': {'label_key': 'class_label'}, 'value': 1.0}, {'type': 'Precision', 'value': 1.0, 'label': {'key': 'class_label', 'value': 'cat'}}, {'type': 'Recall', 'value': 1.0, 'label': {'key': 'class_label', 'value': 'cat'}}, {'type': 'F1', 'value': 1.0, 'label': {'key': 'class_label', 'value': 'cat'}}, {'type': 'Precision', 'value': 1.0, 'label': {'key': 'class_label', 'value': 'dog'}}, {'type': 'Recall', 'value': 1.0, 'label': {'key': 'class_label', 'value': 'dog'}}, {'type': 'F1', 'value': 1.0, 'label': {'key': 'class_label', 'value': 'dog'}}, {'type': 'Accuracy', 'parameters': {'label_key': 'label'}, 'value': 1.0}, {'type': 'ROCAUC', 'parameters': {'label_key': 'label'}, 'value': -1.0}, {'type': 'Precision', 'value': -1.0, 'label': {'key': 'label', 'value': 'negative'}}, {'type': 'Recall', 'value': -1.0, 'label': {'key': 'label', 'value': 'negative'}}, {'type': 'F1', 'value': -1.0, 'label': {'key': 'label', 'value': 'negative'}}, {'type': 'Precision', 'value': 1.0, 'label': {'key': 'label', 'value': 'positive'}}, {'type': 'Recall', 'value': 1.0, 'label': {'key': 'label', 'value': 'positive'}}, {'type': 'F1', 'value': 1.0, 'label': {'key': 'label', 'value': 'positive'}}, {'type': 'Precision', 'value': -1.0, 'label': {'key': 'label', 'value': 'place'}}, {'type': 'Recall', 'value': -1.0, 'label': {'key': 'label', 'value': 'place'}}, {'type': 'F1', 'value': -1.0, 'label': {'key': 'label', 'value': 'place'}}], confusion_matrices=[{'label_key': 'class_label', 'entries': [{'prediction': 'cat', 'groundtruth': 'cat', 'count': 1}, {'prediction': 'dog', 'groundtruth': 'dog', 'count': 1}]}, {'label_key': 'label', 'entries': [{'prediction': 'positive', 'groundtruth': 'positive', 'count': 1}]}])"
      ]
     },
     "execution_count": 1113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_clf = model.evaluate_classification(dataset)\n",
    "eval_clf.wait_for_completion()\n",
    "eval_clf.results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationResult(dataset='myDataset', model='myModel', settings=EvaluationSettings(parameters=DetectionParameters(iou_thresholds_to_compute=[0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95], iou_thresholds_to_keep=[0.5, 0.75]), filters=Filter(dataset_names=None, dataset_metadata=None, dataset_geospatial=None, models_names=None, models_metadata=None, models_geospatial=None, datum_uids=None, datum_metadata=None, datum_geospatial=None, task_types=None, annotation_types=None, annotation_geometric_area=None, annotation_metadata=None, annotation_geospatial=None, prediction_scores=None, labels=None, label_ids=None, label_keys=None)), job_id=65, status='done', metrics=[{'type': 'AP', 'parameters': {'iou': 0.5}, 'value': 1.0, 'label': {'key': 'class_label', 'value': 'person'}}, {'type': 'AP', 'parameters': {'iou': 0.5}, 'value': 1.0, 'label': {'key': 'class_label', 'value': 'dog'}}, {'type': 'AP', 'parameters': {'iou': 0.5}, 'value': 1.0, 'label': {'key': 'class_label', 'value': 'cat'}}, {'type': 'AP', 'parameters': {'iou': 0.75}, 'value': 1.0, 'label': {'key': 'class_label', 'value': 'person'}}, {'type': 'AP', 'parameters': {'iou': 0.75}, 'value': 1.0, 'label': {'key': 'class_label', 'value': 'dog'}}, {'type': 'AP', 'parameters': {'iou': 0.75}, 'value': 1.0, 'label': {'key': 'class_label', 'value': 'cat'}}, {'type': 'mAP', 'parameters': {'iou': 0.5}, 'value': 1.0}, {'type': 'mAP', 'parameters': {'iou': 0.75}, 'value': 1.0}, {'type': 'APAveragedOverIOUs', 'parameters': {'ious': [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]}, 'value': 1.0, 'label': {'key': 'class_label', 'value': 'person'}}, {'type': 'APAveragedOverIOUs', 'parameters': {'ious': [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]}, 'value': 1.0, 'label': {'key': 'class_label', 'value': 'dog'}}, {'type': 'APAveragedOverIOUs', 'parameters': {'ious': [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]}, 'value': 1.0, 'label': {'key': 'class_label', 'value': 'cat'}}, {'type': 'mAPAveragedOverIOUs', 'parameters': {'ious': [0.5, 0.55, 0.6, 0.7, 0.65, 0.75, 0.8, 0.85, 0.9, 0.95]}, 'value': 1.0}], confusion_matrices=[])"
      ]
     },
     "execution_count": 1114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_objdet = model.evaluate_detection(dataset)\n",
    "eval_objdet.wait_for_completion()\n",
    "eval_objdet.results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationResult(dataset='myDataset', model='myModel', settings=EvaluationSettings(parameters=None, filters=Filter(dataset_names=None, dataset_metadata=None, dataset_geospatial=None, models_names=None, models_metadata=None, models_geospatial=None, datum_uids=None, datum_metadata=None, datum_geospatial=None, task_types=None, annotation_types=None, annotation_geometric_area=None, annotation_metadata=None, annotation_geospatial=None, prediction_scores=None, labels=None, label_ids=None, label_keys=None)), job_id=66, status='done', metrics=[{'type': 'mIOU', 'value': -1.0}], confusion_matrices=[])"
      ]
     },
     "execution_count": 1115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_semseg = model.evaluate_segmentation(dataset)\n",
    "eval_semseg.wait_for_completion()\n",
    "eval_semseg.results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env-velour",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
