{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Getting Started with Valor\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Valor is a centralized evaluation store which makes it easy to measure, explore, and rank model performance. Valor empowers data scientists and engineers to evaluate the performance of their machine learning pipelines and use those evaluations to make better modeling decisions in the future. For a conceptual introduction to Valor, [check out our project overview](https://striveworks.github.io/valor/).\n",
        "\n",
        "In this notebook, we'll introduce Valor's high-level abstractions and walk through a computer vision-oriented example of how you can use Valor to evaluate model performance. For task-specific examples, please see our follow-up notebooks below:\n",
        "- [Tabular classification](https://github.com/Striveworks/valor/blob/main/examples/classification/tabular.ipynb)\n",
        "- [Object detection](https://github.com/Striveworks/valor/blob/main/examples/object-detection/coco-yolo.ipynb)\n",
        "- [Semantic segmentation](https://github.com/Striveworks/valor/blob/main/examples/semantic-segmentation/coco-yolo.ipynb)\n",
        "\n",
        "Before using this notebook, please ensure that the Valor service is running on your machine (for start-up instructions, [click here](https://striveworks.github.io/valor/getting_started/)). To connect to a non-local instance of Valor, update `client = Client(\"http://0.0.0.0:8000\")` in the first code block to point to the correct URL."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## High-Level Workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Valor is equipped to handle a wide variety of supervised learning tasks thanks to its six core abstractions. We can think of these abstractions as being split into two categories:\n",
        "- **Dataset**: When describing our actual dataset, we define a `Dataset` containing a list of `GroundTruths` which, in turn, are made up of `Datums` and `Annotations`.\n",
        "- **Model**: When describing our model outputs, we define a `Model` containing a list of `Predictions` which, in turn, are also made up of `Datums` and `Annotations`. We then link our `Model` to a `Dataset` when finalizing the model.\n",
        "\n",
        "After we define both our dataset inputs and model outputs, Valor will make it easy to calculate and store our evaluation metrics. Let's start by describing our dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining Our Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To begin, we import all needed packages and connect to our Valor API using the `valor.Client` object. For instructions on setting up your API, please see [our docs here](https://striveworks.github.io/valor/getting_started/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The Valor client version (0.27.2.dev37+g6c9eaddf.d20240614) is newer than the Valor API version 0.27.2.dev37+g6c9eaddf\t==========================================================================================\n",
            "\t== Running with a mismatched client != API version may have unexpected results.\n",
            "\t== Please update your client to \u001b[1;0.27.2.dev37+g6c9eaddf\u001b[0;31m to avoid aberrant behavior.\n",
            "\t==========================================================================================\n",
            "\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully connected to host at http://0.0.0.0:8000/\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "from valor import (\n",
        "    connect,\n",
        "    Client,\n",
        "    Dataset,\n",
        "    Model,\n",
        "    Datum,\n",
        "    Annotation,\n",
        "    GroundTruth, \n",
        "    Prediction,\n",
        "    Label,\n",
        "    Filter,\n",
        ")\n",
        "from valor.schemas import (\n",
        "    Box, \n",
        "    Polygon,\n",
        "    Raster,\n",
        ")\n",
        "from valor.enums import TaskType\n",
        "\n",
        "# connect to the Valor API\n",
        "connect(\"http://0.0.0.0:8000\")\n",
        "client = Client()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we define our `Dataset` in Valor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = Dataset.create(  \n",
        "    name=\"myDataset\",\n",
        "    metadata={        # optional, metadata can take `str`, `int`, `float` value types.\n",
        "        \"some_string\": \"hello_world\",\n",
        "        \"some_number\": 1234,\n",
        "        \"a_different_number\": 1.234,\n",
        "    },\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To describe the various objects in our `Dataset`, we'll associate a list of `GroundTruths` (made up of `Annotations` and `Datums`) to the `Dataset` we defined above. Note that Valor doesn't actually store any images, and that the `Annotations` we use will vary by our task type (i.e., object detection, semantic segmentation, etc.). For demonstrative purposes, we'll create `GroundTruths` for four different learning tasks in this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Object Detection GroundTruths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'datum': {'uid': 'img3', 'metadata': {'path': 'a/b/c/img3.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': None}], 'bounding_box': [[(16, 130), (70, 130), (70, 150), (16, 150), (16, 130)]], 'polygon': None, 'raster': None, 'embedding': None, 'is_instance': True, 'implied_task_types': None}, {'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'person', 'score': None}], 'bounding_box': [[(89, 10), (97, 10), (97, 110), (89, 110), (89, 10)]], 'polygon': None, 'raster': None, 'embedding': None, 'is_instance': True, 'implied_task_types': None}]}\n",
            "{'datum': {'uid': 'img4', 'metadata': {'path': 'a/b/c/img4.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'cat', 'score': None}], 'bounding_box': [[(500, 220), (530, 220), (530, 260), (500, 260), (500, 220)]], 'polygon': None, 'raster': None, 'embedding': None, 'is_instance': True, 'implied_task_types': None}]}\n",
            "{'datum': {'uid': 'img5', 'metadata': {'path': 'a/b/c/img5.png'}}, 'annotations': []}\n"
          ]
        }
      ],
      "source": [
        "def create_groundtruth_from_object_detection_dict(element: dict):\n",
        "    \n",
        "\n",
        "    # each image is represented by a Valor Datum.\n",
        "    # this is used to connect ground truths and predictions when it's time for evaluation.\n",
        "    datum = Datum(\n",
        "        uid=Path(element[\"path\"]).stem,\n",
        "        metadata={\n",
        "            \"path\": element[\"path\"] \n",
        "        }\n",
        "    )\n",
        "\n",
        "    # a Valor Annotation consists of a task_type, labels, and, optionally, a geometry.\n",
        "    annotations = [\n",
        "        Annotation(\n",
        "            labels=[Label(key=\"class_label\", value=annotation[\"class_label\"])],\n",
        "            bounding_box=Box.from_extrema(\n",
        "                xmin=annotation[\"bbox\"][\"xmin\"],\n",
        "                xmax=annotation[\"bbox\"][\"xmax\"],\n",
        "                ymin=annotation[\"bbox\"][\"ymin\"],\n",
        "                ymax=annotation[\"bbox\"][\"ymax\"],\n",
        "            ),\n",
        "            is_instance=True,\n",
        "        )\n",
        "        for annotation in element[\"annotations\"]\n",
        "        if len(annotation) > 0\n",
        "    ]\n",
        "\n",
        "    # the datum and annotations we created are then used to form a GroundTruth\n",
        "    return GroundTruth(\n",
        "        datum=datum,\n",
        "        annotations=annotations,\n",
        "    )\n",
        "\n",
        "image_object_detections = [\n",
        "    {\"path\": \"a/b/c/img3.png\", \"annotations\": [{\"class_label\": \"dog\", \"bbox\": {\"xmin\": 16, \"ymin\": 130, \"xmax\": 70, \"ymax\": 150}}, {\"class_label\": \"person\", \"bbox\": {\"xmin\": 89, \"ymin\": 10, \"xmax\": 97, \"ymax\": 110}}]},\n",
        "    {\"path\": \"a/b/c/img4.png\", \"annotations\": [{\"class_label\": \"cat\", \"bbox\": {\"xmin\": 500, \"ymin\": 220, \"xmax\": 530, \"ymax\": 260}}]},\n",
        "    {\"path\": \"a/b/c/img5.png\", \"annotations\": []}\n",
        "]\n",
        "\n",
        "\n",
        "for element in image_object_detections:\n",
        "    # create ground truth\n",
        "    groundtruth = create_groundtruth_from_object_detection_dict(element)\n",
        "\n",
        "    # add ground truth to dataset\n",
        "    dataset.add_groundtruth(groundtruth)\n",
        "    \n",
        "    print(groundtruth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Image Classification GroundTruths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'datum': {'uid': 'img1', 'metadata': {'path': 'a/b/c/img1.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None, 'is_instance': None, 'implied_task_types': None}]}\n",
            "{'datum': {'uid': 'img2', 'metadata': {'path': 'a/b/c/img2.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'cat', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None, 'is_instance': None, 'implied_task_types': None}]}\n"
          ]
        }
      ],
      "source": [
        "def create_groundtruth_from_image_classification_dict(element: dict):\n",
        "    \n",
        "    # create Datum using filename, save the full filepath into metadata\n",
        "    datum = Datum(\n",
        "        uid=Path(element[\"path\"]).stem,\n",
        "        metadata={\n",
        "            \"path\": element[\"path\"]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # create Annotation\n",
        "    annotations = [\n",
        "        Annotation(\n",
        "            labels=[\n",
        "                Label(key=key, value=value)\n",
        "                for label in element[\"annotations\"]\n",
        "                for key, value in label.items()\n",
        "            ]\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # create and return GroundTruth\n",
        "    return GroundTruth(\n",
        "        datum=datum,\n",
        "        annotations=annotations,\n",
        "    )\n",
        "\n",
        "image_classifications = [\n",
        "    {\"path\": \"a/b/c/img1.png\", \"annotations\": [{\"class_label\": \"dog\"}]},\n",
        "    {\"path\": \"a/b/c/img2.png\", \"annotations\": [{\"class_label\": \"cat\"}]}\n",
        "]\n",
        "\n",
        "for element in image_classifications:\n",
        "    # create ground truth\n",
        "    groundtruth = create_groundtruth_from_image_classification_dict(element)\n",
        "\n",
        "    # add ground truth to dataset\n",
        "    dataset.add_groundtruth(groundtruth)\n",
        "    \n",
        "    print(groundtruth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Image Segmentation GroundTruths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'datum': {'uid': 'img6', 'metadata': {'path': 'a/b/c/img6.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': {'mask': 'iVBORw0KGgoAAAANSUhEUgAAAGQAAABkAQAAAABYmaj5AAAAFElEQVR4nGNgGAWjYBSMglFATwAABXgAAQj9RYMAAAAASUVORK5CYII=', 'geometry': [[(10, 15), (20, 50), (25, 28), (10, 15)]]}, 'embedding': None, 'is_instance': False, 'implied_task_types': None}]}\n",
            "{'datum': {'uid': 'img7', 'metadata': {'path': 'a/b/c/img7.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'cat', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': {'mask': 'iVBORw0KGgoAAAANSUhEUgAAAGQAAABkAQAAAABYmaj5AAAAFElEQVR4nGNgGAWjYBSMglFATwAABXgAAQj9RYMAAAAASUVORK5CYII=', 'geometry': [[(97, 40), (33, 44), (10, 18), (97, 40)]]}, 'embedding': None, 'is_instance': False, 'implied_task_types': None}]}\n",
            "{'datum': {'uid': 'img8', 'metadata': {'path': 'a/b/c/img8.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'car', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': {'mask': 'iVBORw0KGgoAAAANSUhEUgAAAGQAAABkAQAAAABYmaj5AAAAFElEQVR4nGNgGAWjYBSMglFATwAABXgAAQj9RYMAAAAASUVORK5CYII=', 'geometry': [[(10, 15), (20, 50), (25, 28), (10, 15)], [(60, 15), (70, 50), (75, 28), (60, 15)]]}, 'embedding': None, 'is_instance': False, 'implied_task_types': None}]}\n"
          ]
        }
      ],
      "source": [
        "def create_groundtruth_from_image_segmentation_dict(element: dict):\n",
        "    \n",
        "    # create Datum using filename, save the full filepath into metadata\n",
        "    datum = Datum(\n",
        "        uid=Path(element[\"path\"]).stem,\n",
        "        metadata={\n",
        "            \"path\": element[\"path\"] \n",
        "        }\n",
        "    )\n",
        "\n",
        "    # create Annotations\n",
        "    annotations = [\n",
        "        Annotation(\n",
        "            labels=[Label(key=\"class_label\", value=annotation[\"class_label\"])],\n",
        "            raster=Raster.from_geometry(\n",
        "                geometry=Polygon(\n",
        "                    [\n",
        "                        [\n",
        "                            (pt['x'], pt['y'])\n",
        "                            for pt in [*subpolygon, subpolygon[0]]\n",
        "                        ]\n",
        "                        for subpolygon in annotation[\"contour\"]\n",
        "                    ]\n",
        "                ),\n",
        "                height=100,\n",
        "                width=100,\n",
        "            ),\n",
        "            is_instance=False,\n",
        "        )\n",
        "        for annotation in element[\"annotations\"]\n",
        "        if len(annotation[\"contour\"]) > 0\n",
        "    ]\n",
        "\n",
        "    # create and return GroundTruth\n",
        "    return GroundTruth(\n",
        "        datum=datum,\n",
        "        annotations=annotations,\n",
        "    )\n",
        "\n",
        "image_segmentations = [\n",
        "    {\"path\": \"a/b/c/img6.png\", \"annotations\": [{\"class_label\": \"dog\", \"contour\": [[{\"x\": 10, \"y\": 15}, {\"x\": 20, \"y\": 50}, {\"x\": 25, \"y\": 28}]]}]},\n",
        "    {\"path\": \"a/b/c/img7.png\", \"annotations\": [{\"class_label\": \"cat\", \"contour\": [[{\"x\": 97, \"y\": 40}, {\"x\": 33, \"y\": 44}, {\"x\": 10, \"y\": 18}]]}]},\n",
        "    {\"path\": \"a/b/c/img8.png\", \"annotations\": [{\"class_label\": \"car\", \"contour\": [[{\"x\": 10, \"y\": 15}, {\"x\": 20, \"y\": 50}, {\"x\": 25, \"y\": 28}], [{\"x\": 60, \"y\": 15}, {\"x\": 70, \"y\": 50}, {\"x\": 75, \"y\": 28}]]}]}\n",
        "]\n",
        "\n",
        "for element in image_segmentations:\n",
        "    # create ground truth\n",
        "    groundtruth = create_groundtruth_from_image_segmentation_dict(element)\n",
        "\n",
        "    # add ground truth to dataset\n",
        "    dataset.add_groundtruth(groundtruth)\n",
        "    \n",
        "    print(groundtruth)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Text Classification GroundTruths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'datum': {'uid': 'text1', 'metadata': {'path': 'a/b/c/text1.txt', 'context': 'Is the content of this product review postive?'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'label', 'value': 'positive', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None, 'is_instance': None, 'implied_task_types': None}]}\n"
          ]
        }
      ],
      "source": [
        "def create_groundtruth_from_text_classification_dict(element: dict):\n",
        "    \n",
        "    # create Datum using filename, save the full filepath into metadata\n",
        "    datum = Datum(\n",
        "        uid=Path(element[\"path\"]).stem,\n",
        "        metadata={\n",
        "            \"path\": element[\"path\"],\n",
        "            \"context\": element[\"annotations\"][0][\"sentiment\"][\"context\"]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # create Annotation\n",
        "    annotations = [\n",
        "        Annotation(\n",
        "            labels=[\n",
        "                Label(\n",
        "                    key=\"label\", \n",
        "                    value=element[\"annotations\"][0][\"sentiment\"][\"label\"]\n",
        "                )\n",
        "            ]\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # create and return GroundTruth\n",
        "    return GroundTruth(\n",
        "        datum=datum,\n",
        "        annotations=annotations,\n",
        "    )\n",
        "\n",
        "text_classifications = [\n",
        "    {\"path\": \"a/b/c/text1.txt\", \"annotations\": [{\"sentiment\": {\"context\": \"Is the content of this product review postive?\", \"label\": \"positive\"}}]}\n",
        "]\n",
        "\n",
        "for element in text_classifications:\n",
        "    # create ground truth\n",
        "    groundtruth = create_groundtruth_from_text_classification_dict(element)\n",
        "\n",
        "    # add ground truth to dataset\n",
        "    dataset.add_groundtruth(groundtruth)\n",
        "    \n",
        "    print(groundtruth)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Finalizing Our Dataset\n",
        "\n",
        "Now that we've created all of our `GroundTruth` objects, we finalize our `Dataset` such that it's ready for evaluation. Valor makes finalization a requirement for traceability purposes: we want you to feel confident that a finalized `Dataset` or `Model` won't change over any length of time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.finalize()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining Our Model\n",
        "\n",
        "Now that we've described our dataset, the next step is to define our model and subsequent predictions. Again, for demonstrative purposes, we'll define predictions for four separate task types in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Model.create(\n",
        "    name=\"myModel\",\n",
        "    metadata={\n",
        "        \"foo\": \"bar\",\n",
        "        \"some_number\": 4321,\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Object Detection Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'datum': {'uid': 'img3', 'metadata': {'path': 'a/b/c/img3.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': 0.8}, {'key': 'class_label', 'value': 'cat', 'score': 0.1}, {'key': 'class_label', 'value': 'person', 'score': 0.1}], 'bounding_box': [[(16, 130), (70, 130), (70, 150), (16, 150), (16, 130)]], 'polygon': None, 'raster': None, 'embedding': None, 'is_instance': True, 'implied_task_types': None}, {'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': 0.05}, {'key': 'class_label', 'value': 'cat', 'score': 0.05}, {'key': 'class_label', 'value': 'person', 'score': 0.9}], 'bounding_box': [[(89, 10), (97, 10), (97, 110), (89, 110), (89, 10)]], 'polygon': None, 'raster': None, 'embedding': None, 'is_instance': True, 'implied_task_types': None}]}\n",
            "{'datum': {'uid': 'img4', 'metadata': {'path': 'a/b/c/img4.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': 0.8}, {'key': 'class_label', 'value': 'cat', 'score': 0.1}, {'key': 'class_label', 'value': 'person', 'score': 0.1}], 'bounding_box': [[(500, 220), (530, 220), (530, 260), (500, 260), (500, 220)]], 'polygon': None, 'raster': None, 'embedding': None, 'is_instance': True, 'implied_task_types': None}]}\n",
            "{'datum': {'uid': 'img5', 'metadata': {'path': 'a/b/c/img5.png'}}, 'annotations': []}\n"
          ]
        }
      ],
      "source": [
        "# populate a dictionary mapping Datum UIDs to datums for all of the datums in our dataset\n",
        "datums_by_uid = {\n",
        "    datum.uid: datum\n",
        "    for datum in dataset.get_datums()\n",
        "}\n",
        "\n",
        "def create_prediction_from_object_detection_dict(element: dict, datums_by_uid:dict) -> Prediction:\n",
        "    \n",
        "    # get datum from dataset using filename\n",
        "    uid=Path(element[\"path\"]).stem\n",
        "    datum = datums_by_uid[uid]\n",
        "\n",
        "    # create Annotations\n",
        "    annotations = [\n",
        "        Annotation(\n",
        "            labels=[\n",
        "                Label(key=\"class_label\", value=label[\"class_label\"], score=label[\"score\"])\n",
        "                for label in annotation[\"labels\"]\n",
        "            ],\n",
        "            bounding_box=Box.from_extrema(\n",
        "                xmin=annotation[\"bbox\"][\"xmin\"],\n",
        "                xmax=annotation[\"bbox\"][\"xmax\"],\n",
        "                ymin=annotation[\"bbox\"][\"ymin\"],\n",
        "                ymax=annotation[\"bbox\"][\"ymax\"],\n",
        "            ),\n",
        "            is_instance=True,\n",
        "        )\n",
        "        for annotation in element[\"annotations\"]\n",
        "        if len(annotation) > 0\n",
        "    ]\n",
        "\n",
        "    # create and return Prediction\n",
        "    return Prediction(\n",
        "        datum=datum,\n",
        "        annotations=annotations,\n",
        "    )\n",
        "\n",
        "object_detections = [\n",
        "    {\"path\": \"a/b/c/img3.png\", \"annotations\": [\n",
        "        {\"labels\": [{\"class_label\": \"dog\", \"score\": 0.8}, {\"class_label\": \"cat\", \"score\": 0.1}, {\"class_label\": \"person\", \"score\": 0.1}], \"bbox\": {\"xmin\": 16, \"ymin\": 130, \"xmax\": 70, \"ymax\": 150}}, \n",
        "        {\"labels\": [{\"class_label\": \"dog\", \"score\": 0.05}, {\"class_label\": \"cat\", \"score\": 0.05}, {\"class_label\": \"person\", \"score\": 0.9}], \"bbox\": {\"xmin\": 89, \"ymin\": 10, \"xmax\": 97, \"ymax\": 110}}\n",
        "    ]},\n",
        "    {\"path\": \"a/b/c/img4.png\", \"annotations\": [\n",
        "        {\"labels\": [{\"class_label\": \"dog\", \"score\": 0.8}, {\"class_label\": \"cat\", \"score\": 0.1}, {\"class_label\": \"person\", \"score\": 0.1}], \"bbox\": {\"xmin\": 500, \"ymin\": 220, \"xmax\": 530, \"ymax\": 260}}\n",
        "    ]},\n",
        "    {\"path\": \"a/b/c/img5.png\", \"annotations\": []}\n",
        "]\n",
        "\n",
        "for element in object_detections:\n",
        "    # create prediction\n",
        "    prediction = create_prediction_from_object_detection_dict(element, datums_by_uid=datums_by_uid)\n",
        "\n",
        "    # add prediction to model\n",
        "    model.add_prediction(dataset, prediction)\n",
        "    \n",
        "    print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Image Classification Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'datum': {'uid': 'img1', 'metadata': {'path': 'a/b/c/img1.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': 0.9}, {'key': 'class_label', 'value': 'cat', 'score': 0.1}], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None, 'is_instance': None, 'implied_task_types': None}]}\n",
            "{'datum': {'uid': 'img2', 'metadata': {'path': 'a/b/c/img2.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': 0.1}, {'key': 'class_label', 'value': 'cat', 'score': 0.9}], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None, 'is_instance': None, 'implied_task_types': None}]}\n"
          ]
        }
      ],
      "source": [
        "def create_prediction_from_image_classification_dict(element: dict, datums_by_uid:dict) -> Prediction:\n",
        "    \n",
        "    # get datum from dataset using filename\n",
        "    uid=Path(element[\"path\"]).stem\n",
        "    datum = datums_by_uid[uid]\n",
        "\n",
        "    # create Annotation\n",
        "    annotations = [\n",
        "        Annotation(\n",
        "            labels=[\n",
        "                Label(key=\"class_label\", value=label[\"class_label\"], score=label[\"score\"])\n",
        "                for label in element[\"annotations\"]\n",
        "            ]\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # create and return Prediction\n",
        "    return Prediction(\n",
        "        datum=datum,\n",
        "        annotations=annotations,\n",
        "    )\n",
        "\n",
        "image_classifications = [\n",
        "    {\"path\": \"a/b/c/img1.png\", \"annotations\": [{\"class_label\": \"dog\", \"score\": 0.9}, {\"class_label\": \"cat\", \"score\": 0.1}]},\n",
        "    {\"path\": \"a/b/c/img2.png\", \"annotations\": [{\"class_label\": \"dog\", \"score\": 0.1}, {\"class_label\": \"cat\", \"score\": 0.9}]}\n",
        "]\n",
        "\n",
        "for element in image_classifications:\n",
        "    # create prediction\n",
        "    prediction = create_prediction_from_image_classification_dict(element, datums_by_uid=datums_by_uid)\n",
        "\n",
        "    # add prediction to dataset\n",
        "    model.add_prediction(dataset, prediction)\n",
        "    \n",
        "    print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Image Segmentation Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'datum': {'uid': 'img6', 'metadata': {'path': 'a/b/c/img6.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': {'mask': 'iVBORw0KGgoAAAANSUhEUgAAAGQAAABkAQAAAABYmaj5AAAAFElEQVR4nGNgGAWjYBSMglFATwAABXgAAQj9RYMAAAAASUVORK5CYII=', 'geometry': [[(10, 15), (20, 50), (25, 28), (10, 15)]]}, 'embedding': None, 'is_instance': False, 'implied_task_types': None}]}\n",
            "{'datum': {'uid': 'img7', 'metadata': {'path': 'a/b/c/img7.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'cat', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': {'mask': 'iVBORw0KGgoAAAANSUhEUgAAAGQAAABkAQAAAABYmaj5AAAAFElEQVR4nGNgGAWjYBSMglFATwAABXgAAQj9RYMAAAAASUVORK5CYII=', 'geometry': [[(97, 40), (33, 44), (10, 18), (97, 40)]]}, 'embedding': None, 'is_instance': False, 'implied_task_types': None}]}\n",
            "{'datum': {'uid': 'img8', 'metadata': {'path': 'a/b/c/img8.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'car', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': {'mask': 'iVBORw0KGgoAAAANSUhEUgAAAGQAAABkAQAAAABYmaj5AAAAFElEQVR4nGNgGAWjYBSMglFATwAABXgAAQj9RYMAAAAASUVORK5CYII=', 'geometry': [[(10, 15), (20, 50), (25, 28), (10, 15)], [(60, 15), (70, 50), (75, 28), (60, 15)]]}, 'embedding': None, 'is_instance': False, 'implied_task_types': None}]}\n"
          ]
        }
      ],
      "source": [
        "def create_prediction_from_image_segmentation_dict(element: dict, datums_by_uid: dict) -> Prediction:\n",
        "    \n",
        "    # get datum from dataset using filename\n",
        "    uid=Path(element[\"path\"]).stem\n",
        "    datum = datums_by_uid[uid]\n",
        "\n",
        "\n",
        "    # create Annotations\n",
        "    annotations = [\n",
        "        Annotation(\n",
        "            labels=[\n",
        "                Label(key=\"class_label\", value=annotation[\"class_label\"])\n",
        "            ],\n",
        "            raster=Raster.from_geometry(\n",
        "                geometry=Polygon(\n",
        "                    [\n",
        "                        [\n",
        "                            (pt['x'], pt['y'])\n",
        "                            for pt in [*subpolygon, subpolygon[0]]\n",
        "                        ]\n",
        "                        for subpolygon in annotation[\"contour\"]\n",
        "                    ]\n",
        "                ),\n",
        "                height=100,\n",
        "                width=100,\n",
        "            ),\n",
        "            is_instance=False,\n",
        "        )\n",
        "        for annotation in element[\"annotations\"]\n",
        "        if len(annotation[\"contour\"]) > 0\n",
        "    ]\n",
        "\n",
        "    # create and return Prediction\n",
        "    return Prediction(\n",
        "        datum=datum,\n",
        "        annotations=annotations,\n",
        "    )\n",
        "\n",
        "image_segmentations = [\n",
        "    {\n",
        "        \"path\": \"a/b/c/img6.png\", \n",
        "        \"annotations\": [\n",
        "            {\n",
        "                \"class_label\": \"dog\",\n",
        "                \"contour\": [[{\"x\": 10, \"y\": 15}, {\"x\": 20, \"y\": 50}, {\"x\": 25, \"y\": 28}]]\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"path\": \"a/b/c/img7.png\", \n",
        "        \"annotations\": [\n",
        "            {\n",
        "                \"class_label\": \"cat\",\n",
        "                \"contour\": [[{\"x\": 97, \"y\": 40}, {\"x\": 33, \"y\": 44}, {\"x\": 10, \"y\": 18}]]\n",
        "            }\n",
        "        ]   \n",
        "    },\n",
        "    {\n",
        "        \"path\": \"a/b/c/img8.png\", \n",
        "        \"annotations\": [\n",
        "            {\n",
        "                \"class_label\": \"car\",\n",
        "                \"contour\": [[{\"x\": 10, \"y\": 15}, {\"x\": 20, \"y\": 50}, {\"x\": 25, \"y\": 28}], [{\"x\": 60, \"y\": 15}, {\"x\": 70, \"y\": 50}, {\"x\": 75, \"y\": 28}]]\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "for element in image_segmentations:\n",
        "    # create prediction\n",
        "    prediction = create_prediction_from_image_segmentation_dict(element, datums_by_uid=datums_by_uid)\n",
        "\n",
        "    # add prediction to model\n",
        "    model.add_prediction(dataset, prediction)\n",
        "    \n",
        "    print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Text Classification Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'datum': {'uid': 'text1', 'metadata': {'path': 'a/b/c/text1.txt', 'context': 'Is the content of this product review postive?'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'label', 'value': 'positive', 'score': 0.8}, {'key': 'label', 'value': 'negative', 'score': 0.2}], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None, 'is_instance': None, 'implied_task_types': None}]}\n"
          ]
        }
      ],
      "source": [
        "def create_prediction_from_text_classification_dict(element: dict, datums_by_uid:dict) -> Prediction:\n",
        "    \n",
        "    # get datum from dataset using filename\n",
        "    uid=Path(element[\"path\"]).stem\n",
        "    datum = datums_by_uid[uid]\n",
        "\n",
        "    # create Annotation\n",
        "    annotations = [\n",
        "        Annotation(\n",
        "            labels=[\n",
        "                Label(\n",
        "                    key=\"label\", \n",
        "                    value=label[\"label\"],\n",
        "                    score=label[\"score\"],\n",
        "                )\n",
        "                for label in element[\"annotations\"][0][\"sentiment\"][\"labels\"]\n",
        "            ]\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # create and return Prediction\n",
        "    return Prediction(\n",
        "        datum=datum,\n",
        "        annotations=annotations,\n",
        "    )\n",
        "\n",
        "text_classifications = [\n",
        "    {\n",
        "        \"path\": \"a/b/c/text1.txt\",\n",
        "        \"annotations\": [\n",
        "            {\"sentiment\": \n",
        "                {\n",
        "                    \"context\": \"Is the content of this product review postive?\", \n",
        "                    \"labels\": [\n",
        "                        {\"label\": \"positive\", \"score\": 0.8},\n",
        "                        {\"label\": \"negative\", \"score\": 0.2}\n",
        "                    ]\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "for element in text_classifications:\n",
        "    # create prediction\n",
        "    prediction = create_prediction_from_text_classification_dict(element, datums_by_uid=datums_by_uid)\n",
        "\n",
        "    # add prediction to model\n",
        "    model.add_prediction(dataset, prediction)\n",
        "    \n",
        "    print(prediction)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Finalizing Our Model\n",
        "\n",
        "Now that we've created all of our `Prediction` objects, we finalize our `Model` such that it's ready for evaluation. When finalizing our `Model`, we pass in the `Dataset` object that we want to link it to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.finalize_inferences(dataset)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploring Our Objects\n",
        "\n",
        "Now that we've finalized our `Dataset` and `Model`, we can explore all of the objects stored in Valor before running our evaluations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Client Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Dataset({'name': 'myDataset', 'metadata': {'some_number': 1234, 'some_string': 'hello_world', 'a_different_number': 1.234}})]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.get_datasets()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Model({'name': 'myModel', 'metadata': {'foo': 'bar', 'some_number': 4321}})]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.get_models()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'uid': 'text1', 'metadata': {'path': 'a/b/c/text1.txt', 'context': 'Is the content of this product review postive?'}}\n",
            "{'uid': 'img8', 'metadata': {'path': 'a/b/c/img8.png'}}\n",
            "{'uid': 'img7', 'metadata': {'path': 'a/b/c/img7.png'}}\n",
            "{'uid': 'img6', 'metadata': {'path': 'a/b/c/img6.png'}}\n",
            "{'uid': 'img2', 'metadata': {'path': 'a/b/c/img2.png'}}\n",
            "{'uid': 'img1', 'metadata': {'path': 'a/b/c/img1.png'}}\n",
            "{'uid': 'img5', 'metadata': {'path': 'a/b/c/img5.png'}}\n",
            "{'uid': 'img4', 'metadata': {'path': 'a/b/c/img4.png'}}\n",
            "{'uid': 'img3', 'metadata': {'path': 'a/b/c/img3.png'}}\n"
          ]
        }
      ],
      "source": [
        "for datum in dataset.get_datums():\n",
        "    print(datum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'datum': {'uid': 'text1', 'metadata': {'path': 'a/b/c/text1.txt', 'context': 'Is the content of this product review postive?'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'label', 'value': 'positive', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None, 'is_instance': None, 'implied_task_types': ['classification']}]}\n",
            "{'datum': {'uid': 'img8', 'metadata': {'path': 'a/b/c/img8.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'car', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': {'mask': 'iVBORw0KGgoAAAANSUhEUgAAAGQAAABkAQAAAABYmaj5AAAAjUlEQVR4nO3RsQ3CMBQE0BcHAR2UlBmE4RjNozACJQVKKPwV2YmUAaJcY92/87+Tzf4wgCtI7uAU2gOcQyvTLlgqllc5bqDPwTL0n+KsI5I24vKFbgytikjaiH4CUy5aTAezbUbrHKslrXPJyjU5tIpu34sq72BV4LKZJ+KxVlt+pfVa03zEVpcDB/aIP/qxFseFJQEwAAAAAElFTkSuQmCC', 'geometry': None}, 'embedding': None, 'is_instance': False, 'implied_task_types': ['semantic-segmentation']}]}\n",
            "{'datum': {'uid': 'img7', 'metadata': {'path': 'a/b/c/img7.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'cat', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': {'mask': 'iVBORw0KGgoAAAANSUhEUgAAAGQAAABkAQAAAABYmaj5AAAAgklEQVR4nO2PsRHCQAwE90Xg0B1AC3RoD5W5FHeAQwLGR4BeEjXwF93Nju7+4Z91L954/rD5qGlSTRdV2JTQEFS4JDTYEtp3JdNOvZwlncFeQNtzPqDBScAGCEDmC2tAi+qrp428hJvktZYPcTipQwPe3vPov5e09vLqYSl+aGjI9QHRET1lf0wOaAAAAABJRU5ErkJggg==', 'geometry': None}, 'embedding': None, 'is_instance': False, 'implied_task_types': ['semantic-segmentation']}]}\n",
            "{'datum': {'uid': 'img6', 'metadata': {'path': 'a/b/c/img6.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': {'mask': 'iVBORw0KGgoAAAANSUhEUgAAAGQAAABkAQAAAABYmaj5AAAAYUlEQVR4nO2NMQ6AIBAEVyCx1JKSh/g249N8loVRWkdzF2vCVkxml5PaS3m8g2a4DJdAAc0JTjuogHBiPOASCCfiDacNZDWl4bWzSBKb/3cr3OU0F+fP09lly32aPT3NpQJReQrNLNp22AAAAABJRU5ErkJggg==', 'geometry': None}, 'embedding': None, 'is_instance': False, 'implied_task_types': ['semantic-segmentation']}]}\n",
            "{'datum': {'uid': 'img2', 'metadata': {'path': 'a/b/c/img2.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'cat', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None, 'is_instance': None, 'implied_task_types': ['classification']}]}\n",
            "{'datum': {'uid': 'img1', 'metadata': {'path': 'a/b/c/img1.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None, 'is_instance': None, 'implied_task_types': ['classification']}]}\n",
            "{'datum': {'uid': 'img5', 'metadata': {'path': 'a/b/c/img5.png'}}, 'annotations': [{'metadata': {}, 'labels': [], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None, 'is_instance': None, 'implied_task_types': ['empty']}]}\n",
            "{'datum': {'uid': 'img4', 'metadata': {'path': 'a/b/c/img4.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'cat', 'score': None}], 'bounding_box': [[(500.0, 220.0), (530.0, 220.0), (530.0, 260.0), (500.0, 260.0), (500.0, 220.0)]], 'polygon': None, 'raster': None, 'embedding': None, 'is_instance': True, 'implied_task_types': ['object-detection']}]}\n",
            "{'datum': {'uid': 'img3', 'metadata': {'path': 'a/b/c/img3.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': None}], 'bounding_box': [[(16.0, 130.0), (70.0, 130.0), (70.0, 150.0), (16.0, 150.0), (16.0, 130.0)]], 'polygon': None, 'raster': None, 'embedding': None, 'is_instance': True, 'implied_task_types': ['object-detection']}, {'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'person', 'score': None}], 'bounding_box': [[(89.0, 10.0), (97.0, 10.0), (97.0, 110.0), (89.0, 110.0), (89.0, 10.0)]], 'polygon': None, 'raster': None, 'embedding': None, 'is_instance': True, 'implied_task_types': ['object-detection']}]}\n"
          ]
        }
      ],
      "source": [
        "for datum in dataset.get_datums():\n",
        "    groundtruth = dataset.get_groundtruth(datum)\n",
        "    print(groundtruth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'key': 'class_label', 'value': 'car', 'score': None}\n",
            "{'key': 'label', 'value': 'positive', 'score': None}\n",
            "{'key': 'class_label', 'value': 'person', 'score': None}\n",
            "{'key': 'class_label', 'value': 'cat', 'score': None}\n",
            "{'key': 'class_label', 'value': 'dog', 'score': None}\n"
          ]
        }
      ],
      "source": [
        "for label in dataset.get_labels():\n",
        "    print(label)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'datum': {'uid': 'text1', 'metadata': {'path': 'a/b/c/text1.txt', 'context': 'Is the content of this product review postive?'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'label', 'value': 'positive', 'score': 0.8}, {'key': 'label', 'value': 'negative', 'score': 0.2}], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None, 'is_instance': None, 'implied_task_types': ['classification']}]}\n",
            "{'datum': {'uid': 'img8', 'metadata': {'path': 'a/b/c/img8.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'car', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': {'mask': 'iVBORw0KGgoAAAANSUhEUgAAAGQAAABkAQAAAABYmaj5AAAAjUlEQVR4nO3RsQ3CMBQE0BcHAR2UlBmE4RjNozACJQVKKPwV2YmUAaJcY92/87+Tzf4wgCtI7uAU2gOcQyvTLlgqllc5bqDPwTL0n+KsI5I24vKFbgytikjaiH4CUy5aTAezbUbrHKslrXPJyjU5tIpu34sq72BV4LKZJ+KxVlt+pfVa03zEVpcDB/aIP/qxFseFJQEwAAAAAElFTkSuQmCC', 'geometry': None}, 'embedding': None, 'is_instance': False, 'implied_task_types': ['semantic-segmentation']}]}\n",
            "{'datum': {'uid': 'img7', 'metadata': {'path': 'a/b/c/img7.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'cat', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': {'mask': 'iVBORw0KGgoAAAANSUhEUgAAAGQAAABkAQAAAABYmaj5AAAAgklEQVR4nO2PsRHCQAwE90Xg0B1AC3RoD5W5FHeAQwLGR4BeEjXwF93Nju7+4Z91L954/rD5qGlSTRdV2JTQEFS4JDTYEtp3JdNOvZwlncFeQNtzPqDBScAGCEDmC2tAi+qrp428hJvktZYPcTipQwPe3vPov5e09vLqYSl+aGjI9QHRET1lf0wOaAAAAABJRU5ErkJggg==', 'geometry': None}, 'embedding': None, 'is_instance': False, 'implied_task_types': ['semantic-segmentation']}]}\n",
            "{'datum': {'uid': 'img6', 'metadata': {'path': 'a/b/c/img6.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': {'mask': 'iVBORw0KGgoAAAANSUhEUgAAAGQAAABkAQAAAABYmaj5AAAAYUlEQVR4nO2NMQ6AIBAEVyCx1JKSh/g249N8loVRWkdzF2vCVkxml5PaS3m8g2a4DJdAAc0JTjuogHBiPOASCCfiDacNZDWl4bWzSBKb/3cr3OU0F+fP09lly32aPT3NpQJReQrNLNp22AAAAABJRU5ErkJggg==', 'geometry': None}, 'embedding': None, 'is_instance': False, 'implied_task_types': ['semantic-segmentation']}]}\n",
            "{'datum': {'uid': 'img2', 'metadata': {'path': 'a/b/c/img2.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': 0.1}, {'key': 'class_label', 'value': 'cat', 'score': 0.9}], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None, 'is_instance': None, 'implied_task_types': ['classification']}]}\n",
            "{'datum': {'uid': 'img1', 'metadata': {'path': 'a/b/c/img1.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': 0.9}, {'key': 'class_label', 'value': 'cat', 'score': 0.1}], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None, 'is_instance': None, 'implied_task_types': ['classification']}]}\n",
            "{'datum': {'uid': 'img5', 'metadata': {'path': 'a/b/c/img5.png'}}, 'annotations': [{'metadata': {}, 'labels': [], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None, 'is_instance': None, 'implied_task_types': ['empty']}]}\n",
            "{'datum': {'uid': 'img4', 'metadata': {'path': 'a/b/c/img4.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': 0.8}, {'key': 'class_label', 'value': 'person', 'score': 0.1}, {'key': 'class_label', 'value': 'cat', 'score': 0.1}], 'bounding_box': [[(500.0, 220.0), (530.0, 220.0), (530.0, 260.0), (500.0, 260.0), (500.0, 220.0)]], 'polygon': None, 'raster': None, 'embedding': None, 'is_instance': True, 'implied_task_types': ['object-detection']}]}\n",
            "{'datum': {'uid': 'img3', 'metadata': {'path': 'a/b/c/img3.png'}}, 'annotations': [{'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': 0.8}, {'key': 'class_label', 'value': 'person', 'score': 0.1}, {'key': 'class_label', 'value': 'cat', 'score': 0.1}], 'bounding_box': [[(16.0, 130.0), (70.0, 130.0), (70.0, 150.0), (16.0, 150.0), (16.0, 130.0)]], 'polygon': None, 'raster': None, 'embedding': None, 'is_instance': True, 'implied_task_types': ['object-detection']}, {'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': 0.05}, {'key': 'class_label', 'value': 'person', 'score': 0.9}, {'key': 'class_label', 'value': 'cat', 'score': 0.05}], 'bounding_box': [[(89.0, 10.0), (97.0, 10.0), (97.0, 110.0), (89.0, 110.0), (89.0, 10.0)]], 'polygon': None, 'raster': None, 'embedding': None, 'is_instance': True, 'implied_task_types': ['object-detection']}]}\n"
          ]
        }
      ],
      "source": [
        "for datum in dataset.get_datums():\n",
        "    print(model.get_prediction(dataset, datum))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'key': 'class_label', 'value': 'car', 'score': None}\n",
            "{'key': 'label', 'value': 'positive', 'score': None}\n",
            "{'key': 'class_label', 'value': 'cat', 'score': None}\n",
            "{'key': 'class_label', 'value': 'person', 'score': None}\n",
            "{'key': 'label', 'value': 'negative', 'score': None}\n",
            "{'key': 'class_label', 'value': 'dog', 'score': None}\n"
          ]
        }
      ],
      "source": [
        "for label in model.get_labels():\n",
        "    print(label)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluating Performance\n",
        "\n",
        "Finally, we'll use our Valor abstractions to evaluate model performance. For more detailed, task-specific examples, see our follow-up notebooks at the links below:\n",
        "- [Tabular classification](https://github.com/Striveworks/valor/blob/main/examples/classification/tabular.ipynb)\n",
        "- [Object detection](https://github.com/Striveworks/valor/blob/main/examples/object-detection/coco-yolo.ipynb)\n",
        "- [Semantic segmentation](https://github.com/Striveworks/valor/blob/main/examples/semantic-segmentation/coco-yolo.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluating Detections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'type': 'AP',\n",
              "  'parameters': {'iou': 0.5},\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'person'}},\n",
              " {'type': 'AP',\n",
              "  'parameters': {'iou': 0.75},\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'person'}},\n",
              " {'type': 'AP',\n",
              "  'parameters': {'iou': 0.5},\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'dog'}},\n",
              " {'type': 'AP',\n",
              "  'parameters': {'iou': 0.75},\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'dog'}},\n",
              " {'type': 'AP',\n",
              "  'parameters': {'iou': 0.5},\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'cat'}},\n",
              " {'type': 'AP',\n",
              "  'parameters': {'iou': 0.75},\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'cat'}},\n",
              " {'type': 'AR',\n",
              "  'parameters': {'ious': [0.5,\n",
              "    0.55,\n",
              "    0.6,\n",
              "    0.65,\n",
              "    0.7,\n",
              "    0.75,\n",
              "    0.8,\n",
              "    0.85,\n",
              "    0.9,\n",
              "    0.95]},\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'person'}},\n",
              " {'type': 'AR',\n",
              "  'parameters': {'ious': [0.5,\n",
              "    0.55,\n",
              "    0.6,\n",
              "    0.65,\n",
              "    0.7,\n",
              "    0.75,\n",
              "    0.8,\n",
              "    0.85,\n",
              "    0.9,\n",
              "    0.95]},\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'dog'}},\n",
              " {'type': 'AR',\n",
              "  'parameters': {'ious': [0.5,\n",
              "    0.55,\n",
              "    0.6,\n",
              "    0.65,\n",
              "    0.7,\n",
              "    0.75,\n",
              "    0.8,\n",
              "    0.85,\n",
              "    0.9,\n",
              "    0.95]},\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'cat'}},\n",
              " {'type': 'mAP',\n",
              "  'parameters': {'iou': 0.5, 'label_key': 'class_label'},\n",
              "  'value': 1.0},\n",
              " {'type': 'mAP',\n",
              "  'parameters': {'iou': 0.75, 'label_key': 'class_label'},\n",
              "  'value': 1.0},\n",
              " {'type': 'mAR',\n",
              "  'parameters': {'ious': [0.5,\n",
              "    0.55,\n",
              "    0.6,\n",
              "    0.7,\n",
              "    0.65,\n",
              "    0.75,\n",
              "    0.8,\n",
              "    0.85,\n",
              "    0.9,\n",
              "    0.95],\n",
              "   'label_key': 'class_label'},\n",
              "  'value': 1.0},\n",
              " {'type': 'APAveragedOverIOUs',\n",
              "  'parameters': {'ious': [0.5,\n",
              "    0.55,\n",
              "    0.6,\n",
              "    0.65,\n",
              "    0.7,\n",
              "    0.75,\n",
              "    0.8,\n",
              "    0.85,\n",
              "    0.9,\n",
              "    0.95]},\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'person'}},\n",
              " {'type': 'APAveragedOverIOUs',\n",
              "  'parameters': {'ious': [0.5,\n",
              "    0.55,\n",
              "    0.6,\n",
              "    0.65,\n",
              "    0.7,\n",
              "    0.75,\n",
              "    0.8,\n",
              "    0.85,\n",
              "    0.9,\n",
              "    0.95]},\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'dog'}},\n",
              " {'type': 'APAveragedOverIOUs',\n",
              "  'parameters': {'ious': [0.5,\n",
              "    0.55,\n",
              "    0.6,\n",
              "    0.65,\n",
              "    0.7,\n",
              "    0.75,\n",
              "    0.8,\n",
              "    0.85,\n",
              "    0.9,\n",
              "    0.95]},\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'cat'}},\n",
              " {'type': 'mAPAveragedOverIOUs',\n",
              "  'parameters': {'ious': [0.5,\n",
              "    0.55,\n",
              "    0.6,\n",
              "    0.7,\n",
              "    0.65,\n",
              "    0.75,\n",
              "    0.8,\n",
              "    0.85,\n",
              "    0.9,\n",
              "    0.95],\n",
              "   'label_key': 'class_label'},\n",
              "  'value': 1.0}]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_objdet = model.evaluate_detection(dataset)\n",
        "eval_objdet.wait_for_completion()\n",
        "eval_objdet.metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluating Classifications\n",
        "\n",
        "Note that running the code below evaluates both our text classifications as well as our image classifications. If we only wanted to evaluate one type of classification task, we could use `evaluation_classification`'s `filters` argument to specify which type of labels to evaluate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'type': 'Accuracy',\n",
              "  'parameters': {'label_key': 'class_label'},\n",
              "  'value': 1.0},\n",
              " {'type': 'ROCAUC', 'parameters': {'label_key': 'class_label'}, 'value': 1.0},\n",
              " {'type': 'Precision',\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'dog'}},\n",
              " {'type': 'Recall',\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'dog'}},\n",
              " {'type': 'F1', 'value': 1.0, 'label': {'key': 'class_label', 'value': 'dog'}},\n",
              " {'type': 'Precision',\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'cat'}},\n",
              " {'type': 'Recall',\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'cat'}},\n",
              " {'type': 'F1', 'value': 1.0, 'label': {'key': 'class_label', 'value': 'cat'}},\n",
              " {'type': 'Accuracy', 'parameters': {'label_key': 'label'}, 'value': 1.0},\n",
              " {'type': 'ROCAUC', 'parameters': {'label_key': 'label'}, 'value': 1.0},\n",
              " {'type': 'Precision',\n",
              "  'value': -1.0,\n",
              "  'label': {'key': 'label', 'value': 'negative'}},\n",
              " {'type': 'Recall',\n",
              "  'value': -1.0,\n",
              "  'label': {'key': 'label', 'value': 'negative'}},\n",
              " {'type': 'F1', 'value': -1.0, 'label': {'key': 'label', 'value': 'negative'}},\n",
              " {'type': 'Precision',\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'label', 'value': 'positive'}},\n",
              " {'type': 'Recall',\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'label', 'value': 'positive'}},\n",
              " {'type': 'F1', 'value': 1.0, 'label': {'key': 'label', 'value': 'positive'}}]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_clf = model.evaluate_classification(dataset)\n",
        "eval_clf.wait_for_completion()\n",
        "eval_clf.metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this second example, we can use `filter_by` to only evaluate image `Annotations` via the label key `class_name`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'type': 'Accuracy',\n",
              "  'parameters': {'label_key': 'class_label'},\n",
              "  'value': 1.0},\n",
              " {'type': 'ROCAUC', 'parameters': {'label_key': 'class_label'}, 'value': 1.0},\n",
              " {'type': 'Precision',\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'dog'}},\n",
              " {'type': 'Recall',\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'dog'}},\n",
              " {'type': 'F1', 'value': 1.0, 'label': {'key': 'class_label', 'value': 'dog'}},\n",
              " {'type': 'Precision',\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'cat'}},\n",
              " {'type': 'Recall',\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'cat'}},\n",
              " {'type': 'F1', 'value': 1.0, 'label': {'key': 'class_label', 'value': 'cat'}}]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_clf = model.evaluate_classification(dataset, filters=Filter(labels=(Label.key == 'class_label')))\n",
        "eval_clf.wait_for_completion()\n",
        "eval_clf.metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluating Segmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'type': 'IOU',\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'car'}},\n",
              " {'type': 'IOU',\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'dog'}},\n",
              " {'type': 'IOU',\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'cat'}},\n",
              " {'type': 'mIOU', 'parameters': {'label_key': 'class_label'}, 'value': 1.0}]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_semseg = model.evaluate_segmentation(dataset)\n",
        "eval_semseg.wait_for_completion()\n",
        "eval_semseg.metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "For more examples, we'd recommend reviewing our [other sample notebooks on GitHub](https://github.com/Striveworks/valor/blob/main/examples/). For more detailed explanations of Valor's technical underpinnings, see our [technical concepts guide](technical_concepts.md)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".env-valor",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
