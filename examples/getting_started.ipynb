{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Getting Started with Valor\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Valor is a centralized evaluation store which makes it easy to measure, explore, and rank model performance. Valor empowers data scientists and engineers to evaluate the performance of their machine learning pipelines and use those evaluations to make better modeling decisions in the future. For a conceptual introduction to Valor, [check out our project overview](https://striveworks.github.io/valor/).\n",
        "\n",
        "In this notebook, we'll introduce Valor's high-level abstractions and walk through a computer vision-oriented example of how you can use Valor to evaluate model performance. For task-specific examples, please see our follow-up notebooks below:\n",
        "- [Tabular classification](https://github.com/Striveworks/valor/blob/main/examples/classification/tabular.ipynb)\n",
        "- [Object detection](https://github.com/Striveworks/valor/blob/main/examples/object-detection/coco-yolo.ipynb)\n",
        "- [Semantic segmentation](https://github.com/Striveworks/valor/blob/main/examples/semantic-segmentation/coco-yolo.ipynb)\n",
        "\n",
        "Before using this notebook, please ensure that the Valor service is running on your machine (for start-up instructions, [click here](https://striveworks.github.io/valor/getting_started/)). To connect to a non-local instance of Valor, update `client = Client(\"http://0.0.0.0:8000\")` in the first code block to point to the correct URL."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## High-Level Workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Valor is equipped to handle a wide variety of supervised learning tasks thanks to its six core abstractions. We can think of these abstractions as being split into two categories:\n",
        "- **Dataset**: When describing our actual dataset, we define a `Dataset` containing a list of `GroundTruths` which, in turn, are made up of `Datums` and `Annotations`.\n",
        "- **Model**: When describing our model outputs, we define a `Model` containing a list of `Predictions` which, in turn, are also made up of `Datums` and `Annotations`. We then link our `Model` to a `Dataset` when finalizing the model.\n",
        "\n",
        "After we define both our dataset inputs and model outputs, Valor will make it easy to calculate and store our evaluation metrics. Let's start by describing our dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining Our Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To begin, we import all needed packages and connect to our Valor API. For instructions on setting up your API, please see [our docs here](https://striveworks.github.io/valor/getting_started/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The Valor client isn't versioned.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully connected to host at http://0.0.0.0:8000/\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "from valor import (\n",
        "    connect,\n",
        "    Client,\n",
        "    Dataset,\n",
        "    Model,\n",
        "    Datum,\n",
        "    Annotation,\n",
        "    GroundTruth, \n",
        "    Prediction,\n",
        "    Label,\n",
        ")\n",
        "from valor.schemas import (\n",
        "    Box, \n",
        "    Polygon,\n",
        "    Raster,\n",
        ")\n",
        "from valor.enums import TaskType\n",
        "\n",
        "# connect to the Valor API\n",
        "connect(\"http://0.0.0.0:8000\")\n",
        "client = Client()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we define our `Dataset` in Valor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = Dataset.create(  \n",
        "    name=\"myDataset\",\n",
        "    metadata={        # optional, metadata can take `str`, `int`, `float` value types.\n",
        "        \"some_string\": \"hello_world\",\n",
        "        \"some_number\": 1234,\n",
        "        \"a_different_number\": 1.234,\n",
        "    },\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To describe the various objects in our `Dataset`, we'll associate a list of `GroundTruths` (made up of `Annotations` and `Datums`) to the `Dataset` we defined above. Note that Valor doesn't actually store any images, and that the `Annotations` we use will vary by our task type (i.e., object detection, semantic segmentation, etc.). For demonstrative purposes, we'll create `GroundTruths` for four different learning tasks in this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Object Detection GroundTruths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'datum': {'uid': 'img3', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img3.png'}}}, 'annotations': [{'task_type': 'object-detection', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': None}], 'bounding_box': [[(16, 130), (70, 130), (70, 150), (16, 150), (16, 130)]], 'polygon': None, 'raster': None, 'embedding': None}, {'task_type': 'object-detection', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'person', 'score': None}], 'bounding_box': [[(89, 10), (97, 10), (97, 110), (89, 110), (89, 10)]], 'polygon': None, 'raster': None, 'embedding': None}]}\n",
            "{'datum': {'uid': 'img4', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img4.png'}}}, 'annotations': [{'task_type': 'object-detection', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'cat', 'score': None}], 'bounding_box': [[(500, 220), (530, 220), (530, 260), (500, 260), (500, 220)]], 'polygon': None, 'raster': None, 'embedding': None}]}\n",
            "{'datum': {'uid': 'img5', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img5.png'}}}, 'annotations': []}\n"
          ]
        }
      ],
      "source": [
        "def create_groundtruth_from_object_detection_dict(element: dict):\n",
        "    \n",
        "    # create Datum using filename, save the full filepath into metadata\n",
        "    datum = Datum(\n",
        "        uid=Path(element[\"path\"]).stem,\n",
        "        metadata={\n",
        "            \"path\": element[\"path\"] \n",
        "        }\n",
        "    )\n",
        "\n",
        "    # create Annotations\n",
        "    annotations = [\n",
        "        Annotation(\n",
        "            task_type=TaskType.OBJECT_DETECTION,\n",
        "            labels=[Label(key=\"class_label\", value=annotation[\"class_label\"])],\n",
        "            bounding_box=Box.from_extrema(\n",
        "                xmin=annotation[\"bbox\"][\"xmin\"],\n",
        "                xmax=annotation[\"bbox\"][\"xmax\"],\n",
        "                ymin=annotation[\"bbox\"][\"ymin\"],\n",
        "                ymax=annotation[\"bbox\"][\"ymax\"],\n",
        "            )\n",
        "        )\n",
        "        for annotation in element[\"annotations\"]\n",
        "        if len(annotation) > 0\n",
        "    ]\n",
        "\n",
        "    # create and return GroundTruth\n",
        "    return GroundTruth(\n",
        "        datum=datum,\n",
        "        annotations=annotations,\n",
        "    )\n",
        "\n",
        "image_object_detections = [\n",
        "    {\"path\": \"a/b/c/img3.png\", \"annotations\": [{\"class_label\": \"dog\", \"bbox\": {\"xmin\": 16, \"ymin\": 130, \"xmax\": 70, \"ymax\": 150}}, {\"class_label\": \"person\", \"bbox\": {\"xmin\": 89, \"ymin\": 10, \"xmax\": 97, \"ymax\": 110}}]},\n",
        "    {\"path\": \"a/b/c/img4.png\", \"annotations\": [{\"class_label\": \"cat\", \"bbox\": {\"xmin\": 500, \"ymin\": 220, \"xmax\": 530, \"ymax\": 260}}]},\n",
        "    {\"path\": \"a/b/c/img5.png\", \"annotations\": []}\n",
        "]\n",
        "\n",
        "\n",
        "for element in image_object_detections:\n",
        "    # create ground truth\n",
        "    groundtruth = create_groundtruth_from_object_detection_dict(element)\n",
        "\n",
        "    # add ground truth to dataset\n",
        "    dataset.add_groundtruth(groundtruth)\n",
        "    \n",
        "    print(groundtruth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Image Classification GroundTruths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'datum': {'uid': 'img1', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img1.png'}}}, 'annotations': [{'task_type': 'classification', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None}]}\n",
            "{'datum': {'uid': 'img2', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img2.png'}}}, 'annotations': [{'task_type': 'classification', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'cat', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None}]}\n"
          ]
        }
      ],
      "source": [
        "def create_groundtruth_from_image_classification_dict(element: dict):\n",
        "    \n",
        "    # create Datum using filename, save the full filepath into metadata\n",
        "    datum = Datum(\n",
        "        uid=Path(element[\"path\"]).stem,\n",
        "        metadata={\n",
        "            \"path\": element[\"path\"]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # create Annotation\n",
        "    annotations = [\n",
        "        Annotation(\n",
        "            task_type=TaskType.CLASSIFICATION,\n",
        "            labels=[\n",
        "                Label(key=key, value=value)\n",
        "                for label in element[\"annotations\"]\n",
        "                for key, value in label.items()\n",
        "            ]\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # create and return GroundTruth\n",
        "    return GroundTruth(\n",
        "        datum=datum,\n",
        "        annotations=annotations,\n",
        "    )\n",
        "\n",
        "image_classifications = [\n",
        "    {\"path\": \"a/b/c/img1.png\", \"annotations\": [{\"class_label\": \"dog\"}]},\n",
        "    {\"path\": \"a/b/c/img2.png\", \"annotations\": [{\"class_label\": \"cat\"}]}\n",
        "]\n",
        "\n",
        "for element in image_classifications:\n",
        "    # create ground truth\n",
        "    groundtruth = create_groundtruth_from_image_classification_dict(element)\n",
        "\n",
        "    # add ground truth to dataset\n",
        "    dataset.add_groundtruth(groundtruth)\n",
        "    \n",
        "    print(groundtruth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Image Segmentation GroundTruths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'datum': {'uid': 'img6', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img6.png'}}}, 'annotations': [{'task_type': 'semantic-segmentation', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': {'mask': 'iVBORw0KGgoAAAANSUhEUgAAAGQAAABkAQAAAABYmaj5AAAAFElEQVR4nGNgGAWjYBSMglFATwAABXgAAQj9RYMAAAAASUVORK5CYII=', 'geometry': [[(10, 15), (20, 50), (25, 28), (10, 15)]]}, 'embedding': None}]}\n",
            "{'datum': {'uid': 'img7', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img7.png'}}}, 'annotations': [{'task_type': 'semantic-segmentation', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'cat', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': {'mask': 'iVBORw0KGgoAAAANSUhEUgAAAGQAAABkAQAAAABYmaj5AAAAFElEQVR4nGNgGAWjYBSMglFATwAABXgAAQj9RYMAAAAASUVORK5CYII=', 'geometry': [[(97, 40), (33, 44), (10, 18), (97, 40)]]}, 'embedding': None}]}\n",
            "{'datum': {'uid': 'img8', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img8.png'}}}, 'annotations': [{'task_type': 'semantic-segmentation', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'car', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': {'mask': 'iVBORw0KGgoAAAANSUhEUgAAAGQAAABkAQAAAABYmaj5AAAAFElEQVR4nGNgGAWjYBSMglFATwAABXgAAQj9RYMAAAAASUVORK5CYII=', 'geometry': [[(10, 15), (20, 50), (25, 28), (10, 15)], [(60, 15), (70, 50), (75, 28), (60, 15)]]}, 'embedding': None}]}\n"
          ]
        }
      ],
      "source": [
        "def create_groundtruth_from_image_segmentation_dict(element: dict):\n",
        "    \n",
        "    # create Datum using filename, save the full filepath into metadata\n",
        "    datum = Datum(\n",
        "        uid=Path(element[\"path\"]).stem,\n",
        "        metadata={\n",
        "            \"path\": element[\"path\"] \n",
        "        }\n",
        "    )\n",
        "\n",
        "    # create Annotations\n",
        "    annotations = [\n",
        "        Annotation(\n",
        "            task_type=TaskType.SEMANTIC_SEGMENTATION,\n",
        "            labels=[Label(key=\"class_label\", value=annotation[\"class_label\"])],\n",
        "            raster=Raster.from_geometry(\n",
        "                geometry=Polygon(\n",
        "                    [\n",
        "                        [\n",
        "                            (pt['x'], pt['y'])\n",
        "                            for pt in [*subpolygon, subpolygon[0]]\n",
        "                        ]\n",
        "                        for subpolygon in annotation[\"contour\"]\n",
        "                    ]\n",
        "                ),\n",
        "                height=100,\n",
        "                width=100,\n",
        "            )\n",
        "        )\n",
        "        for annotation in element[\"annotations\"]\n",
        "        if len(annotation[\"contour\"]) > 0\n",
        "    ]\n",
        "\n",
        "    # create and return GroundTruth\n",
        "    return GroundTruth(\n",
        "        datum=datum,\n",
        "        annotations=annotations,\n",
        "    )\n",
        "\n",
        "image_segmentations = [\n",
        "    {\"path\": \"a/b/c/img6.png\", \"annotations\": [{\"class_label\": \"dog\", \"contour\": [[{\"x\": 10, \"y\": 15}, {\"x\": 20, \"y\": 50}, {\"x\": 25, \"y\": 28}]]}]},\n",
        "    {\"path\": \"a/b/c/img7.png\", \"annotations\": [{\"class_label\": \"cat\", \"contour\": [[{\"x\": 97, \"y\": 40}, {\"x\": 33, \"y\": 44}, {\"x\": 10, \"y\": 18}]]}]},\n",
        "    {\"path\": \"a/b/c/img8.png\", \"annotations\": [{\"class_label\": \"car\", \"contour\": [[{\"x\": 10, \"y\": 15}, {\"x\": 20, \"y\": 50}, {\"x\": 25, \"y\": 28}], [{\"x\": 60, \"y\": 15}, {\"x\": 70, \"y\": 50}, {\"x\": 75, \"y\": 28}]]}]}\n",
        "]\n",
        "\n",
        "for element in image_segmentations:\n",
        "    # create ground truth\n",
        "    groundtruth = create_groundtruth_from_image_segmentation_dict(element)\n",
        "\n",
        "    # add ground truth to dataset\n",
        "    dataset.add_groundtruth(groundtruth)\n",
        "    \n",
        "    print(groundtruth)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Text Classification GroundTruths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'datum': {'uid': 'text1', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/text1.txt'}, 'context': {'type': 'string', 'value': 'Is the content of this product review postive?'}}}, 'annotations': [{'task_type': 'classification', 'metadata': {}, 'labels': [{'key': 'label', 'value': 'positive', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None}]}\n"
          ]
        }
      ],
      "source": [
        "def create_groundtruth_from_text_classification_dict(element: dict):\n",
        "    \n",
        "    # create Datum using filename, save the full filepath into metadata\n",
        "    datum = Datum(\n",
        "        uid=Path(element[\"path\"]).stem,\n",
        "        metadata={\n",
        "            \"path\": element[\"path\"],\n",
        "            \"context\": element[\"annotations\"][0][\"sentiment\"][\"context\"]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # create Annotation\n",
        "    annotations = [\n",
        "        Annotation(\n",
        "            task_type=TaskType.CLASSIFICATION,\n",
        "            labels=[\n",
        "                Label(\n",
        "                    key=\"label\", \n",
        "                    value=element[\"annotations\"][0][\"sentiment\"][\"label\"]\n",
        "                )\n",
        "            ]\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # create and return GroundTruth\n",
        "    return GroundTruth(\n",
        "        datum=datum,\n",
        "        annotations=annotations,\n",
        "    )\n",
        "\n",
        "text_classifications = [\n",
        "    {\"path\": \"a/b/c/text1.txt\", \"annotations\": [{\"sentiment\": {\"context\": \"Is the content of this product review postive?\", \"label\": \"positive\"}}]}\n",
        "]\n",
        "\n",
        "for element in text_classifications:\n",
        "    # create ground truth\n",
        "    groundtruth = create_groundtruth_from_text_classification_dict(element)\n",
        "\n",
        "    # add ground truth to dataset\n",
        "    dataset.add_groundtruth(groundtruth)\n",
        "    \n",
        "    print(groundtruth)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Finalizing Our Dataset\n",
        "\n",
        "Now that we've created all of our `GroundTruth` objects, we finalize our `Dataset` such that it's ready for evaluation. Valor makes finalization a requirement for traceability purposes: we want you to feel confident that a finalized `Dataset` or `Model` won't change over any length of time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.finalize()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining Our Model\n",
        "\n",
        "Now that we've described our dataset, the next step is to define our model and subsequent predictions. Again, for demonstrative purposes, we'll define predictions for four separate task types in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Model.create(\n",
        "    name=\"myModel\",\n",
        "    metadata={\n",
        "        \"foo\": \"bar\",\n",
        "        \"some_number\": 4321,\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Object Detection Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'datum': {'uid': 'img3', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img3.png'}}}, 'annotations': [{'task_type': 'object-detection', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': 0.8}, {'key': 'class_label', 'value': 'cat', 'score': 0.1}, {'key': 'class_label', 'value': 'person', 'score': 0.1}], 'bounding_box': [[(16, 130), (70, 130), (70, 150), (16, 150), (16, 130)]], 'polygon': None, 'raster': None, 'embedding': None}, {'task_type': 'object-detection', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': 0.05}, {'key': 'class_label', 'value': 'cat', 'score': 0.05}, {'key': 'class_label', 'value': 'person', 'score': 0.9}], 'bounding_box': [[(89, 10), (97, 10), (97, 110), (89, 110), (89, 10)]], 'polygon': None, 'raster': None, 'embedding': None}]}\n",
            "{'datum': {'uid': 'img4', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img4.png'}}}, 'annotations': [{'task_type': 'object-detection', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': 0.8}, {'key': 'class_label', 'value': 'cat', 'score': 0.1}, {'key': 'class_label', 'value': 'person', 'score': 0.1}], 'bounding_box': [[(500, 220), (530, 220), (530, 260), (500, 260), (500, 220)]], 'polygon': None, 'raster': None, 'embedding': None}]}\n",
            "{'datum': {'uid': 'img5', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img5.png'}}}, 'annotations': []}\n"
          ]
        }
      ],
      "source": [
        "# populate a dictionary mapping Datum UIDs to datums for all of the datums in our dataset\n",
        "datums_by_uid = {\n",
        "    datum.uid: datum\n",
        "    for datum in dataset.get_datums()\n",
        "}\n",
        "\n",
        "def create_prediction_from_object_detection_dict(element: dict, datums_by_uid:dict) -> Prediction:\n",
        "    \n",
        "    # get datum from dataset using filename\n",
        "    uid=Path(element[\"path\"]).stem\n",
        "    datum = datums_by_uid[uid]\n",
        "\n",
        "    # create Annotations\n",
        "    annotations = [\n",
        "        Annotation(\n",
        "            task_type=TaskType.OBJECT_DETECTION,\n",
        "            labels=[\n",
        "                Label(key=\"class_label\", value=label[\"class_label\"], score=label[\"score\"])\n",
        "                for label in annotation[\"labels\"]\n",
        "            ],\n",
        "            bounding_box=Box.from_extrema(\n",
        "                xmin=annotation[\"bbox\"][\"xmin\"],\n",
        "                xmax=annotation[\"bbox\"][\"xmax\"],\n",
        "                ymin=annotation[\"bbox\"][\"ymin\"],\n",
        "                ymax=annotation[\"bbox\"][\"ymax\"],\n",
        "            )\n",
        "        )\n",
        "        for annotation in element[\"annotations\"]\n",
        "        if len(annotation) > 0\n",
        "    ]\n",
        "\n",
        "    # create and return Prediction\n",
        "    return Prediction(\n",
        "        datum=datum,\n",
        "        annotations=annotations,\n",
        "    )\n",
        "\n",
        "object_detections = [\n",
        "    {\"path\": \"a/b/c/img3.png\", \"annotations\": [\n",
        "        {\"labels\": [{\"class_label\": \"dog\", \"score\": 0.8}, {\"class_label\": \"cat\", \"score\": 0.1}, {\"class_label\": \"person\", \"score\": 0.1}], \"bbox\": {\"xmin\": 16, \"ymin\": 130, \"xmax\": 70, \"ymax\": 150}}, \n",
        "        {\"labels\": [{\"class_label\": \"dog\", \"score\": 0.05}, {\"class_label\": \"cat\", \"score\": 0.05}, {\"class_label\": \"person\", \"score\": 0.9}], \"bbox\": {\"xmin\": 89, \"ymin\": 10, \"xmax\": 97, \"ymax\": 110}}\n",
        "    ]},\n",
        "    {\"path\": \"a/b/c/img4.png\", \"annotations\": [\n",
        "        {\"labels\": [{\"class_label\": \"dog\", \"score\": 0.8}, {\"class_label\": \"cat\", \"score\": 0.1}, {\"class_label\": \"person\", \"score\": 0.1}], \"bbox\": {\"xmin\": 500, \"ymin\": 220, \"xmax\": 530, \"ymax\": 260}}\n",
        "    ]},\n",
        "    {\"path\": \"a/b/c/img5.png\", \"annotations\": []}\n",
        "]\n",
        "\n",
        "for element in object_detections:\n",
        "    # create prediction\n",
        "    prediction = create_prediction_from_object_detection_dict(element, datums_by_uid=datums_by_uid)\n",
        "\n",
        "    # add prediction to model\n",
        "    model.add_prediction(dataset, prediction)\n",
        "    \n",
        "    print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Image Classification Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'datum': {'uid': 'img1', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img1.png'}}}, 'annotations': [{'task_type': 'classification', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': 0.9}, {'key': 'class_label', 'value': 'cat', 'score': 0.1}], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None}]}\n",
            "{'datum': {'uid': 'img2', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img2.png'}}}, 'annotations': [{'task_type': 'classification', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': 0.1}, {'key': 'class_label', 'value': 'cat', 'score': 0.9}], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None}]}\n"
          ]
        }
      ],
      "source": [
        "def create_prediction_from_image_classification_dict(element: dict, datums_by_uid:dict) -> Prediction:\n",
        "    \n",
        "    # get datum from dataset using filename\n",
        "    uid=Path(element[\"path\"]).stem\n",
        "    datum = datums_by_uid[uid]\n",
        "\n",
        "    # create Annotation\n",
        "    annotations = [\n",
        "        Annotation(\n",
        "            task_type=TaskType.CLASSIFICATION,\n",
        "            labels=[\n",
        "                Label(key=\"class_label\", value=label[\"class_label\"], score=label[\"score\"])\n",
        "                for label in element[\"annotations\"]\n",
        "            ]\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # create and return Prediction\n",
        "    return Prediction(\n",
        "        datum=datum,\n",
        "        annotations=annotations,\n",
        "    )\n",
        "\n",
        "image_classifications = [\n",
        "    {\"path\": \"a/b/c/img1.png\", \"annotations\": [{\"class_label\": \"dog\", \"score\": 0.9}, {\"class_label\": \"cat\", \"score\": 0.1}]},\n",
        "    {\"path\": \"a/b/c/img2.png\", \"annotations\": [{\"class_label\": \"dog\", \"score\": 0.1}, {\"class_label\": \"cat\", \"score\": 0.9}]}\n",
        "]\n",
        "\n",
        "for element in image_classifications:\n",
        "    # create prediction\n",
        "    prediction = create_prediction_from_image_classification_dict(element, datums_by_uid=datums_by_uid)\n",
        "\n",
        "    # add prediction to dataset\n",
        "    model.add_prediction(dataset, prediction)\n",
        "    \n",
        "    print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Image Segmentation Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'datum': {'uid': 'img6', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img6.png'}}}, 'annotations': [{'task_type': 'semantic-segmentation', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': {'mask': 'iVBORw0KGgoAAAANSUhEUgAAAGQAAABkAQAAAABYmaj5AAAAFElEQVR4nGNgGAWjYBSMglFATwAABXgAAQj9RYMAAAAASUVORK5CYII=', 'geometry': [[(10, 15), (20, 50), (25, 28), (10, 15)]]}, 'embedding': None}]}\n",
            "{'datum': {'uid': 'img7', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img7.png'}}}, 'annotations': [{'task_type': 'semantic-segmentation', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'cat', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': {'mask': 'iVBORw0KGgoAAAANSUhEUgAAAGQAAABkAQAAAABYmaj5AAAAFElEQVR4nGNgGAWjYBSMglFATwAABXgAAQj9RYMAAAAASUVORK5CYII=', 'geometry': [[(97, 40), (33, 44), (10, 18), (97, 40)]]}, 'embedding': None}]}\n",
            "{'datum': {'uid': 'img8', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img8.png'}}}, 'annotations': [{'task_type': 'semantic-segmentation', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'car', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': {'mask': 'iVBORw0KGgoAAAANSUhEUgAAAGQAAABkAQAAAABYmaj5AAAAFElEQVR4nGNgGAWjYBSMglFATwAABXgAAQj9RYMAAAAASUVORK5CYII=', 'geometry': [[(10, 15), (20, 50), (25, 28), (10, 15)], [(60, 15), (70, 50), (75, 28), (60, 15)]]}, 'embedding': None}]}\n"
          ]
        }
      ],
      "source": [
        "def create_prediction_from_image_segmentation_dict(element: dict, datums_by_uid: dict) -> Prediction:\n",
        "    \n",
        "    # get datum from dataset using filename\n",
        "    uid=Path(element[\"path\"]).stem\n",
        "    datum = datums_by_uid[uid]\n",
        "\n",
        "\n",
        "    # create Annotations\n",
        "    annotations = [\n",
        "        Annotation(\n",
        "            task_type=TaskType.SEMANTIC_SEGMENTATION,\n",
        "            labels=[\n",
        "                Label(key=\"class_label\", value=annotation[\"class_label\"])\n",
        "            ],\n",
        "            raster=Raster.from_geometry(\n",
        "                geometry=Polygon(\n",
        "                    [\n",
        "                        [\n",
        "                            (pt['x'], pt['y'])\n",
        "                            for pt in [*subpolygon, subpolygon[0]]\n",
        "                        ]\n",
        "                        for subpolygon in annotation[\"contour\"]\n",
        "                    ]\n",
        "                ),\n",
        "                height=100,\n",
        "                width=100,\n",
        "            )\n",
        "        )\n",
        "        for annotation in element[\"annotations\"]\n",
        "        if len(annotation[\"contour\"]) > 0\n",
        "    ]\n",
        "\n",
        "    # create and return Prediction\n",
        "    return Prediction(\n",
        "        datum=datum,\n",
        "        annotations=annotations,\n",
        "    )\n",
        "\n",
        "image_segmentations = [\n",
        "    {\n",
        "        \"path\": \"a/b/c/img6.png\", \n",
        "        \"annotations\": [\n",
        "            {\n",
        "                \"class_label\": \"dog\",\n",
        "                \"contour\": [[{\"x\": 10, \"y\": 15}, {\"x\": 20, \"y\": 50}, {\"x\": 25, \"y\": 28}]]\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        \"path\": \"a/b/c/img7.png\", \n",
        "        \"annotations\": [\n",
        "            {\n",
        "                \"class_label\": \"cat\",\n",
        "                \"contour\": [[{\"x\": 97, \"y\": 40}, {\"x\": 33, \"y\": 44}, {\"x\": 10, \"y\": 18}]]\n",
        "            }\n",
        "        ]   \n",
        "    },\n",
        "    {\n",
        "        \"path\": \"a/b/c/img8.png\", \n",
        "        \"annotations\": [\n",
        "            {\n",
        "                \"class_label\": \"car\",\n",
        "                \"contour\": [[{\"x\": 10, \"y\": 15}, {\"x\": 20, \"y\": 50}, {\"x\": 25, \"y\": 28}], [{\"x\": 60, \"y\": 15}, {\"x\": 70, \"y\": 50}, {\"x\": 75, \"y\": 28}]]\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "for element in image_segmentations:\n",
        "    # create prediction\n",
        "    prediction = create_prediction_from_image_segmentation_dict(element, datums_by_uid=datums_by_uid)\n",
        "\n",
        "    # add prediction to model\n",
        "    model.add_prediction(dataset, prediction)\n",
        "    \n",
        "    print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Text Classification Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'datum': {'uid': 'text1', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/text1.txt'}, 'context': {'type': 'string', 'value': 'Is the content of this product review postive?'}}}, 'annotations': [{'task_type': 'classification', 'metadata': {}, 'labels': [{'key': 'label', 'value': 'positive', 'score': 0.8}, {'key': 'label', 'value': 'negative', 'score': 0.2}], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None}]}\n"
          ]
        }
      ],
      "source": [
        "def create_prediction_from_text_classification_dict(element: dict, datums_by_uid:dict) -> Prediction:\n",
        "    \n",
        "    # get datum from dataset using filename\n",
        "    uid=Path(element[\"path\"]).stem\n",
        "    datum = datums_by_uid[uid]\n",
        "\n",
        "    # create Annotation\n",
        "    annotations = [\n",
        "        Annotation(\n",
        "            task_type=TaskType.CLASSIFICATION,\n",
        "            labels=[\n",
        "                Label(\n",
        "                    key=\"label\", \n",
        "                    value=label[\"label\"],\n",
        "                    score=label[\"score\"],\n",
        "                )\n",
        "                for label in element[\"annotations\"][0][\"sentiment\"][\"labels\"]\n",
        "            ]\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # create and return Prediction\n",
        "    return Prediction(\n",
        "        datum=datum,\n",
        "        annotations=annotations,\n",
        "    )\n",
        "\n",
        "text_classifications = [\n",
        "    {\n",
        "        \"path\": \"a/b/c/text1.txt\",\n",
        "        \"annotations\": [\n",
        "            {\"sentiment\": \n",
        "                {\n",
        "                    \"context\": \"Is the content of this product review postive?\", \n",
        "                    \"labels\": [\n",
        "                        {\"label\": \"positive\", \"score\": 0.8},\n",
        "                        {\"label\": \"negative\", \"score\": 0.2}\n",
        "                    ]\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "for element in text_classifications:\n",
        "    # create prediction\n",
        "    prediction = create_prediction_from_text_classification_dict(element, datums_by_uid=datums_by_uid)\n",
        "\n",
        "    # add prediction to model\n",
        "    model.add_prediction(dataset, prediction)\n",
        "    \n",
        "    print(prediction)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Finalizing Our Model\n",
        "\n",
        "Now that we've created all of our `Prediction` objects, we finalize our `Model` such that it's ready for evaluation. When finalizing our `Model`, we pass in the `Dataset` object that we want to link it to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.finalize_inferences(dataset)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploring Our Objects\n",
        "\n",
        "Now that we've finalized our `Dataset` and `Model`, we can explore all of the objects stored in Valor before running our evaluations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Client Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'name': 'myDataset', 'metadata': {'some_number': {'type': 'integer', 'value': 1234}, 'some_string': {'type': 'string', 'value': 'hello_world'}, 'a_different_number': {'type': 'float', 'value': 1.234}}}]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.get_datasets()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'name': 'myModel', 'metadata': {'foo': {'type': 'string', 'value': 'bar'}, 'some_number': {'type': 'integer', 'value': 4321}}}]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.get_models()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'uid': 'img3', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img3.png'}}}\n",
            "{'uid': 'img4', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img4.png'}}}\n",
            "{'uid': 'img5', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img5.png'}}}\n",
            "{'uid': 'img1', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img1.png'}}}\n",
            "{'uid': 'img2', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img2.png'}}}\n",
            "{'uid': 'img6', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img6.png'}}}\n",
            "{'uid': 'img7', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img7.png'}}}\n",
            "{'uid': 'img8', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img8.png'}}}\n",
            "{'uid': 'text1', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/text1.txt'}, 'context': {'type': 'string', 'value': 'Is the content of this product review postive?'}}}\n"
          ]
        }
      ],
      "source": [
        "for datum in dataset.get_datums():\n",
        "    print(datum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"datum\": {\n",
            "    \"uid\": \"img3\",\n",
            "    \"metadata\": {\n",
            "      \"path\": {\n",
            "        \"type\": \"string\",\n",
            "        \"value\": \"a/b/c/img3.png\"\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  \"annotations\": [\n",
            "    {\n",
            "      \"task_type\": \"object-detection\",\n",
            "      \"metadata\": {},\n",
            "      \"labels\": [\n",
            "        {\n",
            "          \"key\": \"class_label\",\n",
            "          \"value\": \"dog\",\n",
            "          \"score\": null\n",
            "        }\n",
            "      ],\n",
            "      \"bounding_box\": [\n",
            "        [\n",
            "          [\n",
            "            16.0,\n",
            "            130.0\n",
            "          ],\n",
            "          [\n",
            "            70.0,\n",
            "            130.0\n",
            "          ],\n",
            "          [\n",
            "            70.0,\n",
            "            150.0\n",
            "          ],\n",
            "          [\n",
            "            16.0,\n",
            "            150.0\n",
            "          ],\n",
            "          [\n",
            "            16.0,\n",
            "            130.0\n",
            "          ]\n",
            "        ]\n",
            "      ],\n",
            "      \"polygon\": null,\n",
            "      \"raster\": null,\n",
            "      \"embedding\": null\n",
            "    },\n",
            "    {\n",
            "      \"task_type\": \"object-detection\",\n",
            "      \"metadata\": {},\n",
            "      \"labels\": [\n",
            "        {\n",
            "          \"key\": \"class_label\",\n",
            "          \"value\": \"person\",\n",
            "          \"score\": null\n",
            "        }\n",
            "      ],\n",
            "      \"bounding_box\": [\n",
            "        [\n",
            "          [\n",
            "            89.0,\n",
            "            10.0\n",
            "          ],\n",
            "          [\n",
            "            97.0,\n",
            "            10.0\n",
            "          ],\n",
            "          [\n",
            "            97.0,\n",
            "            110.0\n",
            "          ],\n",
            "          [\n",
            "            89.0,\n",
            "            110.0\n",
            "          ],\n",
            "          [\n",
            "            89.0,\n",
            "            10.0\n",
            "          ]\n",
            "        ]\n",
            "      ],\n",
            "      \"polygon\": null,\n",
            "      \"raster\": null,\n",
            "      \"embedding\": null\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "{'datum': {'uid': 'img3', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img3.png'}}}, 'annotations': [{'task_type': 'object-detection', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': None}], 'bounding_box': [[(16.0, 130.0), (70.0, 130.0), (70.0, 150.0), (16.0, 150.0), (16.0, 130.0)]], 'polygon': None, 'raster': None, 'embedding': None}, {'task_type': 'object-detection', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'person', 'score': None}], 'bounding_box': [[(89.0, 10.0), (97.0, 10.0), (97.0, 110.0), (89.0, 110.0), (89.0, 10.0)]], 'polygon': None, 'raster': None, 'embedding': None}]}\n",
            "{\n",
            "  \"datum\": {\n",
            "    \"uid\": \"img4\",\n",
            "    \"metadata\": {\n",
            "      \"path\": {\n",
            "        \"type\": \"string\",\n",
            "        \"value\": \"a/b/c/img4.png\"\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  \"annotations\": [\n",
            "    {\n",
            "      \"task_type\": \"object-detection\",\n",
            "      \"metadata\": {},\n",
            "      \"labels\": [\n",
            "        {\n",
            "          \"key\": \"class_label\",\n",
            "          \"value\": \"cat\",\n",
            "          \"score\": null\n",
            "        }\n",
            "      ],\n",
            "      \"bounding_box\": [\n",
            "        [\n",
            "          [\n",
            "            500.0,\n",
            "            220.0\n",
            "          ],\n",
            "          [\n",
            "            530.0,\n",
            "            220.0\n",
            "          ],\n",
            "          [\n",
            "            530.0,\n",
            "            260.0\n",
            "          ],\n",
            "          [\n",
            "            500.0,\n",
            "            260.0\n",
            "          ],\n",
            "          [\n",
            "            500.0,\n",
            "            220.0\n",
            "          ]\n",
            "        ]\n",
            "      ],\n",
            "      \"polygon\": null,\n",
            "      \"raster\": null,\n",
            "      \"embedding\": null\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "{'datum': {'uid': 'img4', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img4.png'}}}, 'annotations': [{'task_type': 'object-detection', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'cat', 'score': None}], 'bounding_box': [[(500.0, 220.0), (530.0, 220.0), (530.0, 260.0), (500.0, 260.0), (500.0, 220.0)]], 'polygon': None, 'raster': None, 'embedding': None}]}\n",
            "{\n",
            "  \"datum\": {\n",
            "    \"uid\": \"img5\",\n",
            "    \"metadata\": {\n",
            "      \"path\": {\n",
            "        \"type\": \"string\",\n",
            "        \"value\": \"a/b/c/img5.png\"\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  \"annotations\": [\n",
            "    {\n",
            "      \"task_type\": \"empty\",\n",
            "      \"metadata\": {},\n",
            "      \"labels\": [],\n",
            "      \"bounding_box\": null,\n",
            "      \"polygon\": null,\n",
            "      \"raster\": null,\n",
            "      \"embedding\": null\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "{'datum': {'uid': 'img5', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img5.png'}}}, 'annotations': [{'task_type': 'empty', 'metadata': {}, 'labels': [], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None}]}\n",
            "{\n",
            "  \"datum\": {\n",
            "    \"uid\": \"img1\",\n",
            "    \"metadata\": {\n",
            "      \"path\": {\n",
            "        \"type\": \"string\",\n",
            "        \"value\": \"a/b/c/img1.png\"\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  \"annotations\": [\n",
            "    {\n",
            "      \"task_type\": \"classification\",\n",
            "      \"metadata\": {},\n",
            "      \"labels\": [\n",
            "        {\n",
            "          \"key\": \"class_label\",\n",
            "          \"value\": \"dog\",\n",
            "          \"score\": null\n",
            "        }\n",
            "      ],\n",
            "      \"bounding_box\": null,\n",
            "      \"polygon\": null,\n",
            "      \"raster\": null,\n",
            "      \"embedding\": null\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "{'datum': {'uid': 'img1', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img1.png'}}}, 'annotations': [{'task_type': 'classification', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None}]}\n",
            "{\n",
            "  \"datum\": {\n",
            "    \"uid\": \"img2\",\n",
            "    \"metadata\": {\n",
            "      \"path\": {\n",
            "        \"type\": \"string\",\n",
            "        \"value\": \"a/b/c/img2.png\"\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  \"annotations\": [\n",
            "    {\n",
            "      \"task_type\": \"classification\",\n",
            "      \"metadata\": {},\n",
            "      \"labels\": [\n",
            "        {\n",
            "          \"key\": \"class_label\",\n",
            "          \"value\": \"cat\",\n",
            "          \"score\": null\n",
            "        }\n",
            "      ],\n",
            "      \"bounding_box\": null,\n",
            "      \"polygon\": null,\n",
            "      \"raster\": null,\n",
            "      \"embedding\": null\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "{'datum': {'uid': 'img2', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img2.png'}}}, 'annotations': [{'task_type': 'classification', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'cat', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None}]}\n",
            "{\n",
            "  \"datum\": {\n",
            "    \"uid\": \"img6\",\n",
            "    \"metadata\": {\n",
            "      \"path\": {\n",
            "        \"type\": \"string\",\n",
            "        \"value\": \"a/b/c/img6.png\"\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  \"annotations\": [\n",
            "    {\n",
            "      \"task_type\": \"semantic-segmentation\",\n",
            "      \"metadata\": {},\n",
            "      \"labels\": [\n",
            "        {\n",
            "          \"key\": \"class_label\",\n",
            "          \"value\": \"dog\",\n",
            "          \"score\": null\n",
            "        }\n",
            "      ],\n",
            "      \"bounding_box\": null,\n",
            "      \"polygon\": null,\n",
            "      \"raster\": {\n",
            "        \"mask\": \"iVBORw0KGgoAAAANSUhEUgAAAGQAAABkAQAAAABYmaj5AAAAAnRSTlMAAHaTzTgAAABhSURBVHic7Y0xDoAgEARXILHUkpKH+Dbj03yWhVFaR3MXa8JWTGaXk9pLebyDZrgMl0ABzQlOO6iAcGI84BIIJ+INpw1kNaXhtbNIEpv/dyvc5TQX58/T2WXLfZo9Pc2lAlF5Cs0s2nbYAAAAAElFTkSuQmCC\",\n",
            "        \"geometry\": null\n",
            "      },\n",
            "      \"embedding\": null\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "{'datum': {'uid': 'img6', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img6.png'}}}, 'annotations': [{'task_type': 'semantic-segmentation', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': {'mask': 'iVBORw0KGgoAAAANSUhEUgAAAGQAAABkAQAAAABYmaj5AAAAYUlEQVR4nO2NMQ6AIBAEVyCx1JKSh/g249N8loVRWkdzF2vCVkxml5PaS3m8g2a4DJdAAc0JTjuogHBiPOASCCfiDacNZDWl4bWzSBKb/3cr3OU0F+fP09lly32aPT3NpQJReQrNLNp22AAAAABJRU5ErkJggg==', 'geometry': None}, 'embedding': None}]}\n",
            "{\n",
            "  \"datum\": {\n",
            "    \"uid\": \"img7\",\n",
            "    \"metadata\": {\n",
            "      \"path\": {\n",
            "        \"type\": \"string\",\n",
            "        \"value\": \"a/b/c/img7.png\"\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  \"annotations\": [\n",
            "    {\n",
            "      \"task_type\": \"semantic-segmentation\",\n",
            "      \"metadata\": {},\n",
            "      \"labels\": [\n",
            "        {\n",
            "          \"key\": \"class_label\",\n",
            "          \"value\": \"cat\",\n",
            "          \"score\": null\n",
            "        }\n",
            "      ],\n",
            "      \"bounding_box\": null,\n",
            "      \"polygon\": null,\n",
            "      \"raster\": {\n",
            "        \"mask\": \"iVBORw0KGgoAAAANSUhEUgAAAGQAAABkAQAAAABYmaj5AAAAAnRSTlMAAHaTzTgAAACCSURBVHic7Y+xEcJADAT3ReDQHUALdGgPlbkUd4BDAsZHgF4SNfAX3c2O7v7hn3Uv3nj+sPmoaVJNF1XYlNAQVLgkNNgS2ncl0069nCWdwV5A23M+oMFJwAYIQOYLa0CL6qunjbyEm+S1lg9xOKlDA97e8+i/l7T28uphKX5oaMj1AdERPWV/TA5oAAAAAElFTkSuQmCC\",\n",
            "        \"geometry\": null\n",
            "      },\n",
            "      \"embedding\": null\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "{'datum': {'uid': 'img7', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img7.png'}}}, 'annotations': [{'task_type': 'semantic-segmentation', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'cat', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': {'mask': 'iVBORw0KGgoAAAANSUhEUgAAAGQAAABkAQAAAABYmaj5AAAAgklEQVR4nO2PsRHCQAwE90Xg0B1AC3RoD5W5FHeAQwLGR4BeEjXwF93Nju7+4Z91L954/rD5qGlSTRdV2JTQEFS4JDTYEtp3JdNOvZwlncFeQNtzPqDBScAGCEDmC2tAi+qrp428hJvktZYPcTipQwPe3vPov5e09vLqYSl+aGjI9QHRET1lf0wOaAAAAABJRU5ErkJggg==', 'geometry': None}, 'embedding': None}]}\n",
            "{\n",
            "  \"datum\": {\n",
            "    \"uid\": \"img8\",\n",
            "    \"metadata\": {\n",
            "      \"path\": {\n",
            "        \"type\": \"string\",\n",
            "        \"value\": \"a/b/c/img8.png\"\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  \"annotations\": [\n",
            "    {\n",
            "      \"task_type\": \"semantic-segmentation\",\n",
            "      \"metadata\": {},\n",
            "      \"labels\": [\n",
            "        {\n",
            "          \"key\": \"class_label\",\n",
            "          \"value\": \"car\",\n",
            "          \"score\": null\n",
            "        }\n",
            "      ],\n",
            "      \"bounding_box\": null,\n",
            "      \"polygon\": null,\n",
            "      \"raster\": {\n",
            "        \"mask\": \"iVBORw0KGgoAAAANSUhEUgAAAGQAAABkAQAAAABYmaj5AAAAAnRSTlMAAHaTzTgAAACNSURBVHic7dGxDcIwFATQFwcBHZSUGYThGM2jMAIlBUoo/BXZiZQBolxj3b/zv5PN/jCAK0ju4BTaA5xDK9MuWCqWVzluoM/BMvSf4qwjkjbi8oVuDK2KSNqIfgJTLlpMB7NtRuscqyWtc8nKNTm0im7fiyrvYFXgspkn4rFWW36l9VrTfMRWlwMH9og/+rEWx4UlATAAAAAASUVORK5CYII=\",\n",
            "        \"geometry\": null\n",
            "      },\n",
            "      \"embedding\": null\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "{'datum': {'uid': 'img8', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img8.png'}}}, 'annotations': [{'task_type': 'semantic-segmentation', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'car', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': {'mask': 'iVBORw0KGgoAAAANSUhEUgAAAGQAAABkAQAAAABYmaj5AAAAjUlEQVR4nO3RsQ3CMBQE0BcHAR2UlBmE4RjNozACJQVKKPwV2YmUAaJcY92/87+Tzf4wgCtI7uAU2gOcQyvTLlgqllc5bqDPwTL0n+KsI5I24vKFbgytikjaiH4CUy5aTAezbUbrHKslrXPJyjU5tIpu34sq72BV4LKZJ+KxVlt+pfVa03zEVpcDB/aIP/qxFseFJQEwAAAAAElFTkSuQmCC', 'geometry': None}, 'embedding': None}]}\n",
            "{\n",
            "  \"datum\": {\n",
            "    \"uid\": \"text1\",\n",
            "    \"metadata\": {\n",
            "      \"path\": {\n",
            "        \"type\": \"string\",\n",
            "        \"value\": \"a/b/c/text1.txt\"\n",
            "      },\n",
            "      \"context\": {\n",
            "        \"type\": \"string\",\n",
            "        \"value\": \"Is the content of this product review postive?\"\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  \"annotations\": [\n",
            "    {\n",
            "      \"task_type\": \"classification\",\n",
            "      \"metadata\": {},\n",
            "      \"labels\": [\n",
            "        {\n",
            "          \"key\": \"label\",\n",
            "          \"value\": \"positive\",\n",
            "          \"score\": null\n",
            "        }\n",
            "      ],\n",
            "      \"bounding_box\": null,\n",
            "      \"polygon\": null,\n",
            "      \"raster\": null,\n",
            "      \"embedding\": null\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "{'datum': {'uid': 'text1', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/text1.txt'}, 'context': {'type': 'string', 'value': 'Is the content of this product review postive?'}}}, 'annotations': [{'task_type': 'classification', 'metadata': {}, 'labels': [{'key': 'label', 'value': 'positive', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None}]}\n"
          ]
        }
      ],
      "source": [
        "for datum in dataset.get_datums():\n",
        "    groundtruth = dataset.get_groundtruth(datum)\n",
        "    print(groundtruth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'key': 'class_label', 'value': 'dog', 'score': None}\n",
            "{'key': 'class_label', 'value': 'car', 'score': None}\n",
            "{'key': 'class_label', 'value': 'cat', 'score': None}\n",
            "{'key': 'label', 'value': 'positive', 'score': None}\n",
            "{'key': 'class_label', 'value': 'person', 'score': None}\n"
          ]
        }
      ],
      "source": [
        "for label in dataset.get_labels():\n",
        "    print(label)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'datum': {'uid': 'img3', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img3.png'}}}, 'annotations': [{'task_type': 'object-detection', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'person', 'score': 0.1}, {'key': 'class_label', 'value': 'dog', 'score': 0.8}, {'key': 'class_label', 'value': 'cat', 'score': 0.1}], 'bounding_box': [[(16.0, 130.0), (70.0, 130.0), (70.0, 150.0), (16.0, 150.0), (16.0, 130.0)]], 'polygon': None, 'raster': None, 'embedding': None}, {'task_type': 'object-detection', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'person', 'score': 0.9}, {'key': 'class_label', 'value': 'dog', 'score': 0.05}, {'key': 'class_label', 'value': 'cat', 'score': 0.05}], 'bounding_box': [[(89.0, 10.0), (97.0, 10.0), (97.0, 110.0), (89.0, 110.0), (89.0, 10.0)]], 'polygon': None, 'raster': None, 'embedding': None}]}\n",
            "{'datum': {'uid': 'img4', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img4.png'}}}, 'annotations': [{'task_type': 'object-detection', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'person', 'score': 0.1}, {'key': 'class_label', 'value': 'dog', 'score': 0.8}, {'key': 'class_label', 'value': 'cat', 'score': 0.1}], 'bounding_box': [[(500.0, 220.0), (530.0, 220.0), (530.0, 260.0), (500.0, 260.0), (500.0, 220.0)]], 'polygon': None, 'raster': None, 'embedding': None}]}\n",
            "{'datum': {'uid': 'img5', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img5.png'}}}, 'annotations': [{'task_type': 'empty', 'metadata': {}, 'labels': [], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None}]}\n",
            "{'datum': {'uid': 'img1', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img1.png'}}}, 'annotations': [{'task_type': 'classification', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': 0.9}, {'key': 'class_label', 'value': 'cat', 'score': 0.1}], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None}]}\n",
            "{'datum': {'uid': 'img2', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img2.png'}}}, 'annotations': [{'task_type': 'classification', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': 0.1}, {'key': 'class_label', 'value': 'cat', 'score': 0.9}], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None}]}\n",
            "{'datum': {'uid': 'img6', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img6.png'}}}, 'annotations': [{'task_type': 'semantic-segmentation', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'dog', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': {'mask': 'iVBORw0KGgoAAAANSUhEUgAAAGQAAABkAQAAAABYmaj5AAAAYUlEQVR4nO2NMQ6AIBAEVyCx1JKSh/g249N8loVRWkdzF2vCVkxml5PaS3m8g2a4DJdAAc0JTjuogHBiPOASCCfiDacNZDWl4bWzSBKb/3cr3OU0F+fP09lly32aPT3NpQJReQrNLNp22AAAAABJRU5ErkJggg==', 'geometry': None}, 'embedding': None}]}\n",
            "{'datum': {'uid': 'img7', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img7.png'}}}, 'annotations': [{'task_type': 'semantic-segmentation', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'cat', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': {'mask': 'iVBORw0KGgoAAAANSUhEUgAAAGQAAABkAQAAAABYmaj5AAAAgklEQVR4nO2PsRHCQAwE90Xg0B1AC3RoD5W5FHeAQwLGR4BeEjXwF93Nju7+4Z91L954/rD5qGlSTRdV2JTQEFS4JDTYEtp3JdNOvZwlncFeQNtzPqDBScAGCEDmC2tAi+qrp428hJvktZYPcTipQwPe3vPov5e09vLqYSl+aGjI9QHRET1lf0wOaAAAAABJRU5ErkJggg==', 'geometry': None}, 'embedding': None}]}\n",
            "{'datum': {'uid': 'img8', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/img8.png'}}}, 'annotations': [{'task_type': 'semantic-segmentation', 'metadata': {}, 'labels': [{'key': 'class_label', 'value': 'car', 'score': None}], 'bounding_box': None, 'polygon': None, 'raster': {'mask': 'iVBORw0KGgoAAAANSUhEUgAAAGQAAABkAQAAAABYmaj5AAAAjUlEQVR4nO3RsQ3CMBQE0BcHAR2UlBmE4RjNozACJQVKKPwV2YmUAaJcY92/87+Tzf4wgCtI7uAU2gOcQyvTLlgqllc5bqDPwTL0n+KsI5I24vKFbgytikjaiH4CUy5aTAezbUbrHKslrXPJyjU5tIpu34sq72BV4LKZJ+KxVlt+pfVa03zEVpcDB/aIP/qxFseFJQEwAAAAAElFTkSuQmCC', 'geometry': None}, 'embedding': None}]}\n",
            "{'datum': {'uid': 'text1', 'metadata': {'path': {'type': 'string', 'value': 'a/b/c/text1.txt'}, 'context': {'type': 'string', 'value': 'Is the content of this product review postive?'}}}, 'annotations': [{'task_type': 'classification', 'metadata': {}, 'labels': [{'key': 'label', 'value': 'positive', 'score': 0.8}, {'key': 'label', 'value': 'negative', 'score': 0.2}], 'bounding_box': None, 'polygon': None, 'raster': None, 'embedding': None}]}\n"
          ]
        }
      ],
      "source": [
        "for datum in dataset.get_datums():\n",
        "    print(model.get_prediction(dataset, datum))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'key': 'class_label', 'value': 'dog', 'score': None}\n",
            "{'key': 'class_label', 'value': 'car', 'score': None}\n",
            "{'key': 'class_label', 'value': 'cat', 'score': None}\n",
            "{'key': 'label', 'value': 'negative', 'score': None}\n",
            "{'key': 'label', 'value': 'positive', 'score': None}\n",
            "{'key': 'class_label', 'value': 'person', 'score': None}\n"
          ]
        }
      ],
      "source": [
        "for label in model.get_labels():\n",
        "    print(label)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluating Performance\n",
        "\n",
        "Finally, we'll use our Valor abstractions to evaluate model performance. For more detailed, task-specific examples, see our follow-up notebooks at the links below:\n",
        "- [Tabular classification](https://github.com/Striveworks/valor/blob/main/examples/classification/tabular.ipynb)\n",
        "- [Object detection](https://github.com/Striveworks/valor/blob/main/examples/object-detection/coco-yolo.ipynb)\n",
        "- [Semantic segmentation](https://github.com/Striveworks/valor/blob/main/examples/semantic-segmentation/coco-yolo.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluating Detections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'type': 'AP',\n",
              "  'parameters': {'iou': 0.5},\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'cat'}},\n",
              " {'type': 'AP',\n",
              "  'parameters': {'iou': 0.75},\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'cat'}},\n",
              " {'type': 'AP',\n",
              "  'parameters': {'iou': 0.5},\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'person'}},\n",
              " {'type': 'AP',\n",
              "  'parameters': {'iou': 0.75},\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'person'}},\n",
              " {'type': 'AP',\n",
              "  'parameters': {'iou': 0.5},\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'dog'}},\n",
              " {'type': 'AP',\n",
              "  'parameters': {'iou': 0.75},\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'dog'}},\n",
              " {'type': 'AR',\n",
              "  'parameters': {'ious': [0.5,\n",
              "    0.55,\n",
              "    0.6,\n",
              "    0.65,\n",
              "    0.7,\n",
              "    0.75,\n",
              "    0.8,\n",
              "    0.85,\n",
              "    0.9,\n",
              "    0.95]},\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'cat'}},\n",
              " {'type': 'AR',\n",
              "  'parameters': {'ious': [0.5,\n",
              "    0.55,\n",
              "    0.6,\n",
              "    0.65,\n",
              "    0.7,\n",
              "    0.75,\n",
              "    0.8,\n",
              "    0.85,\n",
              "    0.9,\n",
              "    0.95]},\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'person'}},\n",
              " {'type': 'AR',\n",
              "  'parameters': {'ious': [0.5,\n",
              "    0.55,\n",
              "    0.6,\n",
              "    0.65,\n",
              "    0.7,\n",
              "    0.75,\n",
              "    0.8,\n",
              "    0.85,\n",
              "    0.9,\n",
              "    0.95]},\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'dog'}},\n",
              " {'type': 'mAP', 'parameters': {'iou': 0.5}, 'value': 1.0},\n",
              " {'type': 'mAP', 'parameters': {'iou': 0.75}, 'value': 1.0},\n",
              " {'type': 'mAR',\n",
              "  'parameters': {'ious': [0.5,\n",
              "    0.55,\n",
              "    0.6,\n",
              "    0.7,\n",
              "    0.65,\n",
              "    0.75,\n",
              "    0.8,\n",
              "    0.85,\n",
              "    0.9,\n",
              "    0.95]},\n",
              "  'value': 1.0},\n",
              " {'type': 'APAveragedOverIOUs',\n",
              "  'parameters': {'ious': [0.5,\n",
              "    0.55,\n",
              "    0.6,\n",
              "    0.65,\n",
              "    0.7,\n",
              "    0.75,\n",
              "    0.8,\n",
              "    0.85,\n",
              "    0.9,\n",
              "    0.95]},\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'cat'}},\n",
              " {'type': 'APAveragedOverIOUs',\n",
              "  'parameters': {'ious': [0.5,\n",
              "    0.55,\n",
              "    0.6,\n",
              "    0.65,\n",
              "    0.7,\n",
              "    0.75,\n",
              "    0.8,\n",
              "    0.85,\n",
              "    0.9,\n",
              "    0.95]},\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'person'}},\n",
              " {'type': 'APAveragedOverIOUs',\n",
              "  'parameters': {'ious': [0.5,\n",
              "    0.55,\n",
              "    0.6,\n",
              "    0.65,\n",
              "    0.7,\n",
              "    0.75,\n",
              "    0.8,\n",
              "    0.85,\n",
              "    0.9,\n",
              "    0.95]},\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'dog'}},\n",
              " {'type': 'mAPAveragedOverIOUs',\n",
              "  'parameters': {'ious': [0.5,\n",
              "    0.55,\n",
              "    0.6,\n",
              "    0.7,\n",
              "    0.65,\n",
              "    0.75,\n",
              "    0.8,\n",
              "    0.85,\n",
              "    0.9,\n",
              "    0.95]},\n",
              "  'value': 1.0}]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_objdet = model.evaluate_detection(dataset)\n",
        "eval_objdet.wait_for_completion()\n",
        "eval_objdet.metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluating Classifications\n",
        "\n",
        "Note that running the code below evaluates both our text classifications as well as our image classifications. If we only wanted to evaluate one type of classification task, we could use `evaluation_classification`'s `filters` argument to specify which type of labels to evaluate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'type': 'Accuracy',\n",
              "  'parameters': {'label_key': 'class_label'},\n",
              "  'value': 1.0},\n",
              " {'type': 'ROCAUC', 'parameters': {'label_key': 'class_label'}, 'value': 1.0},\n",
              " {'type': 'Precision',\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'cat'}},\n",
              " {'type': 'Recall',\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'cat'}},\n",
              " {'type': 'F1', 'value': 1.0, 'label': {'key': 'class_label', 'value': 'cat'}},\n",
              " {'type': 'Precision',\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'dog'}},\n",
              " {'type': 'Recall',\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'dog'}},\n",
              " {'type': 'F1', 'value': 1.0, 'label': {'key': 'class_label', 'value': 'dog'}},\n",
              " {'type': 'Accuracy', 'parameters': {'label_key': 'label'}, 'value': 1.0},\n",
              " {'type': 'ROCAUC', 'parameters': {'label_key': 'label'}, 'value': 1.0},\n",
              " {'type': 'Precision',\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'label', 'value': 'positive'}},\n",
              " {'type': 'Recall',\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'label', 'value': 'positive'}},\n",
              " {'type': 'F1', 'value': 1.0, 'label': {'key': 'label', 'value': 'positive'}},\n",
              " {'type': 'Precision',\n",
              "  'value': -1.0,\n",
              "  'label': {'key': 'label', 'value': 'negative'}},\n",
              " {'type': 'Recall',\n",
              "  'value': -1.0,\n",
              "  'label': {'key': 'label', 'value': 'negative'}},\n",
              " {'type': 'F1', 'value': -1.0, 'label': {'key': 'label', 'value': 'negative'}}]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_clf = model.evaluate_classification(dataset)\n",
        "eval_clf.wait_for_completion()\n",
        "eval_clf.metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluating Segmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'type': 'IOU',\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'cat'}},\n",
              " {'type': 'IOU',\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'car'}},\n",
              " {'type': 'IOU',\n",
              "  'value': 1.0,\n",
              "  'label': {'key': 'class_label', 'value': 'dog'}},\n",
              " {'type': 'mIOU', 'value': 1.0}]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_semseg = model.evaluate_segmentation(dataset)\n",
        "eval_semseg.wait_for_completion()\n",
        "eval_semseg.metrics"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".env-valor",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
