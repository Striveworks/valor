{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Notebook for Text Generation Metric Evaluation\n",
    "\n",
    "This notebook demonstrates example use cases for the Valor text generation metrics. The Valor text generation metrics can be used across a variety of tasks which typically, but not always, involve prompting an LLM to generate some text. Use cases include Query Answering, Retrieval Augmented Generation (which can be thought of as a subcase of Q&A), Summarization and Content Generation. \n",
    "\n",
    "Some of the metrics can be applied across different use cases. For example, the BLEU metric can be used to compare predictions (generated text) to groundtruth answers in the case of Q&A/RAG, and can also be used to compare predictions (generated text) to groundtruth summaries in the case of Summarization. Conversely, some of the metrics are specific to a use case, such as the ContextRecall metric for RAG or the Summarization score for Summarization. \n",
    "\n",
    "In all three use cases below, we generate answers using GPT3.5-turbo and evaluate those answers with a variety of metrics. For the text comparison metrics, we compare GPT3.5-turbo's responses to groundtruth Huggingface answers/summaries for the RAG and Summarization datasets. For the llm guided metrics (which include the RAG metrics, Summarization metrics and general text generation metrics), we are using GPT4o to evaluate the responses of GPT3.5-turbo. \n",
    "\n",
    "The first example is RAG for Q&A. We download a RAG dataset from HuggingFace, use Llama-Index and GPT3.5-turbo to generate answers, and evaluate those answers with text comparison metrics, RAG metrics and general text generation metrics.\n",
    "\n",
    "The second example is Summarization. We download a CNN news dataset from HuggingFace which includes groundtruth summaries. We ask GPT3.5-turbo to summarize the articles. Then, we evaluate those summaries with text comparison metrics, summarization metrics and general text generation metrics.\n",
    "\n",
    "The third example is content generation. We manually create a few queries, each of a different query type (creative, educational, professional). Then we evaluate the generated content with general text generation metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to Valor API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientConnectionFailed",
     "evalue": "HTTPConnectionPool(host='0.0.0.0', port=8000): Max retries exceeded with url: /api-version (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fb3ab0a6450>: Failed to establish a new connection: [Errno 111] Connection refused'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/valor/lib/python3.11/site-packages/urllib3/connection.py:198\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 198\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/valor/lib/python3.11/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/valor/lib/python3.11/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/valor/lib/python3.11/site-packages/urllib3/connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/valor/lib/python3.11/site-packages/urllib3/connectionpool.py:496\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 496\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/valor/lib/python3.11/site-packages/urllib3/connection.py:400\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[0;32m--> 400\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/valor/lib/python3.11/http/client.py:1277\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1277\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/valor/lib/python3.11/http/client.py:1037\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1037\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1040\u001b[0m \n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/valor/lib/python3.11/http/client.py:975\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 975\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/valor/lib/python3.11/site-packages/urllib3/connection.py:238\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/valor/lib/python3.11/site-packages/urllib3/connection.py:213\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;66;03m# Audit hooks are only available in Python 3.8+\u001b[39;00m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7fb3ab0a6450>: Failed to establish a new connection: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/valor/lib/python3.11/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/valor/lib/python3.11/site-packages/urllib3/connectionpool.py:847\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    845\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 847\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    850\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/miniconda3/envs/valor/lib/python3.11/site-packages/urllib3/util/retry.py:515\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    514\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    517\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='0.0.0.0', port=8000): Max retries exceeded with url: /api-version (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fb3ab0a6450>: Failed to establish a new connection: [Errno 111] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/mnt/nvme0n1p2/home/b.nativi/valor/client/valor/client.py:174\u001b[0m, in \u001b[0;36mClientConnection.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     api_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_api_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/mnt/nvme0n1p2/home/b.nativi/valor/client/valor/client.py:1167\u001b[0m, in \u001b[0;36mClientConnection.get_api_version\u001b[0;34m(self, timeout, *_)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;124;03mGets the version number of the API.\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;124;03m    The api version or `None` if it doesn't exist.\u001b[39;00m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1167\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_requests_get_rel_host\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapi-version\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_version\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/mnt/nvme0n1p2/home/b.nativi/valor/client/valor/client.py:346\u001b[0m, in \u001b[0;36mClientConnection._requests_get_rel_host\u001b[0;34m(self, endpoint, timeout, *_)\u001b[0m\n\u001b[1;32m    345\u001b[0m timeout \u001b[38;5;241m=\u001b[39m _format_request_timeout(timeout\u001b[38;5;241m=\u001b[39mtimeout, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_requests_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/nvme0n1p2/home/b.nativi/valor/client/valor/client.py:269\u001b[0m, in \u001b[0;36mClientConnection._requests_wrapper\u001b[0;34m(self, method_name, endpoint, timeout, ignore_auth, *_, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 269\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mrequests_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mReadTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/valor/lib/python3.11/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/valor/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/valor/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/envs/valor/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/valor/lib/python3.11/site-packages/requests/adapters.py:700\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 700\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='0.0.0.0', port=8000): Max retries exceeded with url: /api-version (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fb3ab0a6450>: Failed to establish a new connection: [Errno 111] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mClientConnectionFailed\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvalor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Annotation, Datum, Dataset, Model, GroundTruth, Client, Prediction, connect\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Connect to Valor API.\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttp://0.0.0.0:8000\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m client \u001b[38;5;241m=\u001b[39m Client()\n\u001b[1;32m     10\u001b[0m OPENAI_API_KEY \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/mnt/nvme0n1p2/home/b.nativi/valor/client/valor/client.py:1255\u001b[0m, in \u001b[0;36m_create_connection.<locals>.connect\u001b[0;34m(host, username, password, access_token, reconnect)\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reconnect:\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ClientAlreadyConnectedError\n\u001b[0;32m-> 1255\u001b[0m _connection \u001b[38;5;241m=\u001b[39m \u001b[43mClientConnection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43musername\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musername\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpassword\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1259\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccess_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccess_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:7\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, host, access_token, username, password)\u001b[0m\n",
      "File \u001b[0;32m/mnt/nvme0n1p2/home/b.nativi/valor/client/valor/client.py:176\u001b[0m, in \u001b[0;36mClientConnection.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m     api_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_api_version()\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ClientConnectionFailed(\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_version(\n\u001b[1;32m    179\u001b[0m     client_version\u001b[38;5;241m=\u001b[39mclient_version, api_version\u001b[38;5;241m=\u001b[39mapi_version\n\u001b[1;32m    180\u001b[0m )\n\u001b[1;32m    182\u001b[0m success_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully connected to host at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mClientConnectionFailed\u001b[0m: HTTPConnectionPool(host='0.0.0.0', port=8000): Max retries exceeded with url: /api-version (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fb3ab0a6450>: Failed to establish a new connection: [Errno 111] Connection refused'))"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from valor.enums import EvaluationStatus\n",
    "from valor import Annotation, Datum, Dataset, Model, GroundTruth, Client, Prediction, connect\n",
    "\n",
    "# Connect to Valor API.\n",
    "connect(\"http://0.0.0.0:8000\")\n",
    "client = Client()\n",
    "\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "MISTRAL_API_KEY = os.environ[\"MISTRAL_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Case #1: RAG for Q&A\n",
    "\n",
    "## Download and Save the Corpus for the RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_dataset = load_dataset(\"rag-datasets/mini_wikipedia\", \"text-corpus\")[\"passages\"]\n",
    "print(corpus_dataset)\n",
    "\n",
    "# For each passage in corpus_dataset, save that passage to a .txt file with the passage_id as the filename.\n",
    "for passage in corpus_dataset:\n",
    "    with open(f\"./rag_corpus/{passage[\"id\"]}.txt\", \"w\") as f:\n",
    "        f.write(passage[\"passage\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Queries and get Answers with Llama-Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the query dataset. \n",
    "qa_dataset = load_dataset(\"rag-datasets/mini_wikipedia\", \"question-answer\")[\"test\"]\n",
    "qa_dataset = qa_dataset.shuffle(seed=42)\n",
    "print(qa_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads in the rag_corpus and builds an index.\n",
    "# Initialize a query_engine, which will use GPT3.5-turbo by default with calls to OpenAI's API.\n",
    "# You must specify your OpenAI API key in the environment variable OPENAI_API_KEY for the below code to function. \n",
    "documents = SimpleDirectoryReader(\"rag_corpus\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample use\n",
    "response = query_engine.query(\"What country borders Argentina and Brazil?\")\n",
    "print(response)\n",
    "print(response.source_nodes)\n",
    "\n",
    "response = query_engine.query(\"What color is a penguin?\")\n",
    "print(response)\n",
    "print(response.source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"rag_data.csv\"):\n",
    "    os.remove(\"rag_data.csv\")\n",
    "\n",
    "NUMBER_OF_RECORDS = 50\n",
    "\n",
    "with open(\"rag_data.csv\", mode=\"w\") as data_file:\n",
    "    data_writer = csv.writer(data_file, delimiter=\",\", quoting=csv.QUOTE_MINIMAL)\n",
    "    data_writer.writerow([\"query\", \"groundtruth\", \"prediction\", \"context_list\"])\n",
    "\n",
    "    for i in range(NUMBER_OF_RECORDS):\n",
    "        query = qa_dataset[i][\"question\"]\n",
    "        groundtruth = qa_dataset[i][\"answer\"]\n",
    "        print(f\"{i}: {query}\")\n",
    "\n",
    "        response_object = query_engine.query(query)\n",
    "        response = response_object.response\n",
    "        print(f\"response: {response}\")\n",
    "        context_list = []\n",
    "        for i in range(len(response_object.source_nodes)):\n",
    "            context_list.append(response_object.source_nodes[i].text)\n",
    "        data_writer.writerow([query, groundtruth, response, context_list])\n",
    "    \n",
    "    data_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation in Valor\n",
    "\n",
    "In this example, the RAG pipeline produces answers to the given queries by retrieving context and then generating answers based on the context and query. Groundtruth answers are also known for these queries. Both the datums (which contain the queries) and the groundtruths are added to the dataset. Then, the predictions are added to the model, which includes the answer and the context used to generate that answer. \n",
    "\n",
    "The metrics requested include some text comparison metrics (BLEU and ROUGE), which do a text comparison between the generated answer and the groundtruth answer for the same datum. If the user only desires these metrics, then they do not need to include the context_list in the prediction and they do not need to supply the llm_api_parameters. \n",
    "\n",
    "However, other metrics are requested that use llm guided evaluation (AnswerRelevance and Coherence). To get these metrics, the user needs to specify a client (openai or mistral), an api key and a model name, along with any other model kwargs. The api key can be stored in an environment variable or passed directly into model.evaluate_text_generation(). \n",
    "\n",
    "Each of these metrics will use API calls to the specified LLM service to get information relevant for computing the desired metrics. Some of these metrics, such as AnswerRelevance and Coherence, do not require any context, so can be used with a Q&A model that does not use context. Currently, none of these metrics use the context in their API calls or computations.\n",
    "\n",
    "Note that AnswerRelevance is specific to the Q&A setting (RAG is a subcase of Q&A). AnswerRelevance measures how relevant the answer is to the question, by measuring the proportion of statements in the answer that are relevant to the question. This would not work as well in a less structured setting, such as summarization or content generation, where some statements in the generated text may not be directly relevant to the query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dataset of queries, groundtruths and predictions. \n",
    "df = pd.read_csv(\"rag_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the purposes of this example, let's get metrics for just the first 5 datums.\n",
    "MAX_DATUMS = 5\n",
    "\n",
    "# Create, build and finalize the dataset and model.\n",
    "dataset = Dataset.create(\n",
    "    name=\"rag_dataset\",\n",
    "    metadata={\n",
    "        \"hf_dataset_name\": \"rag-datasets/mini_wikipedia\",\n",
    "        \"hf_dataset_subset\": \"question-answer\",\n",
    "        \"hf_dataset_split\": \"test\",\n",
    "        \"shuffle_seed\": 42,\n",
    "        \"number_of_records\": 50,\n",
    "    }\n",
    ")\n",
    "model = Model.create(\n",
    "    name=\"rag_model\",\n",
    "    metadata={\n",
    "        \"embedding_model_name\": \"text-embedding-ada-002\", # When we ran llama-index above, it defaulted to text-embedding-ada-002.\n",
    "        \"llm_model_name\": \"GPT3.5-turbo\", # When we ran llama-index above, it defaulted to GPT3.5.\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create a list of datums\n",
    "datum_list = []\n",
    "for i in range(min(len(df), MAX_DATUMS)):\n",
    "    row = df.iloc[i]\n",
    "\n",
    "    datum_list.append(\n",
    "        Datum(\n",
    "            uid=f\"query{i}\",\n",
    "            text=row[\"query\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Build and finalize the dataset\n",
    "for i in range(min(len(df), MAX_DATUMS)):\n",
    "    row = df.iloc[i]\n",
    "    datum = datum_list[i]\n",
    "\n",
    "    dataset.add_groundtruth(\n",
    "        GroundTruth(\n",
    "            datum=datum,\n",
    "            annotations=[\n",
    "                # Perhaps you have multiple correct or good groundtruth answers to the query.\n",
    "                # The labels below are a trivial example, but you could have less trivial examples.\n",
    "                # For example, to the query \"When was the United States of America founded?\", you might \n",
    "                # consider both \"During the American Revolution\" or \"July 4th, 1776\" to be good answers.\n",
    "                Annotation(\n",
    "                    text=row[\"groundtruth\"],\n",
    "                    metadata={\"annotator\": \"Alice\"},\n",
    "                ),\n",
    "                Annotation(\n",
    "                    text=\"The answer is \" + row[\"groundtruth\"],\n",
    "                    metadata={\"annotator\": \"Bob\"},\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    "dataset.finalize()\n",
    "\n",
    "# Build and finalize the model\n",
    "for i in range(min(len(df), MAX_DATUMS)):\n",
    "    row = df.iloc[i]\n",
    "    datum = datum_list[i]\n",
    "\n",
    "    model.add_prediction(\n",
    "        dataset, \n",
    "        Prediction(\n",
    "            datum=datum,\n",
    "            annotations=[\n",
    "                Annotation(\n",
    "                    text=row[\"prediction\"],\n",
    "                    context_list=ast.literal_eval(row[\"context_list\"]),\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    "model.finalize_inferences(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using GPT4o to evaluate GPT3.5-turbo's predictions across a variety of metrics. \n",
    "eval_job = model.evaluate_text_generation(\n",
    "    dataset,\n",
    "    metrics_to_return=[\n",
    "        \"AnswerCorrectness\",\n",
    "        \"AnswerRelevance\", \n",
    "        \"Bias\",\n",
    "        \"BLEU\", \n",
    "        \"ContextPrecision\",\n",
    "        \"ContextRecall\",\n",
    "        \"ContextRelevance\",\n",
    "        \"Faithfulness\",\n",
    "        \"Hallucination\",\n",
    "        \"ROUGE\",\n",
    "        \"Toxicity\",\n",
    "    ],\n",
    "    llm_api_params = {\n",
    "        \"client\":\"openai\",\n",
    "        \"api_key\":OPENAI_API_KEY,\n",
    "        \"data\":{\n",
    "            \"model\":\"gpt-4o\",\n",
    "            \"seed\":2024,\n",
    "        },\n",
    "    },    \n",
    "    metric_params={\n",
    "        \"BLEU\": {\n",
    "            \"weights\": [1, 0, 0, 0],\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "assert eval_job.wait_for_completion(timeout=3000) == EvaluationStatus.DONE\n",
    "\n",
    "# These are the computed metrics.\n",
    "eval_job.metrics\n",
    "\n",
    "# Here are some example metrics. These are all for query0 and were evaluated by GPT-4o.\n",
    "example_expected_metrics = [\n",
    "    {\n",
    "        'type': 'AnswerCorrectness',\n",
    "        'value': 0.5,\n",
    "        'parameters': {\n",
    "            'dataset': 'rag_dataset', \n",
    "            'datum_uid': 'query0', \n",
    "            'prediction': \"Cleveland's opponents in 1884 criticized his alleged involvement in a scandal regarding an illegitimate child, which was used to counter his innocent image during the presidential campaign.\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        'type': 'AnswerRelevance',\n",
    "        'value': 1.0,\n",
    "        'parameters': {\n",
    "            'dataset': 'rag_dataset',\n",
    "            'datum_uid': 'query0',\n",
    "            'prediction': \"Cleveland's opponents in 1884 criticized his alleged involvement in a scandal regarding an illegitimate child, which was used to counter his innocent image during the presidential campaign.\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        'type': 'Bias',\n",
    "        'value': 0.0,\n",
    "        'parameters': {\n",
    "            'dataset': 'rag_dataset',\n",
    "            'datum_uid': 'query0',\n",
    "            'prediction': \"Cleveland's opponents in 1884 criticized his alleged involvement in a scandal regarding an illegitimate child, which was used to counter his innocent image during the presidential campaign.\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        'type': 'BLEU',\n",
    "        'value': 0.10344827586206899,\n",
    "        'parameters': {\n",
    "            'dataset': 'rag_dataset',\n",
    "            'weights': [1.0, 0.0, 0.0, 0.0],\n",
    "            'datum_uid': 'query0',\n",
    "            'prediction': \"Cleveland's opponents in 1884 criticized his alleged involvement in a scandal regarding an illegitimate child, which was used to counter his innocent image during the presidential campaign.\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        'type': 'ContextPrecision', \n",
    "        'value': 0.0,\n",
    "        'parameters': {\n",
    "            'dataset': 'rag_dataset', \n",
    "            'datum_uid': 'query0', \n",
    "            'context_list': [\n",
    "                \"Cleveland was defeated in the 1888 presidential election, in part due to fraud (See Blocks of Five). He actually led in the popular vote over Benjamin Harrison (48.6% to 47.8%), but Harrison won the Electoral College by a 233-168 margin, largely by squeaking out a barely-over-1% win in Cleveland's home state of New York; in fact, had Cleveland won his home state, he would have won the electoral vote by a count of 204-197 (201 votes then needed for victory). Note, though, that Cleveland earned 24 of his electoral votes in states that he won by less than 1% (Connecticut, Virginia, and West Virginia).\", \n",
    "                \"Some of Cleveland's actions were controversial with political factions. Such criticisms include but are not limited to: his intervention in the Pullman Strike of 1894 in order to keep the railroads moving (a move which angered labor unions), his support of the gold standard, and opposition to free silver which alienated the agrarian wing of the Democrats.  Furthermore, critics complained that he had little imagination and seemed overwhelmed by the nation's economic disasters   depressions and strikes   in his second term. He lost control of his party to the agrarians and silverites in 1896.\"\n",
    "            ]\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        'type': 'ContextRecall',\n",
    "        'value': 0.0, \n",
    "        'parameters': {\n",
    "            'dataset': 'rag_dataset', \n",
    "            'datum_uid': 'query0', \n",
    "            'context_list': [\n",
    "                \"Cleveland was defeated in the 1888 presidential election, in part due to fraud (See Blocks of Five). He actually led in the popular vote over Benjamin Harrison (48.6% to 47.8%), but Harrison won the Electoral College by a 233-168 margin, largely by squeaking out a barely-over-1% win in Cleveland's home state of New York; in fact, had Cleveland won his home state, he would have won the electoral vote by a count of 204-197 (201 votes then needed for victory). Note, though, that Cleveland earned 24 of his electoral votes in states that he won by less than 1% (Connecticut, Virginia, and West Virginia).\", \n",
    "                \"Some of Cleveland's actions were controversial with political factions. Such criticisms include but are not limited to: his intervention in the Pullman Strike of 1894 in order to keep the railroads moving (a move which angered labor unions), his support of the gold standard, and opposition to free silver which alienated the agrarian wing of the Democrats.  Furthermore, critics complained that he had little imagination and seemed overwhelmed by the nation's economic disasters   depressions and strikes   in his second term. He lost control of his party to the agrarians and silverites in 1896.\"\n",
    "            ]\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        'type': 'ContextRelevance', \n",
    "        'value': 0.0,\n",
    "        'parameters': {\n",
    "            'dataset': 'rag_dataset', \n",
    "            'datum_uid': 'query0', \n",
    "            'context_list': [\n",
    "                \"Cleveland was defeated in the 1888 presidential election, in part due to fraud (See Blocks of Five). He actually led in the popular vote over Benjamin Harrison (48.6% to 47.8%), but Harrison won the Electoral College by a 233-168 margin, largely by squeaking out a barely-over-1% win in Cleveland's home state of New York; in fact, had Cleveland won his home state, he would have won the electoral vote by a count of 204-197 (201 votes then needed for victory). Note, though, that Cleveland earned 24 of his electoral votes in states that he won by less than 1% (Connecticut, Virginia, and West Virginia).\", \n",
    "                \"Some of Cleveland's actions were controversial with political factions. Such criticisms include but are not limited to: his intervention in the Pullman Strike of 1894 in order to keep the railroads moving (a move which angered labor unions), his support of the gold standard, and opposition to free silver which alienated the agrarian wing of the Democrats.  Furthermore, critics complained that he had little imagination and seemed overwhelmed by the nation's economic disasters   depressions and strikes   in his second term. He lost control of his party to the agrarians and silverites in 1896.\"\n",
    "            ]\n",
    "        },\n",
    "    },\n",
    "    # {\n",
    "    #     'type': 'Coherence',\n",
    "    #     'value': 4.0,\n",
    "    #     'parameters': {\n",
    "    #         'dataset': 'rag_dataset',\n",
    "    #         'datum_uid': 'query0',\n",
    "    #         'prediction': \"Cleveland's opponents in 1884 criticized his alleged involvement in a scandal regarding an illegitimate child, which was used to counter his innocent image during the presidential campaign.\"\n",
    "    #     },\n",
    "    # },\n",
    "    {\n",
    "        'type': 'Faithfulness',\n",
    "        'value': 0.0,\n",
    "        'parameters': {\n",
    "            'dataset': 'rag_dataset',\n",
    "            'datum_uid': 'query0',\n",
    "            'prediction': \"Cleveland's opponents in 1884 criticized his alleged involvement in a scandal regarding an illegitimate child, which was used to counter his innocent image during the presidential campaign.\",\n",
    "            'context_list': [\n",
    "                \"Cleveland was defeated in the 1888 presidential election, in part due to fraud (See Blocks of Five). He actually led in the popular vote over Benjamin Harrison (48.6% to 47.8%), but Harrison won the Electoral College by a 233-168 margin, largely by squeaking out a barely-over-1% win in Cleveland's home state of New York; in fact, had Cleveland won his home state, he would have won the electoral vote by a count of 204-197 (201 votes then needed for victory). Note, though, that Cleveland earned 24 of his electoral votes in states that he won by less than 1% (Connecticut, Virginia, and West Virginia).\",\n",
    "                \"Some of Cleveland's actions were controversial with political factions. Such criticisms include but are not limited to: his intervention in the Pullman Strike of 1894 in order to keep the railroads moving (a move which angered labor unions), his support of the gold standard, and opposition to free silver which alienated the agrarian wing of the Democrats.  Furthermore, critics complained that he had little imagination and seemed overwhelmed by the nation's economic disasters   depressions and strikes   in his second term. He lost control of his party to the agrarians and silverites in 1896.\"\n",
    "            ],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        'type': 'Hallucination',\n",
    "        'value': 1.0,\n",
    "        'parameters': {\n",
    "            'dataset': 'rag_dataset',\n",
    "            'datum_uid': 'query0',\n",
    "            'prediction': \"Cleveland's opponents in 1884 criticized his alleged involvement in a scandal regarding an illegitimate child, which was used to counter his innocent image during the presidential campaign.\",\n",
    "            'context_list': [\n",
    "                \"Cleveland was defeated in the 1888 presidential election, in part due to fraud (See Blocks of Five). He actually led in the popular vote over Benjamin Harrison (48.6% to 47.8%), but Harrison won the Electoral College by a 233-168 margin, largely by squeaking out a barely-over-1% win in Cleveland's home state of New York; in fact, had Cleveland won his home state, he would have won the electoral vote by a count of 204-197 (201 votes then needed for victory). Note, though, that Cleveland earned 24 of his electoral votes in states that he won by less than 1% (Connecticut, Virginia, and West Virginia).\",\n",
    "                \"Some of Cleveland's actions were controversial with political factions. Such criticisms include but are not limited to: his intervention in the Pullman Strike of 1894 in order to keep the railroads moving (a move which angered labor unions), his support of the gold standard, and opposition to free silver which alienated the agrarian wing of the Democrats.  Furthermore, critics complained that he had little imagination and seemed overwhelmed by the nation's economic disasters   depressions and strikes   in his second term. He lost control of his party to the agrarians and silverites in 1896.\"\n",
    "            ],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        'type': 'ROUGE',\n",
    "        'value': {\n",
    "            'rouge1': 0.21052631578947364,\n",
    "            'rouge2': 0.12121212121212122,\n",
    "            'rougeL': 0.17142857142857143,\n",
    "            'rougeLsum': 0.17142857142857143\n",
    "        },\n",
    "        'parameters': {\n",
    "            'dataset': 'rag_dataset',\n",
    "            'datum_uid': 'query0',\n",
    "            'prediction': \"Cleveland's opponents in 1884 criticized his alleged involvement in a scandal regarding an illegitimate child, which was used to counter his innocent image during the presidential campaign.\",\n",
    "            'rouge_types': ['rouge1', 'rouge2', 'rougeL', 'rougeLsum'],\n",
    "            'use_stemmer': False\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        'type': 'Toxicity',\n",
    "        'value': 0.0,\n",
    "        'parameters': {\n",
    "            'dataset': 'rag_dataset',\n",
    "            'datum_uid': 'query0',\n",
    "            'prediction': \"Cleveland's opponents in 1884 criticized his alleged involvement in a scandal regarding an illegitimate child, which was used to counter his innocent image during the presidential campaign.\"\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Case #2: Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CNN Articles and get Summaries with GPT3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "import openai\n",
    "\n",
    "openai_client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cnn dataset. \n",
    "cnn_dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")[\"test\"]\n",
    "cnn_dataset = cnn_dataset.shuffle(seed=42)\n",
    "print(cnn_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"summarization_data.csv\"):\n",
    "    os.remove(\"summarization_data.csv\")\n",
    "\n",
    "NUMBER_OF_RECORDS = 50\n",
    "\n",
    "instruction=\"You are a helpful assistant. Please summarize the following article in a few sentences.\"\n",
    "\n",
    "with open(\"summarization_data.csv\", mode=\"w\") as data_file:\n",
    "    data_writer = csv.writer(data_file, delimiter=\",\", quoting=csv.QUOTE_MINIMAL)\n",
    "    data_writer.writerow([\"text\", \"groundtruth\", \"prediction\"])\n",
    "\n",
    "    for i in range(NUMBER_OF_RECORDS):\n",
    "        article = cnn_dataset[i][\"article\"]\n",
    "        groundtruth = cnn_dataset[i][\"highlights\"]\n",
    "\n",
    "        print(f\"{i}: {groundtruth}\")\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": instruction},\n",
    "            {\"role\": \"user\", \"content\": article},\n",
    "        ]\n",
    "\n",
    "        response_object = openai_client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\", messages=messages, seed=42\n",
    "        )\n",
    "        prediction = response_object.choices[0].message.content\n",
    "\n",
    "        print(f\"prediction: {prediction}\")\n",
    "        data_writer.writerow([article, groundtruth, prediction])\n",
    "    \n",
    "    data_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation in Valor\n",
    "\n",
    "In this example, CNN articles are summarized by GPT3.5-turbo. Groundtruth summaries are also known for these articles. Both the datums (which contain the articles) and the groundtruths are added to the dataset. Then, the predictions are added to the model, which includes just the generated summary (there is not retrieved context for summarization).\n",
    "\n",
    "The metrics requested are BLEU, ROUGE and Coherence. BLEU and ROUGE are used to measure the similarity between the generated summary and the groundtruth summary. Coherence is an llm-guided metric that measures the overall quality and cohesiveness of the generated summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dataset of queries, groundtruths and predictions. \n",
    "df = pd.read_csv(\"summarization_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aston Villa take on Liverpool in their FA Cup semi-final encounter on Sunday with the competition both sides' last chance to win any silverware this season. Sportsmail columnist Jamie Redknapp looks ahead to the Wembley showdown and where the match could be won and lost with individual player duels. CHRISTIAN BENTEKE v MARTIN SKRTEL . This will be a heavyweight contest that could decide the game. Christian Benteke is superb in the air and Martin Skrtel will have his hands full. Liverpool have to stop the supply line because defending crosses has been their Achilles heel this season. Christian Benteke (centre) scored the only goal of the game as Villa won 1-0 at Tottenham on April 11 . Liverpool defender Martin Skrtel (right) will have his hands full trying to stop Benteke on Sunday afternoon . FABIAN DELPH v JORDAN HENDERSON . This should be a good contest between two England team-mates. Fabian Delphs new deal was a real boost for Villa - he drives that midfield, though he doesnt get enough goals. You used to say the same about Jordan Henderson but he has improved so much. England international Fabian Delph (left) and Jordan Henderson are set for a midfield battle at Wembley . RAHEEM STERLING v RON VLAAR and NATHAN BAKER . Ron Vlaar and Nathan Baker make an imposing back line but they would rather be up against a Benteke than a Raheem Sterling, who will float around and make himself difficult to mark so he can use his lightning pace to get in behind them. Raheem Sterling's (left) pace and trickery is bound to cause the Villa defence a lot of problems . Ron Vlaar (left) was part of the Villa defence that kept a clean sheet at Spurs in the Premier League . The Holland international and Nathan Baker (right) will be hoping to do likewise against the Reds at Wembley .\n",
      "Aston Villa and Liverpool face off in the FA Cup semi-final as both teams look to secure their last chance at silverware this season. Sportsmail columnist Jamie Redknapp analyzes key player duels that could decide the game, such as Christian Benteke against Martin Skrtel, Fabian Delph against Jordan Henderson, and Raheem Sterling against Ron Vlaar and Nathan Baker. Redknapp emphasizes the importance of stopping the supply line to Benteke and dealing with Sterling's pace and trickery in the match.\n",
      "Juventus and Liverpool are continuing to monitor developments with Chelsea midfielder Oscar. The Brazil international has been criticised by Jose Mourinho in recent weeks and there are question marks over his future. Chelsea want to strengthen in the summer and may need a high profile departure to help balance the books. Juventus and Liverpool are interested in signing Chelsea 23-year-old midfielder Oscar . Oscar in action during Chelsea's 1-0 Premier League victory against Queens Park Rangers last weekend . Oscar cost Chelsea 19.35m and they would want a substantial profit on the 23 year-old. Paris Saintt Germain have shown interest in the past also. Juventus want a playmaker for next season and Brazil boss Carlos Dunga advised them to buy Oscar. 'He reminds me of Roberto Baggio,' he said. 'Oscar has technique, reads situations well and is a modern and versatile trequartista. He reminds me of Roberto Baggio, but also has similarities to Massimiliano Allegri. The former Sao Paulo youngster has struggled to make an impact for Chelsea this season . Brazil coach Dunga (pictured) revealed the Chelsea midfielder reminds him of Roberto Baggio . 'Brazilians like to have fun with their football, which hasnt happened to Oscar very much recently, but I met Jose Mourinho and he spoke highly of all his Brazilian players. 'I tell Allegri that Oscar is strong and also a good lad. A forward line with him, Carlos Tevez and Alvaro Morata would drive any Coach crazy. 'It wouldnt be a step backwards for Oscar to go to Juventus. Hed be decisive in Serie A and whether he plays for Juventus or Chelsea itll always be a great club.' Oscar celebrates scoring Chelsea's fourth goal during the 5-0 victory against Swansea in January .\n",
      "Juventus and Liverpool are showing interest in Chelsea midfielder Oscar, who has faced criticism and uncertainty about his future at the club. Chelsea may need to sell a high-profile player to strengthen their squad in the summer. Oscar, who was signed for 19.35m, has also attracted interest from Paris Saint-Germain in the past. Brazil coach Carlos Dunga sees qualities in Oscar similar to Roberto Baggio and believes he could be a key player for Juventus.\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[46]['text'])\n",
    "print(df.iloc[46]['prediction'])\n",
    "print(df.iloc[47]['text'])\n",
    "print(df.iloc[47]['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the purpose of this example, let's get metrics for just the first 5 datums.\n",
    "MAX_DATUMS = 5\n",
    "\n",
    "# Create, build and finalize the dataset and model.\n",
    "dataset = Dataset.create(\"summarization_dataset\")\n",
    "model = Model.create(\"summarization_model\")\n",
    "\n",
    "# Create a list of datums\n",
    "datum_list = []\n",
    "for i in range(min(len(df), MAX_DATUMS)):\n",
    "    row = df.iloc[i]\n",
    "\n",
    "    datum_list.append(\n",
    "        Datum(\n",
    "            uid=f\"article{i}\",\n",
    "            text=row[\"text\"],\n",
    "            metadata={\n",
    "                \"query\": \"Summarize this article in a few sentences.\", \n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    \n",
    "# Build and finalize the dataset\n",
    "for i in range(min(len(df), MAX_DATUMS)):\n",
    "    row = df.iloc[i]\n",
    "    datum = datum_list[i]\n",
    "\n",
    "    dataset.add_groundtruth(\n",
    "        GroundTruth(\n",
    "            datum=datum,\n",
    "            annotations=[\n",
    "                Annotation(\n",
    "                    text=row[\"groundtruth\"],\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    "dataset.finalize()\n",
    "\n",
    "# Build and finalize the model\n",
    "for i in range(min(len(df), MAX_DATUMS)):\n",
    "    row = df.iloc[i]\n",
    "    datum = datum_list[i]\n",
    "\n",
    "    model.add_prediction(\n",
    "        dataset, \n",
    "        Prediction(\n",
    "            datum=datum,\n",
    "            annotations=[\n",
    "                Annotation(\n",
    "                    text=row[\"prediction\"],\n",
    "                )\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    "model.finalize_inferences(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using GPT4o to evaluate GPT3.5-turbo's predictions across a variety of metrics. \n",
    "eval_job = model.evaluate_text_generation(\n",
    "    dataset,\n",
    "    metrics_to_return=[\n",
    "        \"Bias\",\n",
    "        \"BLEU\",\n",
    "        \"Coherence\",\n",
    "        \"ROUGE\",\n",
    "        \"Toxicity\",\n",
    "    ],\n",
    "    llm_api_params = {\n",
    "        \"client\":\"openai\",\n",
    "        \"api_key\":OPENAI_API_KEY,\n",
    "        \"data\":{\n",
    "            \"model\":\"gpt-4o\",\n",
    "            \"seed\":2024,\n",
    "        },\n",
    "    },   \n",
    "    metric_params={\n",
    "        \"BLEU\": {\n",
    "            \"weights\": [1, 0, 0, 0],\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "assert eval_job.wait_for_completion() == EvaluationStatus.DONE\n",
    "\n",
    "eval_job.metrics\n",
    "\n",
    "example_expected_metrics = [\n",
    "    {\n",
    "        'type': 'Bias',\n",
    "        'value': 0.0,\n",
    "        'parameters': {\n",
    "            'dataset': 'summarization_dataset',\n",
    "            'datum_uid': 'article4',\n",
    "            'prediction': 'British taekwondo fighter Aaron Cook plans to compete for Moldova at the 2016 Olympics in Rio after being overlooked for the Great Britain squad in London 2012. Cook received funding from a Moldovan billionaire and has now obtained Moldovan citizenship. He has decided to no longer compete for Great Britain due to feeling overlooked and unsupported, and hopes to represent Moldova at international competitions, including the Olympics. The British Olympic Association could potentially block this move, as discussions are ongoing.'\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        'type': 'BLEU',\n",
    "        'value': 0.3373493975903614,\n",
    "        'parameters': {\n",
    "            'dataset': 'summarization_dataset',\n",
    "            'weights': [1.0, 0.0, 0.0, 0.0],\n",
    "            'datum_uid': 'article4',\n",
    "            'prediction': 'British taekwondo fighter Aaron Cook plans to compete for Moldova at the 2016 Olympics in Rio after being overlooked for the Great Britain squad in London 2012. Cook received funding from a Moldovan billionaire and has now obtained Moldovan citizenship. He has decided to no longer compete for Great Britain due to feeling overlooked and unsupported, and hopes to represent Moldova at international competitions, including the Olympics. The British Olympic Association could potentially block this move, as discussions are ongoing.'\n",
    "        },\n",
    "    },\n",
    "    # {\n",
    "    #     'type': 'Coherence',\n",
    "    #     'value': 5.0,\n",
    "    #     'parameters': {\n",
    "    #         'dataset': 'summarization_dataset',\n",
    "    #         'datum_uid': 'article4',\n",
    "    #         'prediction': 'British taekwondo fighter Aaron Cook plans to compete for Moldova at the 2016 Olympics in Rio after being overlooked for the Great Britain squad in London 2012. Cook received funding from a Moldovan billionaire and has now obtained Moldovan citizenship. He has decided to no longer compete for Great Britain due to feeling overlooked and unsupported, and hopes to represent Moldova at international competitions, including the Olympics. The British Olympic Association could potentially block this move, as discussions are ongoing.'\n",
    "    #     },\n",
    "    # },\n",
    "    {\n",
    "        'type': 'ROUGE',\n",
    "        'value': {\n",
    "            'rouge1': 0.4915254237288136,\n",
    "            'rouge2': 0.13793103448275862,\n",
    "            'rougeL': 0.3389830508474576,\n",
    "            'rougeLsum': 0.37288135593220345\n",
    "        },\n",
    "        'parameters': {\n",
    "            'dataset': 'summarization_dataset',\n",
    "            'datum_uid': 'article4',\n",
    "            'prediction': 'British taekwondo fighter Aaron Cook plans to compete for Moldova at the 2016 Olympics in Rio after being overlooked for the Great Britain squad in London 2012. Cook received funding from a Moldovan billionaire and has now obtained Moldovan citizenship. He has decided to no longer compete for Great Britain due to feeling overlooked and unsupported, and hopes to represent Moldova at international competitions, including the Olympics. The British Olympic Association could potentially block this move, as discussions are ongoing.',\n",
    "            'rouge_types': ['rouge1', 'rouge2', 'rougeL', 'rougeLsum'],\n",
    "            'use_stemmer': False\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        'type': 'Toxicity',\n",
    "        'value': 0.0,\n",
    "        'parameters': {\n",
    "            'dataset': 'summarization_dataset',\n",
    "            'datum_uid': 'article4',\n",
    "            'prediction': 'British taekwondo fighter Aaron Cook plans to compete for Moldova at the 2016 Olympics in Rio after being overlooked for the Great Britain squad in London 2012. Cook received funding from a Moldovan billionaire and has now obtained Moldovan citizenship. He has decided to no longer compete for Great Britain due to feeling overlooked and unsupported, and hopes to represent Moldova at international competitions, including the Olympics. The British Olympic Association could potentially block this move, as discussions are ongoing.'\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Case #3: Content Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Example Content Generation Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"Write about a haunted house from the perspective of the ghost.\",\n",
    "    \"Explain to an elementary school student how to do long multiplication with the example 43 times 22. The resulting answer should be 946.\",\n",
    "    \"Draft an email to a coworker explaining a project delay. Explain that the delay is due to funding cuts, which resulted in multiple employees being moved to different projects. Inform the coworker that the project deadline will have to be pushed back. Be apologetic and professional. Express eagerness to still complete the project as efficiently as possible.\",\n",
    "]\n",
    "\n",
    "query_metadata = [\n",
    "    {\n",
    "        \"request_type\": \"creative\",\n",
    "    },\n",
    "    {\n",
    "        \"request_type\": \"educational\",\n",
    "    },\n",
    "    {\n",
    "        \"request_type\": \"professional\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"content_generation_data.csv\"):\n",
    "    os.remove(\"content_generation_data.csv\")\n",
    "\n",
    "instruction=\"You are a helpful assistant.\"\n",
    "\n",
    "with open(\"content_generation_data.csv\", mode=\"w\") as data_file:\n",
    "    data_writer = csv.writer(data_file, delimiter=\",\", quoting=csv.QUOTE_MINIMAL)\n",
    "    data_writer.writerow([\"query\", \"prediction\"])\n",
    "\n",
    "    for i in range(len(queries)):\n",
    "        query = queries[i]\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": instruction},\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "        ]\n",
    "        response_object = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\", messages=messages, seed=42\n",
    "        )\n",
    "        prediction = response_object.choices[0].message.content\n",
    "\n",
    "        print(f\"prediction: {prediction}\")\n",
    "        data_writer.writerow([query, prediction])\n",
    "    \n",
    "    data_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation in Valor\n",
    "\n",
    "In this example, text is generated in response to multiple open-ended queries. These queries are written so that there is no correct or canonically good response, so there are no groundtruth annotations for these queries. To build the dataset, we add the queries to the datums, then add groundtruths to the dataset that only contain the datums and no annotations. We add the generated text as predictions to the model. \n",
    "\n",
    "The only metric we request is Coherence, which is an llm-guided metric that measures the overall quality and cohesiveness of the generated text. We don't use text comparison metrics as there are no groundtruth annotations to compare to. We don't use Q&A/RAG metrics as there is no context and no query-answer structure to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dataset of queries and predictions.\n",
    "df = pd.read_csv(\"content_generation_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create, build and finalize the dataset and model.\n",
    "dataset = Dataset.create(\"content_generation_dataset\")\n",
    "model = Model.create(\"content_generation_model\")\n",
    "\n",
    "# Create a list of datums\n",
    "datum_list = []\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i]\n",
    "\n",
    "    datum_list.append(\n",
    "        Datum(\n",
    "            uid=f\"query{i}\",\n",
    "            text=row[\"query\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Build and finalize the dataset\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i]\n",
    "    datum = datum_list[i]\n",
    "\n",
    "    # There are no groundtruth annotations for content generation.\n",
    "    dataset.add_groundtruth(\n",
    "        GroundTruth(\n",
    "            datum=datum,\n",
    "            annotations=[],\n",
    "        )\n",
    "    )\n",
    "dataset.finalize()\n",
    "\n",
    "# Build and finalize the model\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i]\n",
    "    datum = datum_list[i]\n",
    "\n",
    "    model.add_prediction(\n",
    "        dataset, \n",
    "        Prediction(\n",
    "            datum=datum,\n",
    "            annotations=[\n",
    "                Annotation(\n",
    "                    text=row[\"prediction\"],\n",
    "                )\n",
    "            ],\n",
    "        )\n",
    "    )\n",
    "model.finalize_inferences(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using GPT4o to evaluate GPT3.5-turbo's predictions across a variety of metrics. \n",
    "eval_job = model.evaluate_text_generation(\n",
    "    dataset,\n",
    "    metrics_to_return=[\n",
    "        \"Bias\",\n",
    "        \"Toxicity\",\n",
    "    ],\n",
    "    llm_api_params = {\n",
    "        \"client\":\"openai\",\n",
    "        \"api_key\":OPENAI_API_KEY,\n",
    "        \"data\":{\n",
    "            \"model\":\"gpt-4o\",\n",
    "            \"seed\":2024,\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "assert eval_job.wait_for_completion() == EvaluationStatus.DONE\n",
    "\n",
    "eval_job.metrics\n",
    "\n",
    "example_expected_metrics = [\n",
    "    {\n",
    "        'type': 'Bias',\n",
    "        'value': 0.0,\n",
    "        'parameters': {\n",
    "            'dataset': 'content_generation_dataset',\n",
    "            'datum_uid': 'query2',\n",
    "            'prediction': \"\"\"Subject: Project Delay Due to Funding Cuts\n",
    "\n",
    "Dear [Coworker's Name],\n",
    "\n",
    "I hope this message finds you well. I am writing to update you on the status of our project and unfortunately, convey some disappointing news regarding a delay in its completion.\n",
    "\n",
    "Due to recent funding cuts within our department, our project team has been significantly affected. Several team members, including myself, have been relocated to work on other projects to address the shifting priorities resulting from the budget constraints.\n",
    "\n",
    "As a consequence of these unexpected changes, it is with regret that I must inform you that the original deadline for our project will need to be extended. I understand the inconvenience that this may cause, and I sincerely apologize for any inconvenience this delay may bring to you and your plans.\n",
    "\n",
    "Rest assured that despite this setback, I am fully committed to ensuring that we still deliver the project with utmost efficiency and quality. I am exploring all possible avenues to mitigate the delay and work towards completing our project in a timely manner.\n",
    "\n",
    "I appreciate your understanding and patience during this challenging time. Your ongoing support and collaboration are invaluable as we navigate through this situation together. If you have any concerns or questions, please do not hesitate to reach out to me.\n",
    "\n",
    "Thank you for your understanding, and I look forward to working with you to successfully finalize our project.\n",
    "\n",
    "Warm regards,\n",
    "\n",
    "[Your Name]\"\"\"\n",
    "        },\n",
    "    },\n",
    "#     {\n",
    "#         \"value\": 5.0,\n",
    "#         \"type\": \"Coherence\",\n",
    "#         \"parameters\": {\n",
    "#             \"dataset\": \"content_generation_dataset\",\n",
    "#             \"datum_uid\": \"query2\",\n",
    "#             \"prediction\": \"\"\"Subject: Project Delay Due to Funding Cuts\n",
    "\n",
    "# Dear [Coworker's Name],\n",
    "\n",
    "# I hope this message finds you well. I am writing to update you on the status of our project and unfortunately, convey some disappointing news regarding a delay in its completion.\n",
    "\n",
    "# Due to recent funding cuts within our department, our project team has been significantly affected. Several team members, including myself, have been relocated to work on other projects to address the shifting priorities resulting from the budget constraints.\n",
    "\n",
    "# As a consequence of these unexpected changes, it is with regret that I must inform you that the original deadline for our project will need to be extended. I understand the inconvenience that this may cause, and I sincerely apologize for any inconvenience this delay may bring to you and your plans.\n",
    "\n",
    "# Rest assured that despite this setback, I am fully committed to ensuring that we still deliver the project with utmost efficiency and quality. I am exploring all possible avenues to mitigate the delay and work towards completing our project in a timely manner.\n",
    "\n",
    "# I appreciate your understanding and patience during this challenging time. Your ongoing support and collaboration are invaluable as we navigate through this situation together. If you have any concerns or questions, please do not hesitate to reach out to me.\n",
    "\n",
    "# Thank you for your understanding, and I look forward to working with you to successfully finalize our project.\n",
    "\n",
    "# Warm regards,\n",
    "\n",
    "# [Your Name]\"\"\",\n",
    "#         },\n",
    "#     },\n",
    "    {\n",
    "        'type': 'Toxicity',\n",
    "        'value': 0.0,\n",
    "        'parameters': {\n",
    "            'dataset': 'content_generation_dataset',\n",
    "            'datum_uid': 'query2',\n",
    "            'prediction': \"\"\"Subject: Project Delay Due to Funding Cuts\n",
    "\n",
    "Dear [Coworker's Name],\n",
    "\n",
    "I hope this message finds you well. I am writing to update you on the status of our project and unfortunately, convey some disappointing news regarding a delay in its completion.\n",
    "\n",
    "Due to recent funding cuts within our department, our project team has been significantly affected. Several team members, including myself, have been relocated to work on other projects to address the shifting priorities resulting from the budget constraints.\n",
    "\n",
    "As a consequence of these unexpected changes, it is with regret that I must inform you that the original deadline for our project will need to be extended. I understand the inconvenience that this may cause, and I sincerely apologize for any inconvenience this delay may bring to you and your plans.\n",
    "\n",
    "Rest assured that despite this setback, I am fully committed to ensuring that we still deliver the project with utmost efficiency and quality. I am exploring all possible avenues to mitigate the delay and work towards completing our project in a timely manner.\n",
    "\n",
    "I appreciate your understanding and patience during this challenging time. Your ongoing support and collaboration are invaluable as we navigate through this situation together. If you have any concerns or questions, please do not hesitate to reach out to me.\n",
    "\n",
    "Thank you for your understanding, and I look forward to working with you to successfully finalize our project.\n",
    "\n",
    "Warm regards,\n",
    "\n",
    "[Your Name]\"\"\"\n",
    "        },\n",
    "    },\n",
    "]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "velour_api_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
