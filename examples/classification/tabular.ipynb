{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0644bdbe-38da-478e-8673-802a5cb59da0",
   "metadata": {},
   "source": [
    "# Tabular Classification Example\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we'll walk-through a detailed example of how you can use Velour to evaluate classifications made on a tabular dataset. We'll use `sklearn's` breast cancer dataset to make a binary prediction about whether a woman has breast cancer based on a table of descriptive features (e.g., mean radius, mean texture, etc.). \n",
    "\n",
    "For a conceptual introduction to Velour, [check out our project overview](https://striveworks.github.io/velour/). For a higher-level example notebook, [check out our \"Getting Started\" notebook](https://github.com/Striveworks/velour/blob/main/examples/getting_started.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e18d9c3",
   "metadata": {},
   "source": [
    "## Defining Our Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d1508c",
   "metadata": {},
   "source": [
    "We start by fetching our dataset, dividing it into test/train splits, and uploading both sets to Velour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9daebe8-0bb4-41eb-8359-9cadaa4a7779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://aws:****@striveworks-724664234782.d.codeartifact.us-east-1.amazonaws.com/pypi/striveworks/simple\n",
      "Requirement already satisfied: scikit-learn in /home/czaloom/velour/.env-velour/lib/python3.10/site-packages (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/czaloom/velour/.env-velour/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/czaloom/velour/.env-velour/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /home/czaloom/velour/.env-velour/lib/python3.10/site-packages (from scikit-learn) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/czaloom/velour/.env-velour/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The Velour client isn't versioned.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Successfully connected to host at http://localhost:8000/\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn\n",
    "\n",
    "from velour import Dataset, Model, Datum, Annotation, GroundTruth, Prediction, Label\n",
    "from velour.enums import TaskType\n",
    "from velour.client import Client\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# connect to Velour API\n",
    "client = Client(\"http://localhost:8000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2c72cd1-50f7-4e85-9e25-d0ed35b1d1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data from sklearn\n",
    "dset = load_breast_cancer()\n",
    "dset.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6a8d343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426, 30), array([1, 1, 1, 0]), array(['malignant', 'benign'], dtype='<U9'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split datasets\n",
    "X, y, target_names = dset[\"data\"], dset[\"target\"], dset[\"target_names\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# show an example input\n",
    "X_train.shape, y_train[:4], target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74f5836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train dataset in Velour\n",
    "velour_train_dataset = Dataset(client, \"breast-cancer-train\", reset=True)\n",
    "\n",
    "# create test dataset in Velour\n",
    "velour_test_dataset = Dataset(client, \"breast-cancer-test\", reset=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e85ac3c",
   "metadata": {},
   "source": [
    "### Adding GroundTruths to our Dataset\n",
    "\n",
    "Now that our two datasets exists in Velour, we can add `GroundTruths` to each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c5311dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format training groundtruths\n",
    "training_groundtruths = [\n",
    "    GroundTruth(\n",
    "        datum=Datum(\n",
    "            uid=f\"train{i}\",\n",
    "        ),\n",
    "        annotations=[\n",
    "            Annotation(\n",
    "                task_type=TaskType.CLASSIFICATION,\n",
    "                labels=[Label(key=\"class\", value=target_names[t])]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    for i, t in enumerate(y_train)\n",
    "]\n",
    "\n",
    "# format testing groundtruths\n",
    "testing_groundtruths = [\n",
    "    GroundTruth(\n",
    "        datum=Datum(\n",
    "            uid=f\"test{i}\",\n",
    "        ),\n",
    "        annotations=[\n",
    "            Annotation(\n",
    "                task_type=TaskType.CLASSIFICATION,\n",
    "                labels=[Label(key=\"class\", value=target_names[t])]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    for i, t in enumerate(y_test)\n",
    "]\n",
    "\n",
    "# add the training groundtruths\n",
    "for gt in training_groundtruths:\n",
    "    velour_train_dataset.add_groundtruth(gt)\n",
    "\n",
    "# add the testing groundtruths\n",
    "for gt in testing_groundtruths:\n",
    "    velour_test_dataset.add_groundtruth(gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b70427",
   "metadata": {},
   "source": [
    "### Finalizing Our Datasets\n",
    "\n",
    "Lastly, we finalize both datasets to prep them for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75e5cddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "velour_train_dataset.finalize()\n",
    "velour_test_dataset.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ea0e42",
   "metadata": {},
   "source": [
    "## Defining Our Model\n",
    "\n",
    "Now that our `Datasets` have been defined, we can describe our model in Velour using the `Model` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f43e61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.69431274e-03, 9.93305687e-01],\n",
       "       [9.53969288e-05, 9.99904603e-01],\n",
       "       [2.06847800e-01, 7.93152200e-01],\n",
       "       [9.99999993e-01, 6.66395645e-09]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit an sklearn model to our data\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# get predictions on both of our datasets\n",
    "y_train_probs = pipe.predict_proba(X_train)\n",
    "y_test_probs = pipe.predict_proba(X_test)\n",
    "\n",
    "# show an example output\n",
    "y_train_probs[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0380f0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our model in Velour\n",
    "velour_model = Model(client, \"breast-cancer-linear-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61de269b",
   "metadata": {},
   "source": [
    "### Adding Predictions to Our Model\n",
    "\n",
    "With our model defined in Velour, we can post predictions for each of our `Datasets` to our `Model` object. Each `Prediction` should contain a list of `Labels` describing the prediction and its associated confidence score. Since we're running a classification task, the confidence scores over all prediction classes should sum to (approximately) 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a224345",
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientException",
     "evalue": "cannot edit inferences for model`breast-cancer-linear-model` on dataset `breast-cancer-train` since it has been finalized",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39m# add the train predictions\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[39mfor\u001b[39;00m pd \u001b[39min\u001b[39;00m training_predictions:\n\u001b[0;32m---> 50\u001b[0m     velour_model\u001b[39m.\u001b[39;49madd_prediction(pd)\n\u001b[1;32m     52\u001b[0m \u001b[39m# add the test predictions\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m pd \u001b[39min\u001b[39;00m testing_predictions:\n",
      "File \u001b[0;32m~/velour/.env-velour/lib/python3.10/site-packages/velour/coretypes.py:1108\u001b[0m, in \u001b[0;36mModel.add_prediction\u001b[0;34m(self, prediction)\u001b[0m\n\u001b[1;32m   1103\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1104\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPrediction for datum with uid `\u001b[39m\u001b[39m{\u001b[39;00mprediction\u001b[39m.\u001b[39mdatum\u001b[39m.\u001b[39muid\u001b[39m}\u001b[39;00m\u001b[39m` contains no annotations.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1105\u001b[0m     )\n\u001b[1;32m   1107\u001b[0m prediction\u001b[39m.\u001b[39mmodel_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\n\u001b[0;32m-> 1108\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49m_requests_post_rel_host(\n\u001b[1;32m   1109\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mpredictions\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1110\u001b[0m     json\u001b[39m=\u001b[39;49mprediction\u001b[39m.\u001b[39;49mdict(),\n\u001b[1;32m   1111\u001b[0m )\n",
      "File \u001b[0;32m~/velour/.env-velour/lib/python3.10/site-packages/velour/client.py:133\u001b[0m, in \u001b[0;36mClient._requests_post_rel_host\u001b[0;34m(self, endpoint, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_requests_post_rel_host\u001b[39m(\u001b[39mself\u001b[39m, endpoint: \u001b[39mstr\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    130\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m    Helper for handling POST requests.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_requests_wrapper(\n\u001b[1;32m    134\u001b[0m         method_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m, endpoint\u001b[39m=\u001b[39;49mendpoint, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    135\u001b[0m     )\n",
      "File \u001b[0;32m~/velour/.env-velour/lib/python3.10/site-packages/velour/client.py:123\u001b[0m, in \u001b[0;36mClient._requests_wrapper\u001b[0;34m(self, method_name, endpoint, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m resp\u001b[39m.\u001b[39mok:\n\u001b[1;32m    122\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 123\u001b[0m         \u001b[39mraise\u001b[39;00m ClientException(resp\u001b[39m.\u001b[39mjson()[\u001b[39m\"\u001b[39m\u001b[39mdetail\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    124\u001b[0m     \u001b[39mexcept\u001b[39;00m (requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mJSONDecodeError, \u001b[39mKeyError\u001b[39;00m):\n\u001b[1;32m    125\u001b[0m         resp\u001b[39m.\u001b[39mraise_for_status()\n",
      "\u001b[0;31mClientException\u001b[0m: cannot edit inferences for model`breast-cancer-linear-model` on dataset `breast-cancer-train` since it has been finalized"
     ]
    }
   ],
   "source": [
    "\n",
    "# define our predictions\n",
    "training_predictions = [\n",
    "    Prediction(\n",
    "        datum=Datum(\n",
    "            dataset=velour_train_dataset.name,\n",
    "            uid=f\"train{i}\",\n",
    "        ),\n",
    "        annotations=[\n",
    "            Annotation(\n",
    "                task_type=TaskType.CLASSIFICATION,\n",
    "                labels=[\n",
    "                    Label(\n",
    "                        key=\"class\", \n",
    "                        value=target_names[j],\n",
    "                        score=p,\n",
    "                    )                        \n",
    "                    for j, p in enumerate(prob)\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    for i, prob in enumerate(y_train_probs)\n",
    "]\n",
    "\n",
    "testing_predictions = [\n",
    "    Prediction(\n",
    "        datum=Datum(\n",
    "            dataset=velour_test_dataset.name,\n",
    "            uid=f\"test{i}\",\n",
    "        ),\n",
    "        annotations=[\n",
    "            Annotation(\n",
    "                task_type=TaskType.CLASSIFICATION,\n",
    "                labels=[\n",
    "                    Label(\n",
    "                        key=\"class\",\n",
    "                        value=target_names[j],\n",
    "                        score=p,\n",
    "                    )                        \n",
    "                    for j, p in enumerate(prob)\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    for i, prob in enumerate(y_test_probs)\n",
    "]\n",
    "\n",
    "# add the train predictions\n",
    "for pd in training_predictions:\n",
    "    velour_model.add_prediction(pd)\n",
    "\n",
    "# add the test predictions\n",
    "for pd in testing_predictions:\n",
    "    velour_model.add_prediction(pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788c9943",
   "metadata": {},
   "source": [
    "### Finalizing Our Model\n",
    "\n",
    "Finally, we finalize our `Model` to prep it for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f7cfd2-4784-466d-90b8-32c813fb7997",
   "metadata": {},
   "outputs": [],
   "source": [
    "velour_model.finalize_inferences(velour_train_dataset)\n",
    "velour_model.finalize_inferences(velour_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b78f442",
   "metadata": {},
   "source": [
    "## Evaluating Performance\n",
    "\n",
    "With our `Dataset` and `Model` defined, we're ready to evaluate our performance and display the results in a `pd.DataFrame`. Note that we use the `wait_for_completion` method since all evaluations run as a postgres `BackgroundTask`; this method ensures that the evaluation finishes before we display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba0e545-4eaa-4f6b-8d62-f3a63018e168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>breast-cancer-train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>parameters</th>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <th>{\"label_key\": \"class\"}</th>\n",
       "      <th>n/a</th>\n",
       "      <td>0.988263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">F1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">\"n/a\"</th>\n",
       "      <th>class: benign</th>\n",
       "      <td>0.991055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class: malignant</th>\n",
       "      <td>0.982935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Precision</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">\"n/a\"</th>\n",
       "      <th>class: benign</th>\n",
       "      <td>0.989286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class: malignant</th>\n",
       "      <td>0.986301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROCAUC</th>\n",
       "      <th>{\"label_key\": \"class\"}</th>\n",
       "      <th>n/a</th>\n",
       "      <td>0.997294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Recall</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">\"n/a\"</th>\n",
       "      <th>class: benign</th>\n",
       "      <td>0.992832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class: malignant</th>\n",
       "      <td>0.979592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                value\n",
       "dataset                                           breast-cancer-train\n",
       "type      parameters             label                               \n",
       "Accuracy  {\"label_key\": \"class\"} n/a                         0.988263\n",
       "F1        \"n/a\"                  class: benign               0.991055\n",
       "                                 class: malignant            0.982935\n",
       "Precision \"n/a\"                  class: benign               0.989286\n",
       "                                 class: malignant            0.986301\n",
       "ROCAUC    {\"label_key\": \"class\"} n/a                         0.997294\n",
       "Recall    \"n/a\"                  class: benign               0.992832\n",
       "                                 class: malignant            0.979592"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eval_job = velour_model.evaluate_classification(velour_train_dataset)\n",
    "train_eval_job.wait_for_completion()\n",
    "results = train_eval_job.results()\n",
    "\n",
    "results.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73626229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label_key': 'class',\n",
       "  'entries': [{'prediction': 'benign', 'groundtruth': 'benign', 'count': 277},\n",
       "   {'prediction': 'benign', 'groundtruth': 'malignant', 'count': 3},\n",
       "   {'prediction': 'malignant', 'groundtruth': 'benign', 'count': 2},\n",
       "   {'prediction': 'malignant', 'groundtruth': 'malignant', 'count': 144}]}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.confusion_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e447e7-0da4-49ae-af0a-8baa1446b4e7",
   "metadata": {},
   "source": [
    "As a brief sanity check, we can check Velour's outputs against `sklearn's` own classification report. We see that the two results are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347c180e-9913-4aa4-994e-de507da32d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant   0.986301  0.979592  0.982935       147\n",
      "      benign   0.989286  0.992832  0.991055       279\n",
      "\n",
      "    accuracy                       0.988263       426\n",
      "   macro avg   0.987794  0.986212  0.986995       426\n",
      "weighted avg   0.988256  0.988263  0.988253       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_preds = pipe.predict(X_train)\n",
    "print(classification_report(y_train, y_train_preds, digits=6, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env-velour",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
