{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Getting Started with Valor Core\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Valor is a centralized evaluation store which makes it easy to measure, explore, and rank model performance. Valor empowers data scientists and engineers to evaluate the performance of their machine learning pipelines and use those evaluations to make better modeling decisions in the future. For a conceptual introduction to Valor, [check out our project overview](https://striveworks.github.io/valor/).\n",
        "\n",
        "In this notebook, we'll introduce Valor's high-level abstractions and walk through a computer vision-oriented example of how you can use Valor to evaluate model performance. For task-specific examples, please see our follow-up notebooks below:\n",
        "\n",
        "- [Tabular classification](https://github.com/Striveworks/valor/blob/main/examples/classification/tabular.ipynb)\n",
        "- [Object detection](https://github.com/Striveworks/valor/blob/main/examples/object-detection/coco-yolo.ipynb)\n",
        "- [Semantic segmentation](https://github.com/Striveworks/valor/blob/main/examples/semantic-segmentation/coco-yolo.ipynb)\n",
        "\n",
        "Note that this notebook uses `valor_core`, rather than `valor`, to calculate all metrics locally without utilizing Postgres' filtering and data exploration capabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining Our Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To begin, we import all needed packages from `valor_core`. For instructions on setting up your environment, please see [our docs here](https://striveworks.github.io/valor/getting_started/).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "from valor_core import (\n",
        "    Datum,\n",
        "    Annotation,\n",
        "    GroundTruth,\n",
        "    Prediction,\n",
        "    Label,\n",
        "    Box,\n",
        "    evaluate_classification, \n",
        "    evaluate_detection\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Image Classification GroundTruths and Predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To describe the various objects in our data, we'll create lists of `GroundTruth` and `Prediction` objects to pass into our `evaluate..` functions. Note that Valor doesn't actually store any images, and that the `Annotations` we use will vary by our task type (i.e., object detection, semantic segmentation, etc.). For demonstrative purposes, we'll create `GroundTruths` for two different learning tasks in this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[GroundTruth(datum=Datum(uid='img1', metadata={'path': 'a/b/c/img1.png'}), annotations=[Annotation(labels=[Label(key='class_label', value='dog', score=None)], metadata=None, bounding_box=None, polygon=None, raster=None, embedding=None, is_instance=None, implied_task_types=None)]), GroundTruth(datum=Datum(uid='img2', metadata={'path': 'a/b/c/img2.png'}), annotations=[Annotation(labels=[Label(key='class_label', value='cat', score=None)], metadata=None, bounding_box=None, polygon=None, raster=None, embedding=None, is_instance=None, implied_task_types=None)])]\n"
          ]
        }
      ],
      "source": [
        "def create_image_classification_data(classification_data):\n",
        "\n",
        "    groundtruths, predictions = [], []\n",
        "\n",
        "    for element in classification_data:\n",
        "\n",
        "        datum = Datum(\n",
        "            uid=Path(element[\"path\"]).stem, metadata={\"path\": element[\"path\"]}\n",
        "        )\n",
        "\n",
        "        gt_annotations = [\n",
        "            Annotation(\n",
        "                labels=[\n",
        "                    Label(key=key, value=value)\n",
        "                    for label in element[\"gt_annotations\"]\n",
        "                    for key, value in label.items()\n",
        "                ]\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        pd_annotations = [\n",
        "            Annotation(\n",
        "                labels=[\n",
        "                    Label(\n",
        "                        key=\"class_label\",\n",
        "                        value=label[\"class_label\"],\n",
        "                        score=label[\"score\"],\n",
        "                    )\n",
        "                    for label in element[\"pd_annotations\"]\n",
        "                ]\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        groundtruths.append(\n",
        "            GroundTruth(\n",
        "                datum=datum,\n",
        "                annotations=gt_annotations,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        predictions.append(\n",
        "            Prediction(\n",
        "                datum=datum,\n",
        "                annotations=pd_annotations,\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return groundtruths, predictions\n",
        "\n",
        "\n",
        "classification_data = [\n",
        "        {\n",
        "            \"path\": \"a/b/c/img1.png\",\n",
        "            \"gt_annotations\": [{\"class_label\": \"dog\"}],\n",
        "            \"pd_annotations\": [\n",
        "                {\"class_label\": \"dog\", \"score\": 0.9},\n",
        "                {\"class_label\": \"cat\", \"score\": 0.1},\n",
        "            ],\n",
        "        },\n",
        "        {\n",
        "            \"path\": \"a/b/c/img2.png\",\n",
        "            \"gt_annotations\": [{\"class_label\": \"cat\"}],\n",
        "            \"pd_annotations\": [\n",
        "                {\"class_label\": \"dog\", \"score\": 0.1},\n",
        "                {\"class_label\": \"cat\", \"score\": 0.9},\n",
        "            ],\n",
        "        },\n",
        "    ]\n",
        "\n",
        "\n",
        "classification_gts, classification_pds = create_image_classification_data(classification_data)\n",
        "print(classification_gts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Object Detection GroundTruths and Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Prediction(datum=Datum(uid='img3', metadata={'path': 'a/b/c/img3.png'}), annotations=[Annotation(labels=[Label(key='class_label', value='dog', score=0.8), Label(key='class_label', value='cat', score=0.1), Label(key='class_label', value='person', score=0.1)], metadata=None, bounding_box=Box(value=[[(16, 130), (70, 130), (70, 150), (16, 150), (16, 130)]]), polygon=None, raster=None, embedding=None, is_instance=True, implied_task_types=None), Annotation(labels=[Label(key='class_label', value='dog', score=0.05), Label(key='class_label', value='cat', score=0.05), Label(key='class_label', value='person', score=0.9)], metadata=None, bounding_box=Box(value=[[(89, 10), (97, 10), (97, 110), (89, 110), (89, 10)]]), polygon=None, raster=None, embedding=None, is_instance=True, implied_task_types=None)]), Prediction(datum=Datum(uid='img4', metadata={'path': 'a/b/c/img4.png'}), annotations=[Annotation(labels=[Label(key='class_label', value='dog', score=0.8), Label(key='class_label', value='cat', score=0.1), Label(key='class_label', value='person', score=0.1)], metadata=None, bounding_box=Box(value=[[(500, 220), (530, 220), (530, 260), (500, 260), (500, 220)]]), polygon=None, raster=None, embedding=None, is_instance=True, implied_task_types=None)]), Prediction(datum=Datum(uid='img5', metadata={'path': 'a/b/c/img5.png'}), annotations=[])]\n"
          ]
        }
      ],
      "source": [
        "def create_groundtruth_from_object_detection_dict(detection_data):\n",
        "    groundtruths, predictions = [], []\n",
        "\n",
        "    for element in detection_data:\n",
        "\n",
        "        datum = Datum(\n",
        "            uid=Path(element[\"path\"]).stem, metadata={\"path\": element[\"path\"]}\n",
        "        )\n",
        "\n",
        "        gt_annotations = [\n",
        "            Annotation(\n",
        "                labels=[\n",
        "                    Label(key=\"class_label\", value=annotation[\"class_label\"])\n",
        "                ],\n",
        "                bounding_box=Box.from_extrema(\n",
        "                    xmin=annotation[\"bbox\"][\"xmin\"],\n",
        "                    xmax=annotation[\"bbox\"][\"xmax\"],\n",
        "                    ymin=annotation[\"bbox\"][\"ymin\"],\n",
        "                    ymax=annotation[\"bbox\"][\"ymax\"],\n",
        "                ),\n",
        "                is_instance=True,\n",
        "            )\n",
        "            for annotation in element[\"gt_annotations\"]\n",
        "            if len(annotation) > 0\n",
        "        ]\n",
        "\n",
        "        pd_annotations = [\n",
        "            Annotation(\n",
        "                labels=[\n",
        "                    Label(\n",
        "                        key=\"class_label\",\n",
        "                        value=label[\"class_label\"],\n",
        "                        score=label[\"score\"],\n",
        "                    )\n",
        "                    for label in annotation[\"labels\"]\n",
        "                ],\n",
        "                bounding_box=Box.from_extrema(\n",
        "                    xmin=annotation[\"bbox\"][\"xmin\"],\n",
        "                    xmax=annotation[\"bbox\"][\"xmax\"],\n",
        "                    ymin=annotation[\"bbox\"][\"ymin\"],\n",
        "                    ymax=annotation[\"bbox\"][\"ymax\"],\n",
        "                ),\n",
        "                is_instance=True,\n",
        "            )\n",
        "            for annotation in element[\"pd_annotations\"]\n",
        "            if len(annotation) > 0\n",
        "        ]\n",
        "\n",
        "        groundtruths.append(\n",
        "            GroundTruth(\n",
        "                datum=datum,\n",
        "                annotations=gt_annotations,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        predictions.append(\n",
        "            Prediction(\n",
        "                datum=datum,\n",
        "                annotations=pd_annotations,\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return groundtruths, predictions\n",
        "\n",
        "\n",
        "detection_data = [\n",
        "    {\n",
        "        \"path\": \"a/b/c/img3.png\",\n",
        "        \"gt_annotations\": [\n",
        "            {\n",
        "                \"class_label\": \"dog\",\n",
        "                \"bbox\": {\"xmin\": 16, \"ymin\": 130, \"xmax\": 70, \"ymax\": 150},\n",
        "            },\n",
        "            {\n",
        "                \"class_label\": \"person\",\n",
        "                \"bbox\": {\"xmin\": 89, \"ymin\": 10, \"xmax\": 97, \"ymax\": 110},\n",
        "            },\n",
        "        ],\n",
        "        \"pd_annotations\": [\n",
        "            {\n",
        "                \"labels\": [\n",
        "                    {\"class_label\": \"dog\", \"score\": 0.8},\n",
        "                    {\"class_label\": \"cat\", \"score\": 0.1},\n",
        "                    {\"class_label\": \"person\", \"score\": 0.1},\n",
        "                ],\n",
        "                \"bbox\": {\"xmin\": 16, \"ymin\": 130, \"xmax\": 70, \"ymax\": 150},\n",
        "            },\n",
        "            {\n",
        "                \"labels\": [\n",
        "                    {\"class_label\": \"dog\", \"score\": 0.05},\n",
        "                    {\"class_label\": \"cat\", \"score\": 0.05},\n",
        "                    {\"class_label\": \"person\", \"score\": 0.9},\n",
        "                ],\n",
        "                \"bbox\": {\"xmin\": 89, \"ymin\": 10, \"xmax\": 97, \"ymax\": 110},\n",
        "            },\n",
        "        ],\n",
        "    },\n",
        "    {\n",
        "        \"path\": \"a/b/c/img4.png\",\n",
        "        \"gt_annotations\": [\n",
        "            {\n",
        "                \"class_label\": \"cat\",\n",
        "                \"bbox\": {\"xmin\": 500, \"ymin\": 220, \"xmax\": 530, \"ymax\": 260},\n",
        "            }\n",
        "        ],\n",
        "        \"pd_annotations\": [\n",
        "            {\n",
        "                \"labels\": [\n",
        "                    {\"class_label\": \"dog\", \"score\": 0.8},\n",
        "                    {\"class_label\": \"cat\", \"score\": 0.1},\n",
        "                    {\"class_label\": \"person\", \"score\": 0.1},\n",
        "                ],\n",
        "                \"bbox\": {\"xmin\": 500, \"ymin\": 220, \"xmax\": 530, \"ymax\": 260},\n",
        "            }\n",
        "        ],\n",
        "    },\n",
        "    {\"path\": \"a/b/c/img5.png\", \"gt_annotations\": [], \"pd_annotations\": []},\n",
        "]\n",
        "\n",
        "\n",
        "detection_gts, detection_pds = create_groundtruth_from_object_detection_dict(\n",
        "    detection_data=detection_data\n",
        ")\n",
        "print(detection_pds)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluating Performance\n",
        "\n",
        "Finally, we'll use our Valor abstractions to evaluate model performance. For more detailed, task-specific examples, see our follow-up notebooks at the links below:\n",
        "\n",
        "- [Tabular classification](https://github.com/Striveworks/valor/blob/main/examples/classification/tabular.ipynb)\n",
        "- [Object detection](https://github.com/Striveworks/valor/blob/main/examples/object-detection/coco-yolo.ipynb)\n",
        "- [Semantic segmentation](https://github.com/Striveworks/valor/blob/main/examples/semantic-segmentation/coco-yolo.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluating Detections\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': {'key': 'class_label', 'value': 'person'},\n",
              "  'parameters': {'iou': 0.5},\n",
              "  'value': 1.0,\n",
              "  'type': 'AP'},\n",
              " {'label': {'key': 'class_label', 'value': 'person'},\n",
              "  'parameters': {'iou': 0.75},\n",
              "  'value': 1.0,\n",
              "  'type': 'AP'},\n",
              " {'label': {'key': 'class_label', 'value': 'cat'},\n",
              "  'parameters': {'iou': 0.5},\n",
              "  'value': 1.0,\n",
              "  'type': 'AP'},\n",
              " {'label': {'key': 'class_label', 'value': 'cat'},\n",
              "  'parameters': {'iou': 0.75},\n",
              "  'value': 1.0,\n",
              "  'type': 'AP'},\n",
              " {'label': {'key': 'class_label', 'value': 'dog'},\n",
              "  'parameters': {'iou': 0.5},\n",
              "  'value': 1.0,\n",
              "  'type': 'AP'},\n",
              " {'label': {'key': 'class_label', 'value': 'dog'},\n",
              "  'parameters': {'iou': 0.75},\n",
              "  'value': 1.0,\n",
              "  'type': 'AP'},\n",
              " {'parameters': {'label_key': 'class_label', 'iou': 0.5},\n",
              "  'value': 1.0,\n",
              "  'type': 'mAP'},\n",
              " {'parameters': {'label_key': 'class_label', 'iou': 0.75},\n",
              "  'value': 1.0,\n",
              "  'type': 'mAP'},\n",
              " {'label': {'key': 'class_label', 'value': 'person'},\n",
              "  'parameters': {'ious': [0.5,\n",
              "    0.55,\n",
              "    0.6,\n",
              "    0.65,\n",
              "    0.7,\n",
              "    0.75,\n",
              "    0.8,\n",
              "    0.85,\n",
              "    0.9,\n",
              "    0.95]},\n",
              "  'value': 1.0,\n",
              "  'type': 'APAveragedOverIOUs'},\n",
              " {'label': {'key': 'class_label', 'value': 'cat'},\n",
              "  'parameters': {'ious': [0.5,\n",
              "    0.55,\n",
              "    0.6,\n",
              "    0.65,\n",
              "    0.7,\n",
              "    0.75,\n",
              "    0.8,\n",
              "    0.85,\n",
              "    0.9,\n",
              "    0.95]},\n",
              "  'value': 1.0,\n",
              "  'type': 'APAveragedOverIOUs'},\n",
              " {'label': {'key': 'class_label', 'value': 'dog'},\n",
              "  'parameters': {'ious': [0.5,\n",
              "    0.55,\n",
              "    0.6,\n",
              "    0.65,\n",
              "    0.7,\n",
              "    0.75,\n",
              "    0.8,\n",
              "    0.85,\n",
              "    0.9,\n",
              "    0.95]},\n",
              "  'value': 1.0,\n",
              "  'type': 'APAveragedOverIOUs'},\n",
              " {'parameters': {'label_key': 'class_label',\n",
              "   'ious': [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]},\n",
              "  'value': 1.0,\n",
              "  'type': 'mAPAveragedOverIOUs'},\n",
              " {'label': {'key': 'class_label', 'value': 'person'},\n",
              "  'parameters': {'ious': [0.5,\n",
              "    0.55,\n",
              "    0.6,\n",
              "    0.65,\n",
              "    0.7,\n",
              "    0.75,\n",
              "    0.8,\n",
              "    0.85,\n",
              "    0.9,\n",
              "    0.95]},\n",
              "  'value': 1.0,\n",
              "  'type': 'AR'},\n",
              " {'label': {'key': 'class_label', 'value': 'cat'},\n",
              "  'parameters': {'ious': [0.5,\n",
              "    0.55,\n",
              "    0.6,\n",
              "    0.65,\n",
              "    0.7,\n",
              "    0.75,\n",
              "    0.8,\n",
              "    0.85,\n",
              "    0.9,\n",
              "    0.95]},\n",
              "  'value': 1.0,\n",
              "  'type': 'AR'},\n",
              " {'label': {'key': 'class_label', 'value': 'dog'},\n",
              "  'parameters': {'ious': [0.5,\n",
              "    0.55,\n",
              "    0.6,\n",
              "    0.65,\n",
              "    0.7,\n",
              "    0.75,\n",
              "    0.8,\n",
              "    0.85,\n",
              "    0.9,\n",
              "    0.95]},\n",
              "  'value': 1.0,\n",
              "  'type': 'AR'},\n",
              " {'parameters': {'label_key': 'class_label',\n",
              "   'ious': [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]},\n",
              "  'value': 1.0,\n",
              "  'type': 'mAR'}]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_objdet = evaluate_detection(groundtruths=detection_gts, predictions=detection_pds)\n",
        "eval_objdet.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': {'key': 'class_label', 'value': 'cat'},\n",
              "  'value': 1.0,\n",
              "  'type': 'Precision'},\n",
              " {'label': {'key': 'class_label', 'value': 'cat'},\n",
              "  'value': 1.0,\n",
              "  'type': 'Recall'},\n",
              " {'label': {'key': 'class_label', 'value': 'cat'}, 'value': 1.0, 'type': 'F1'},\n",
              " {'label': {'key': 'class_label', 'value': 'dog'},\n",
              "  'value': 1.0,\n",
              "  'type': 'Precision'},\n",
              " {'label': {'key': 'class_label', 'value': 'dog'},\n",
              "  'value': 1.0,\n",
              "  'type': 'Recall'},\n",
              " {'label': {'key': 'class_label', 'value': 'dog'}, 'value': 1.0, 'type': 'F1'},\n",
              " {'parameters': {'label_key': 'class_label'},\n",
              "  'value': 1.0,\n",
              "  'type': 'Accuracy'},\n",
              " {'parameters': {'label_key': 'class_label'}, 'value': 1.0, 'type': 'ROCAUC'}]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval_clf = evaluate_classification(groundtruths=classification_gts, predictions=classification_pds)\n",
        "eval_clf.metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "For more examples, we'd recommend reviewing our [other sample notebooks on GitHub](https://github.com/Striveworks/valor/blob/main/examples/). For more detailed explanations of Valor's technical underpinnings, see our [technical concepts guide](technical_concepts.md).\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".env-valor",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
